{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAG_Clova"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Env"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python Version : Python 3.12.2\n",
    "\n",
    "requirements : \n",
    "https://ssl.pstatic.net/static/clova/service/hyperclova/cookbook/rag/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vector DB인 Milvus와 관련된 모듈들은 모듈의 용도를 명확히 구분하기 위해 Vector DB 구축 단계에서 불러왔으며 해당 부분에서 코드를 확인하실 수 있습니다.\n",
    "import json\n",
    "import os\n",
    "import subprocess\n",
    "from langchain_community.document_loaders import UnstructuredHTMLLoader\n",
    "from pathlib import Path\n",
    "import base64\n",
    "import http.client\n",
    "from tqdm import tqdm\n",
    "import requests\n",
    "import dotenv\n",
    "dotenv.load_dotenv()\n",
    "CLOVA_api_key=os.getenv(\"X-NCP-CLOVASTUDIO-API-KEY\")\n",
    "NCP_API_api_key=os.getenv(\"X-NCP-APIGW-API-KEY\")\n",
    "clova_REQUEST_ID=os.getenv(\"X-NCP-CLOVASTUDIO-REQUEST-ID\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Raw Data → Connecting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--2024-08-25 23:24:39--  https://wikidocs.net/233341\n",
      "Resolving wikidocs.net (wikidocs.net)... 15.165.86.219\n",
      "Connecting to wikidocs.net (wikidocs.net)|15.165.86.219|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 99984 (98K) [text/html]\n",
      "Saving to: ‘langchainwikiguide/233341.html’\n",
      "\n",
      "     0K .......... .......... .......... .......... .......... 51% 6.59M 0s\n",
      "    50K .......... .......... .......... .......... .......   100% 58.6M=0.008s\n",
      "\n",
      "2024-08-25 23:24:39 (11.6 MB/s) - ‘langchainwikiguide/233341.html’ saved [99984/99984]\n",
      "\n",
      "--2024-08-25 23:24:39--  https://wikidocs.net/233342\n",
      "Resolving wikidocs.net (wikidocs.net)... 15.165.86.219\n",
      "Connecting to wikidocs.net (wikidocs.net)|15.165.86.219|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 99828 (97K) [text/html]\n",
      "Saving to: ‘langchainwikiguide/233342.html’\n",
      "\n",
      "     0K .......... .......... .......... .......... .......... 51% 6.69M 0s\n",
      "    50K .......... .......... .......... .......... .......   100%  410M=0.007s\n",
      "\n",
      "2024-08-25 23:24:39 (12.9 MB/s) - ‘langchainwikiguide/233342.html’ saved [99828/99828]\n",
      "\n",
      "--2024-08-25 23:24:39--  https://wikidocs.net/250954\n",
      "Resolving wikidocs.net (wikidocs.net)... 15.165.86.219\n",
      "Connecting to wikidocs.net (wikidocs.net)|15.165.86.219|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 100975 (99K) [text/html]\n",
      "Saving to: ‘langchainwikiguide/250954.html’\n",
      "\n",
      "     0K .......... .......... .......... .......... .......... 50% 5.86M 0s\n",
      "    50K .......... .......... .......... .......... ........  100%  452M=0.008s\n",
      "\n",
      "2024-08-25 23:24:40 (11.4 MB/s) - ‘langchainwikiguide/250954.html’ saved [100975/100975]\n",
      "\n",
      "--2024-08-25 23:24:40--  https://wikidocs.net/233343\n",
      "Resolving wikidocs.net (wikidocs.net)... 15.165.86.219\n",
      "Connecting to wikidocs.net (wikidocs.net)|15.165.86.219|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 421303 (411K) [text/html]\n",
      "Saving to: ‘langchainwikiguide/233343.html’\n",
      "\n",
      "     0K .......... .......... .......... .......... .......... 12% 6.03M 0s\n",
      "    50K .......... .......... .......... .......... .......... 24% 6.21M 0s\n",
      "   100K .......... .......... .......... .......... .......... 36%  174M 0s\n",
      "   150K .......... .......... .......... .......... .......... 48% 44.8M 0s\n",
      "   200K .......... .......... .......... .......... .......... 60% 7.83M 0s\n",
      "   250K .......... .......... .......... .......... .......... 72% 68.7M 0s\n",
      "   300K .......... .......... .......... .......... .......... 85% 37.6M 0s\n",
      "   350K .......... .......... .......... .......... .......... 97% 45.9M 0s\n",
      "   400K .......... .                                          100%  229K=0.03s\n",
      "\n",
      "2024-08-25 23:24:40 (15.1 MB/s) - ‘langchainwikiguide/233343.html’ saved [421303/421303]\n",
      "\n",
      "--2024-08-25 23:24:40--  https://wikidocs.net/233344\n",
      "Resolving wikidocs.net (wikidocs.net)... 15.165.86.219\n",
      "Connecting to wikidocs.net (wikidocs.net)|15.165.86.219|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 108554 (106K) [text/html]\n",
      "Saving to: ‘langchainwikiguide/233344.html’\n",
      "\n",
      "     0K .......... .......... .......... .......... .......... 47% 6.00M 0s\n",
      "    50K .......... .......... .......... .......... .......... 94% 5.36M 0s\n",
      "   100K ......                                                100%  120K=0.02s\n",
      "\n",
      "2024-08-25 23:24:40 (6.00 MB/s) - ‘langchainwikiguide/233344.html’ saved [108554/108554]\n",
      "\n",
      "--2024-08-25 23:24:40--  https://wikidocs.net/233345\n",
      "Resolving wikidocs.net (wikidocs.net)... 15.165.86.219\n",
      "Connecting to wikidocs.net (wikidocs.net)|15.165.86.219|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 114939 (112K) [text/html]\n",
      "Saving to: ‘langchainwikiguide/233345.html’\n",
      "\n",
      "     0K .......... .......... .......... .......... .......... 44% 6.36M 0s\n",
      "    50K .......... .......... .......... .......... .......... 89% 6.67M 0s\n",
      "   100K .......... ..                                         100%  184M=0.02s\n",
      "\n",
      "2024-08-25 23:24:40 (7.27 MB/s) - ‘langchainwikiguide/233345.html’ saved [114939/114939]\n",
      "\n",
      "--2024-08-25 23:24:40--  https://wikidocs.net/233346\n",
      "Resolving wikidocs.net (wikidocs.net)... 15.165.86.219\n",
      "Connecting to wikidocs.net (wikidocs.net)|15.165.86.219|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 106310 (104K) [text/html]\n",
      "Saving to: ‘langchainwikiguide/233346.html’\n",
      "\n",
      "     0K .......... .......... .......... .......... .......... 48% 7.00M 0s\n",
      "    50K .......... .......... .......... .......... .......... 96% 8.91M 0s\n",
      "   100K ...                                                   100% 76.4K=0.01s\n",
      "\n",
      "2024-08-25 23:24:41 (8.14 MB/s) - ‘langchainwikiguide/233346.html’ saved [106310/106310]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "url_to_filename_map = {}\n",
    "wget_path=\"/opt/homebrew/bin/wget\"\n",
    "with open(\"langchainwikiurl.txt\", \"r\") as file:\n",
    "    urls = [url.strip() for url in file.readlines()]\n",
    " \n",
    "folder_path = \"langchainwikiguide\"\n",
    " \n",
    "if not os.path.exists(folder_path):\n",
    "    os.makedirs(folder_path)\n",
    "\n",
    "for url in urls:\n",
    "    filename = url.split(\"/\")[-1] + \".html\"\n",
    "    file_path = os.path.join(folder_path, filename)\n",
    "    subprocess.run([wget_path, \"-O\", file_path, url], check=True)\n",
    "    url_to_filename_map[url] = filename\n",
    " \n",
    "with open(\"url_to_filename_map.json\", \"w\") as map_file:\n",
    "    json.dump(url_to_filename_map, map_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 보안 에러 나는 경우 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 7/7 [00:01<00:00,  4.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download complete. Mapping saved to url_to_filename_map.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "\n",
    "url_to_filename_map = {}\n",
    "folder_path = \"langchainwikiguide\"\n",
    "\n",
    "with open(\"langchainwikiurl.txt\", \"r\") as file:\n",
    "    urls = [url.strip() for url in file.readlines()]\n",
    "\n",
    "if not os.path.exists(folder_path):\n",
    "    os.makedirs(folder_path)\n",
    "\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
    "}\n",
    "\n",
    "for url in tqdm(urls, desc=\"Downloading\"):\n",
    "    filename = url.split(\"/\")[-1] + \".html\"\n",
    "    file_path = os.path.join(folder_path, filename)\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(url, headers=headers)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        with open(file_path, \"wb\") as file:\n",
    "            file.write(response.content)\n",
    "        \n",
    "        url_to_filename_map[url] = filename\n",
    "\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"An error occurred while downloading {url}: {e}\")\n",
    "\n",
    "with open(\"url_to_filename_map.json\", \"w\") as map_file:\n",
    "    json.dump(url_to_filename_map, map_file, indent=4)\n",
    "\n",
    "print(\"Download complete. Mapping saved to url_to_filename_map.json\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Quote"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "txt 파일을 작성할 때는 한 줄에 하나의 URL을 작성해야 합니다. 이때, 각 URL은 줄바꿈으로 구분되어야 합니다.\n",
    "\n",
    "그리고 html 데이터를 로딩하기 전, robots.txt를 통해 데이터로 활용할 사이트의 접근 허용 여부를 확인해야합니다. NCP의 클로바스튜디오 사용 가이드의 경우 User-agent: * Allow:/ 로 접근이 가능합니다.\n",
    "\n",
    "예제에서 활용한 HTML은, 네이버클라우드 플랫폼(NCP)의 클로바스튜디오 사용 가이드중 CLOVA Studio(\"AI Services\" → \"CLOVA Studio\")와 관련된 모든 안내 페이지를 데이터로 활용했습니다.\n",
    "\n",
    "LangChain을 활용해 로딩한 html은, 파일을 저장한 디렉토리의 주소를 metadata의 'source'로 가져오게 됩니다. 추후 답변 제공시, 디렉토리 주소가 아닌 실제 URL을 제공하기 위해, LangChain이 로딩한 데이터를 수정해야합니다.\n",
    "\n",
    "html을 로딩할 때 파일명을 URL로 할 경우, /와 : 기호로 인해 파일명이 깨지게 됩니다. 따라서 원본 URL과 로딩한 HTML 파일을 쌍으로 mapping하고, 이 정보를 json 형식으로 \"url_to_filename_map\"에 저장합니다.\n",
    "\n",
    "이후, html 파일의 저장 경로가 담긴 'source'를, 이 json 파일과 연결해 실제 URL로 변환해줍니다. 위 코드는, json 파일을 저장하는 단계까지입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### LangChain 활용 HTML 로딩\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed langchainwikiguide/233341.html\n",
      "Processed langchainwikiguide/233346.html\n",
      "Processed langchainwikiguide/233344.html\n",
      "Processed langchainwikiguide/233345.html\n",
      "Processed langchainwikiguide/250954.html\n",
      "Processed langchainwikiguide/233342.html\n",
      "Processed langchainwikiguide/233343.html\n"
     ]
    }
   ],
   "source": [
    "# 폴더 이름에 맞게 수정\n",
    "html_files_dir = Path('langchainwikiguide')\n",
    " \n",
    "html_files = list(html_files_dir.glob(\"*.html\"))\n",
    " \n",
    "langchainwikidatas = []\n",
    " \n",
    "for html_file in html_files:\n",
    "    loader = UnstructuredHTMLLoader(str(html_file))\n",
    "    document_data = loader.load()\n",
    "    langchainwikidatas.append(document_data)\n",
    "    print(f\"Processed {html_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Quote"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "각 HTML에는 page_content에 모든 텍스트가, metadata의 'source'에는 저장 경로가 기록되어 있습니다. 위는, 로딩된 데이터 중 하나인 clovastudio-info.html의 형태입니다. metadata의 'source'에 실제 URL이 아닌 html 파일이 저장된 디렉토리 경로가 담긴 것을 확인할 수 있습니다. Mapping을 통해 이 'source'를 실제 URL로 바꾸는 작업을 다음 단계에 진행하게 됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Mapping 정보를 활용해 'source'를 실제 URL로 대체"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"url_to_filename_map.json\", \"r\") as map_file:\n",
    "    url_to_filename_map = json.load(map_file)\n",
    " \n",
    "filename_to_url_map = {v: k for k, v in url_to_filename_map.items()}\n",
    " \n",
    "# langchainwikidatas 리스트의 각 Document 객체의 'source' 수정\n",
    "for doc_list in langchainwikidatas:\n",
    "    for doc in doc_list:\n",
    "        extracted_filename = doc.metadata[\"source\"].split(\"/\")[-1]\n",
    "        if extracted_filename in filename_to_url_map:\n",
    "            doc.metadata[\"source\"] = filename_to_url_map[extracted_filename]\n",
    "        else:\n",
    "            print(f\"Warning: {extracted_filename}에 해당하는 URL을 찾을 수 없습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이중 리스트를 풀어서 하나의 리스트로 만드는 작업\n",
    "langchainwiki_flattened = [item for sublist in langchainwikidatas for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content=\"<랭체인LangChain 노트> - LangChain 한국어 튜토리얼🇰🇷 CH01 LangChain 시작하기 01. OpenAI API 키 발급 및 테스트 02. LangSmith 추적 설정 03. OpenAI API 사용(GPT-4o 멀티모달) 04. LangChain Expression Language(LCEL) 05. LCEL 인터페이스 06. Runnable CH02 프롬프트(Prompt) 01. 프롬프트(Prompt) 02. 퓨샷 프롬프트(FewShotPromptTemplate) 03. LangChain Hub 04. 개인화된 프롬프트(Hub에 업로드) CH03 출력 파서(Output Parsers) 01. Pydantic 출력 파서(PydanticOutputParser) 02. 콤마 구분자 출력 파서(CommaSeparatedListOutputParser) 03. 구조화된 출력 파서(StructuredOuputParser) 04. JSON 출력 파서(JsonOutputParser) 05. 데이터프레임 출력 파서(PandasDataFrameOutputParser) 06. 날짜 형식 출력 파서(DatetimeOutputParser) 07. 열거형 출력 파서(EnumOutputParser) 08. 출력 수정 파서(OutputFixingParser) CH04 모델(Model) 01. 다양한 LLM 모델 활용 02. 캐싱(Cache) 03. 모델 직렬화(Serialization) - 저장 및 불러오기 04. 토큰 사용량 확인 05. 구글 생성 AI(Google Generative AI) 06. 허깅페이스 엔드포인트(HuggingFace Endpoints) 07. 허깅페이스 로컬(HuggingFace Local) 08. 허깅페이스 파이프라인(HuggingFace Pipeline) 09. 올라마(Ollama) 10. GPT4ALL CH05 메모리(Memory) 01. 대화 버퍼 메모리(ConversationBufferMemory) 02. 대화 버퍼 윈도우 메모리(ConversationBufferWindowMemory) 03. 대화 토큰 버퍼 메모리(ConversationTokenBufferMemory) 04. 대화 엔티티 메모리(ConversationEntityMemory) 05. 대화 지식그래프 메모리(ConversationKGMemory) 06. 대화 요약 메모리(ConversationSummaryMemory) 07. 벡터저장소 검색 메모리(VectorStoreRetrieverMemory) 08. LCEL Chain 에 메모리 추가 09. SQLite 에 대화내용 저장 10. RunnableWithMessageHistory에 ChatMessageHistory추가 CH06 문서 로더(Document Loader) 01. 도큐먼트(Document) 의 구조 02. PDF 03. 한글(HWP) 04. CSV 05. Excel 06. Word 07. PowerPoint 08. 웹 문서(WebBaseLoader) 09. 텍스트(TextLoader) 10. JSON 11. Arxiv 13. UpstageLayoutAnalysisLoader 14. LlamaParser CH07 텍스트 분할(Text Splitter) 01. 문자 텍스트 분할(CharacterTextSplitter) 02. 재귀적 문자 텍스트 분할(RecursiveCharacterTextSplitter) 03. 토큰 텍스트 분할(TokenTextSplitter) 04. 시멘틱 청커(SemanticChunker) 05. 코드 분할(Python, Markdown, JAVA, C++, C#, GO, JS, Latex 등) 06. 마크다운 헤더 텍스트 분할(MarkdownHeaderTextSplitter) 07. HTML 헤더 텍스트 분할(HTMLHeaderTextSplitter) 08. 재귀적 JSON 분할(RecursiveJsonSplitter) CH08 임베딩(Embedding) 01. OpenAIEmbeddings 02. 캐시 임베딩(CacheBackedEmbeddings) 03. 허깅페이스 임베딩(HuggingFace Embeddings) 04. UpstageEmbeddings 05. OllamaEmbeddings 06. GPT4ALL 임베딩 07. Llama CPP 임베딩 CH09 벡터저장소(VectorStore) 01. Chroma 02. FAISS 03. Pinecone CH10 검색기(Retriever) 01. 벡터저장소 지원 검색기(VectorStore-backed Retriever) 02. 문맥 압축 검색기(ContextualCompressionRetriever) 03. 앙상블 검색기(EnsembleRetriever) 04. 긴 문맥 재정렬(LongContextReorder) 05. 상위 문서 검색기(ParentDocumentRetriever) 06. 다중 쿼리 검색기(MultiQueryRetriever) 07. 다중 벡터저장소 검색기(MultiVectorRetriever) 08. 셀프 쿼리 검색기(SelfQueryRetriever) 09. 시간 가중 벡터저장소 검색기(TimeWeightedVectorStoreRetriever) 10. 한글 형태소 분석기(Kiwi, Kkma, Okt) + BM25 검색기 CH11 리랭커(Reranker) 01. Cross Encoder Reranker 02. Cohere Reranker 03. Jina Reranker 04. FlashRank Reranker CH12 Retrieval Augmented Generation(RAG) 01. PDF 문서 기반 QA(Question-Answer) 02. 네이버 뉴스기사 QA(Question-Answer) 03. RAG 의 기능별 다양한 모듈 활용기 04. RAPTOR: 긴 문맥 요약(Long Context Summary) 05. 대화내용을 기억하는 RAG 체인 CH13 LangChain Expression Language(LCEL) 01. RunnablePassthrough: 데이터 전달 02. Runnable 구조(그래프) 확인 03. RunnableLambda: 사용자 정의 함수 04. RunnableBranch: 라우팅(Routing) 05. RunnableParallel: 병렬 처리 06. configurable_fields, configurable_alternatives 07. @chain 데코레이터로 Runnable 생성 08. RunnableWithMessageHistory 09. 사용자 정의 제네레이터(generator) 10. Runtime Arguments 바인딩 11. 폴백(fallback) 모델 지정 CH14 체인(Chains) 01. 문서 요약 02. SQL CH15 에이전트(Agent) 01. Agent 사용법 톺아보기 02. 도구를 활용한 토론 에이전트(Two Agent Debates with Tools) CH16 파인튜닝(Fine Tuning) CH17 LangGraph 01. Chain of Table for Multiple Tables\\n\\nPublished with WikiDocs\\n\\n<랭체인LangChain 노트> - Lang…\\n\\nCH01 LangChain 시작하기\\n\\n위키독스\\n\\nCH01 LangChain 시작하기\\n\\n🦜️🔗 랭체인 LangChain\\n\\nLangChain 은 언어 모델을 활용해 다양한 애플리케이션을 개발할 수 있는 프레임워크를 말합니다. 이 프레임워크를 통해 언어 모델은 다음과 같은 기능을 수행할 수 있게 됩니다.\\n\\n문맥을 인식하는 기능: LangChain은 언어 모델을 다양한 문맥 소스와 연결합니다. 여기에는 프롬프트 지시사항, 소수의 예시, 응답에 근거한 내용 등이 포함됩니다. 이를 통해 언어 모델은 제공된 정보를 기반으로 더 정확하고 관련성 높은 답변을 생성할 수 있습니다.\\n\\n추론하는 기능: 또한, 언어 모델은 주어진 문맥을 바탕으로 어떠한 답변을 제공하거나, 어떤 조치를 취해야 할지를 스스로 추론할 수 있습니다. 이는 언어 모델이 단순히 정보를 재생산하는 것을 넘어서, 주어진 상황을 분석하고 적절한 해결책을 제시할 수 있음을 의미합니다.\\n\\nLangChain 을 활용하면 이전에 언급한 기능을 바탕으로 검색 증강 생성(RAG) 어플리케이션 제작, 구조화된 데이터 분석, 챗봇 등을 만들 수 있습니다.\\n\\n더 많은 예제는 유튜브 채널 테디노트 에서 확인하실 수 있습니다.\\n\\n설치\\n\\n권장하는 파이썬 버전은 3.11 버전입니다.\\n\\npip 를 이용한 설치\\n\\npip install -r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt\\n\\n최소한의 기능만 설치하기 위한 mini 버전 (일부 패키지만 설치하는 경우)\\n\\npip install -r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements-mini.txt\\n\\n구성\\n\\n이 프레임워크는 여러 부분으로 구성되어 있습니다.\\n\\nLangChain 라이브러리: Python 및 JavaScript 라이브러리. 다양한 컴포넌트의 인터페이스와 통합, 이러한 컴포넌트를 체인과 에이전트로 결합하는 기본 런타임, 그리고 즉시 사용 가능한 체인과 에이전트의 구현을 포함합니다.\\n\\nLangChain 템플릿: 다양한 작업을 위한 쉽게 배포할 수 있는 참조 아키텍처 모음입니다.\\n\\nLangServe: LangChain 체인을 REST API로 배포하기 위한 라이브러리입니다.\\n\\nLangSmith: 어떤 LLM 프레임워크에도 구축된 체인을 디버그, 테스트, 평가, 모니터링할 수 있게 해주며 LangChain과 원활하게 통합되는 개발자 플랫폼입니다.\\n\\nLangGraph: LLM을 사용한 상태유지가 가능한 다중 액터 애플리케이션을 구축하기 위한 라이브러리로, LangChain 위에 구축되었으며 LangChain과 함께 사용하도록 설계되었습니다. 여러 계산 단계에서 다중 체인(또는 액터)을 순환 방식으로 조정할 수 있는 능력을 LangChain 표현 언어에 추가합니다.\\n\\n개발 용이성✨\\n\\n컴포넌트의 조립 및 통합 🔧\\n\\nLangChain은 언어 모델과의 작업을 위한 조립 가능한 도구 및 통합을 제공합니다.\\n\\n컴포넌트는 모듈식으로 설계되어, 사용하기 쉽습니다. 이는 개발자가 LangChain 프레임워크를 자유롭게 활용할 수 있게 해줍니다.\\n\\n즉시 사용 가능한 체인 🚀\\n\\n고수준 작업을 수행하기 위한 컴포넌트의 내장 조합을 제공합니다.\\n\\n이러한 체인은 개발 과정을 간소화하고 속도를 높여줍니다.\\n\\n주요 모듈 📌\\n\\n모델 I/O 📃\\n\\n프롬프트 관리, 최적화 및 LLM과의 일반적인 인터페이스와 작업을 위한 유틸리티를 포함합니다.\\n\\n검색 📚\\n\\n'데이터 강화 생성'에 초점을 맞춘 이 모듈은 생성 단계에서 필요한 데이터를 외부 데이터 소스에서 가져오는 작업을 담당합니다.\\n\\n에이전트 🤖\\n\\n언어 모델이 어떤 조치를 취할지 결정하고, 해당 조치를 실행하며, 관찰하고, 필요한 경우 반복하는 과정을 포함합니다.\\n\\nLangChain을 활용하면, 언어 모델 기반 애플리케이션의 개발을 보다 쉽게 시작할 수 있으며, 필요에 맞게 기능을 맞춤 설정하고, 다양한 데이터 소스와 통합하여 복잡한 작업을 처리할 수 있게 됩니다.\\n\\n마지막 편집일시 : 2024년 7월 16일 2:40 오전\\n\\n댓글 0 피드백\\n\\n※ 댓글 작성은 로그인이 필요합니다. (또는 피드백을 이용해 주세요.)\\n\\n이전글 : <랭체인LangChain 노트> - LangChain 한국어 튜토리얼🇰🇷\\n\\n다음글 : 01. OpenAI API 키 발급 및 테스트\\n\\n책갈피\\n\\n이 페이지에 대한 피드백을 남겨주세요\\n\\n댓글을 신고합니다.\", metadata={'source': 'https://wikidocs.net/233341'}),\n",
       " Document(page_content='<랭체인LangChain 노트> - LangChain 한국어 튜토리얼🇰🇷 CH01 LangChain 시작하기 01. OpenAI API 키 발급 및 테스트 02. LangSmith 추적 설정 03. OpenAI API 사용(GPT-4o 멀티모달) 04. LangChain Expression Language(LCEL) 05. LCEL 인터페이스 06. Runnable CH02 프롬프트(Prompt) 01. 프롬프트(Prompt) 02. 퓨샷 프롬프트(FewShotPromptTemplate) 03. LangChain Hub 04. 개인화된 프롬프트(Hub에 업로드) CH03 출력 파서(Output Parsers) 01. Pydantic 출력 파서(PydanticOutputParser) 02. 콤마 구분자 출력 파서(CommaSeparatedListOutputParser) 03. 구조화된 출력 파서(StructuredOuputParser) 04. JSON 출력 파서(JsonOutputParser) 05. 데이터프레임 출력 파서(PandasDataFrameOutputParser) 06. 날짜 형식 출력 파서(DatetimeOutputParser) 07. 열거형 출력 파서(EnumOutputParser) 08. 출력 수정 파서(OutputFixingParser) CH04 모델(Model) 01. 다양한 LLM 모델 활용 02. 캐싱(Cache) 03. 모델 직렬화(Serialization) - 저장 및 불러오기 04. 토큰 사용량 확인 05. 구글 생성 AI(Google Generative AI) 06. 허깅페이스 엔드포인트(HuggingFace Endpoints) 07. 허깅페이스 로컬(HuggingFace Local) 08. 허깅페이스 파이프라인(HuggingFace Pipeline) 09. 올라마(Ollama) 10. GPT4ALL CH05 메모리(Memory) 01. 대화 버퍼 메모리(ConversationBufferMemory) 02. 대화 버퍼 윈도우 메모리(ConversationBufferWindowMemory) 03. 대화 토큰 버퍼 메모리(ConversationTokenBufferMemory) 04. 대화 엔티티 메모리(ConversationEntityMemory) 05. 대화 지식그래프 메모리(ConversationKGMemory) 06. 대화 요약 메모리(ConversationSummaryMemory) 07. 벡터저장소 검색 메모리(VectorStoreRetrieverMemory) 08. LCEL Chain 에 메모리 추가 09. SQLite 에 대화내용 저장 10. RunnableWithMessageHistory에 ChatMessageHistory추가 CH06 문서 로더(Document Loader) 01. 도큐먼트(Document) 의 구조 02. PDF 03. 한글(HWP) 04. CSV 05. Excel 06. Word 07. PowerPoint 08. 웹 문서(WebBaseLoader) 09. 텍스트(TextLoader) 10. JSON 11. Arxiv 13. UpstageLayoutAnalysisLoader 14. LlamaParser CH07 텍스트 분할(Text Splitter) 01. 문자 텍스트 분할(CharacterTextSplitter) 02. 재귀적 문자 텍스트 분할(RecursiveCharacterTextSplitter) 03. 토큰 텍스트 분할(TokenTextSplitter) 04. 시멘틱 청커(SemanticChunker) 05. 코드 분할(Python, Markdown, JAVA, C++, C#, GO, JS, Latex 등) 06. 마크다운 헤더 텍스트 분할(MarkdownHeaderTextSplitter) 07. HTML 헤더 텍스트 분할(HTMLHeaderTextSplitter) 08. 재귀적 JSON 분할(RecursiveJsonSplitter) CH08 임베딩(Embedding) 01. OpenAIEmbeddings 02. 캐시 임베딩(CacheBackedEmbeddings) 03. 허깅페이스 임베딩(HuggingFace Embeddings) 04. UpstageEmbeddings 05. OllamaEmbeddings 06. GPT4ALL 임베딩 07. Llama CPP 임베딩 CH09 벡터저장소(VectorStore) 01. Chroma 02. FAISS 03. Pinecone CH10 검색기(Retriever) 01. 벡터저장소 지원 검색기(VectorStore-backed Retriever) 02. 문맥 압축 검색기(ContextualCompressionRetriever) 03. 앙상블 검색기(EnsembleRetriever) 04. 긴 문맥 재정렬(LongContextReorder) 05. 상위 문서 검색기(ParentDocumentRetriever) 06. 다중 쿼리 검색기(MultiQueryRetriever) 07. 다중 벡터저장소 검색기(MultiVectorRetriever) 08. 셀프 쿼리 검색기(SelfQueryRetriever) 09. 시간 가중 벡터저장소 검색기(TimeWeightedVectorStoreRetriever) 10. 한글 형태소 분석기(Kiwi, Kkma, Okt) + BM25 검색기 CH11 리랭커(Reranker) 01. Cross Encoder Reranker 02. Cohere Reranker 03. Jina Reranker 04. FlashRank Reranker CH12 Retrieval Augmented Generation(RAG) 01. PDF 문서 기반 QA(Question-Answer) 02. 네이버 뉴스기사 QA(Question-Answer) 03. RAG 의 기능별 다양한 모듈 활용기 04. RAPTOR: 긴 문맥 요약(Long Context Summary) 05. 대화내용을 기억하는 RAG 체인 CH13 LangChain Expression Language(LCEL) 01. RunnablePassthrough: 데이터 전달 02. Runnable 구조(그래프) 확인 03. RunnableLambda: 사용자 정의 함수 04. RunnableBranch: 라우팅(Routing) 05. RunnableParallel: 병렬 처리 06. configurable_fields, configurable_alternatives 07. @chain 데코레이터로 Runnable 생성 08. RunnableWithMessageHistory 09. 사용자 정의 제네레이터(generator) 10. Runtime Arguments 바인딩 11. 폴백(fallback) 모델 지정 CH14 체인(Chains) 01. 문서 요약 02. SQL CH15 에이전트(Agent) 01. Agent 사용법 톺아보기 02. 도구를 활용한 토론 에이전트(Two Agent Debates with Tools) CH16 파인튜닝(Fine Tuning) CH17 LangGraph 01. Chain of Table for Multiple Tables\\n\\nPublished with WikiDocs\\n\\n<랭체인LangChain 노트> - Lang…\\n\\nCH01 LangChain 시작하기\\n\\n06. Runnable\\n\\n위키독스\\n\\n06. Runnable\\n\\n# .env 파일을 읽어서 환경변수로 설정\\nfrom dotenv import load_dotenv\\n\\n# 토큰 정보로드\\nload_dotenv()\\n\\nTrue\\n\\n# LangSmith 추적을 설정합니다. https://smith.langchain.com\\n# !pip install -qU langchain-teddynote\\nfrom langchain_teddynote import logging\\n\\n# 프로젝트 이름을 입력합니다.\\nlogging.langsmith(\"CH01-Basic\")\\n\\nLangSmith 추적을 시작합니다.\\n[프로젝트명]\\nCH01-Basic\\n\\n데이터를 효과적으로 전달하는 방법\\n\\nRunnablePassthrough 는 입력을 변경하지 않거나 추가 키를 더하여 전달할 수 있습니다.\\n\\nRunnablePassthrough() 가 단독으로 호출되면, 단순히 입력을 받아 그대로 전달합니다.\\n\\nRunnablePassthrough.assign(...) 방식으로 호출되면, 입력을 받아 assign 함수에 전달된 추가 인수를 추가합니다.\\n\\nRunnablePassthrough\\n\\nfrom langchain_core.prompts import PromptTemplate\\nfrom langchain_openai import ChatOpenAI\\n\\n\\n# prompt 와 llm 을 생성합니다.\\nprompt = PromptTemplate.from_template(\"{num} 의 10배는?\")\\nllm = ChatOpenAI(temperature=0)\\n\\n# chain 을 생성합니다.\\nchain = prompt | llm\\n\\nchain 을 invoke() 하여 실행할 때는 입력 데이터의 타입이 딕셔너리여야 합니다.\\n\\n# chain 을 실행합니다.\\nchain.invoke({\"num\": 5})\\n\\nAIMessage(content=\\'50입니다.\\', response_metadata={\\'token_usage\\': {\\'completion_tokens\\': 3, \\'prompt_tokens\\': 16, \\'total_tokens\\': 19}, \\'model_name\\': \\'gpt-3.5-turbo\\', \\'system_fingerprint\\': None, \\'finish_reason\\': \\'stop\\', \\'logprobs\\': None}, id=\\'run-29242a8b-01c0-41ad-8f5b-7613e6876dc5-0\\', usage_metadata={\\'input_tokens\\': 16, \\'output_tokens\\': 3, \\'total_tokens\\': 19})\\n\\n하지만, langchain 라이브러리가 업데이트 되면서 1개의 변수만 템플릿에 포함하고 있다면, 값만 전달하는 것도 가능합니다.\\n\\n# chain 을 실행합니다.\\nchain.invoke(5)\\n\\nAIMessage(content=\\'50\\', response_metadata={\\'token_usage\\': {\\'completion_tokens\\': 1, \\'prompt_tokens\\': 16, \\'total_tokens\\': 17}, \\'model_name\\': \\'gpt-3.5-turbo\\', \\'system_fingerprint\\': None, \\'finish_reason\\': \\'stop\\', \\'logprobs\\': None}, id=\\'run-44f606db-2437-4d1f-9cee-ddfc69428745-0\\', usage_metadata={\\'input_tokens\\': 16, \\'output_tokens\\': 1, \\'total_tokens\\': 17})\\n\\n아래는 RunnablePassthrough 를 사용한 예제입니다.\\n\\nRunnablePassthrough 는 runnable 객체이며, runnable 객체는 invoke() 메소드를 사용하여 별도 실행이 가능합니다.\\n\\nfrom langchain_core.runnables import RunnablePassthrough\\n\\n# runnable\\nRunnablePassthrough().invoke({\"num\": 10})\\n\\n{\\'num\\': 10}\\n\\n아래는 RunnablePassthrough 로 체인을 구성하는 예제입니다.\\n\\nrunnable_chain = {\"num\": RunnablePassthrough()} | prompt | ChatOpenAI()\\n\\n# dict 값이 RunnablePassthrough() 로 변경되었습니다.\\nrunnable_chain.invoke(10)\\n\\nAIMessage(content=\\'100입니다.\\', response_metadata={\\'token_usage\\': {\\'completion_tokens\\': 3, \\'prompt_tokens\\': 16, \\'total_tokens\\': 19}, \\'model_name\\': \\'gpt-3.5-turbo\\', \\'system_fingerprint\\': None, \\'finish_reason\\': \\'stop\\', \\'logprobs\\': None}, id=\\'run-66270ca2-4d62-4c71-859b-de6318f29909-0\\', usage_metadata={\\'input_tokens\\': 16, \\'output_tokens\\': 3, \\'total_tokens\\': 19})\\n\\n다음은 RunnablePassthrough.assign() 을 사용하는 경우와 비교한 결과입니다.\\n\\nRunnablePassthrough().invoke({\"num\": 1})\\n\\n{\\'num\\': 1}\\n\\nRunnablePassthrough.assign()\\n\\n입력 값으로 들어온 값의 key/value 쌍과 새롭게 할당된 key/value 쌍을 합칩니다.\\n\\n# 입력 키: num, 할당(assign) 키: new_num\\n(RunnablePassthrough.assign(new_num=lambda x: x[\"num\"] * 3)).invoke({\"num\": 1})\\n\\n{\\'num\\': 1, \\'new_num\\': 3}\\n\\nRunnableParallel\\n\\nfrom langchain_core.runnables import RunnableParallel\\n\\n# RunnableParallel 인스턴스를 생성합니다. 이 인스턴스는 여러 Runnable 인스턴스를 병렬로 실행할 수 있습니다.\\nrunnable = RunnableParallel(\\n    # RunnablePassthrough 인스턴스를 \\'passed\\' 키워드 인자로 전달합니다. 이는 입력된 데이터를 그대로 통과시키는 역할을 합니다.\\n    passed=RunnablePassthrough(),\\n    # \\'extra\\' 키워드 인자로 RunnablePassthrough.assign을 사용하여, \\'mult\\' 람다 함수를 할당합니다. 이 함수는 입력된 딕셔너리의 \\'num\\' 키에 해당하는 값을 3배로 증가시킵니다.\\n    extra=RunnablePassthrough.assign(mult=lambda x: x[\"num\"] * 3),\\n    # \\'modified\\' 키워드 인자로 람다 함수를 전달합니다. 이 함수는 입력된 딕셔너리의 \\'num\\' 키에 해당하는 값에 1을 더합니다.\\n    modified=lambda x: x[\"num\"] + 1,\\n)\\n\\n# runnable 인스턴스에 {\\'num\\': 1} 딕셔너리를 입력으로 전달하여 invoke 메소드를 호출합니다.\\nrunnable.invoke({\"num\": 1})\\n\\n{\\'passed\\': {\\'num\\': 1}, \\'extra\\': {\\'num\\': 1, \\'mult\\': 3}, \\'modified\\': 2}\\n\\nChain 도 RunnableParallel 적용할 수 있습니다.\\n\\nchain1 = (\\n    {\"country\": RunnablePassthrough()}\\n    | PromptTemplate.from_template(\"{country} 의 수도는?\")\\n    | ChatOpenAI()\\n)\\nchain2 = (\\n    {\"country\": RunnablePassthrough()}\\n    | PromptTemplate.from_template(\"{country} 의 면적은?\")\\n    | ChatOpenAI()\\n)\\n\\ncombined_chain = RunnableParallel(capital=chain1, area=chain2)\\ncombined_chain.invoke(\"대한민국\")\\n\\n{\\'capital\\': AIMessage(content=\\'서울입니다.\\', response_metadata={\\'token_usage\\': {\\'completion_tokens\\': 5, \\'prompt_tokens\\': 19, \\'total_tokens\\': 24}, \\'model_name\\': \\'gpt-3.5-turbo\\', \\'system_fingerprint\\': None, \\'finish_reason\\': \\'stop\\', \\'logprobs\\': None}, id=\\'run-d9324c24-9670-4430-97d6-1272f5dbe0f2-0\\', usage_metadata={\\'input_tokens\\': 19, \\'output_tokens\\': 5, \\'total_tokens\\': 24}), \\'area\\': AIMessage(content=\\'대한민국의 총 면적은 약 100,363 km²입니다.\\', response_metadata={\\'token_usage\\': {\\'completion_tokens\\': 24, \\'prompt_tokens\\': 20, \\'total_tokens\\': 44}, \\'model_name\\': \\'gpt-3.5-turbo\\', \\'system_fingerprint\\': None, \\'finish_reason\\': \\'stop\\', \\'logprobs\\': None}, id=\\'run-f27442a3-fc9c-4d08-9fdf-189c1b4585c8-0\\', usage_metadata={\\'input_tokens\\': 20, \\'output_tokens\\': 24, \\'total_tokens\\': 44})}\\n\\nRunnableLambda\\n\\nRunnableLambda 를 사용하여 사용자 정의 함수를 맵핑할 수 있습니다.\\n\\nfrom langchain_core.output_parsers import StrOutputParser\\nfrom langchain_core.prompts import PromptTemplate\\nfrom langchain_openai import ChatOpenAI\\nfrom datetime import datetime\\n\\n\\ndef get_today(a):\\n    # 오늘 날짜를 가져오기\\n    return datetime.today().strftime(\"%b-%d\")\\n\\n\\n# 오늘 날짜를 출력\\nget_today(None)\\n\\n\\'Jun-19\\'\\n\\nfrom langchain_core.runnables import RunnableLambda, RunnablePassthrough\\n\\n# prompt 와 llm 을 생성합니다.\\nprompt = PromptTemplate.from_template(\\n    \"{today} 가 생일인 유명인 {n} 명을 나열하세요. 생년월일을 표기해 주세요.\"\\n)\\nllm = ChatOpenAI(temperature=0, model_name=\"gpt-4o\")\\n\\n# chain 을 생성합니다.\\nchain = (\\n    {\"today\": RunnableLambda(get_today), \"n\": RunnablePassthrough()}\\n    | prompt\\n    | llm\\n    | StrOutputParser()\\n)\\n\\n# 출력\\nprint(chain.invoke(3))\\n\\n다음은 6월 19일이 생일인 몇몇 유명인들입니다:\\n\\n1. 폴 도노반 (Paul Dano) - 1984년 6월 19일\\n2. 디렉 노박 조코비치 (Novak Djokovic) - 1987년 6월 19일\\n3. 필리페 쿠티뉴 (Philippe Coutinho) - 1992년 6월 19일\\n\\n이들은 각각 배우, 테니스 선수, 축구 선수로서 다양한 분야에서 활동하고 있습니다.\\n\\nitemgetter 를 사용하여 특정 키를 추출합니다.\\n\\nfrom operator import itemgetter\\n\\nfrom langchain_core.prompts import ChatPromptTemplate\\nfrom langchain_core.runnables import RunnableLambda\\nfrom langchain_openai import ChatOpenAI\\n\\n\\n# 문장의 길이를 반환하는 함수입니다.\\ndef length_function(text):\\n    return len(text)\\n\\n\\n# 두 문장의 길이를 곱한 값을 반환하는 함수입니다.\\ndef _multiple_length_function(text1, text2):\\n    return len(text1) * len(text2)\\n\\n\\n# _multiple_length_function 함수를 사용하여 두 문장의 길이를 곱한 값을 반환하는 함수입니다.\\ndef multiple_length_function(_dict):\\n    return _multiple_length_function(_dict[\"text1\"], _dict[\"text2\"])\\n\\n\\nprompt = ChatPromptTemplate.from_template(\"{a} + {b} 는 무엇인가요?\")\\nmodel = ChatOpenAI()\\n\\nchain1 = prompt | model\\n\\nchain = (\\n    {\\n        \"a\": itemgetter(\"word1\") | RunnableLambda(length_function),\\n        \"b\": {\"text1\": itemgetter(\"word1\"), \"text2\": itemgetter(\"word2\")}\\n        | RunnableLambda(multiple_length_function),\\n    }\\n    | prompt\\n    | model\\n)\\n\\nchain.invoke({\"word1\": \"hello\", \"word2\": \"world\"})\\n\\nAIMessage(content=\\'5 + 25 = 30입니다.\\', response_metadata={\\'token_usage\\': {\\'completion_tokens\\': 9, \\'prompt_tokens\\': 22, \\'total_tokens\\': 31}, \\'model_name\\': \\'gpt-3.5-turbo\\', \\'system_fingerprint\\': None, \\'finish_reason\\': \\'stop\\', \\'logprobs\\': None}, id=\\'run-5db9b475-09ee-4edb-af9d-b37b320bee1e-0\\', usage_metadata={\\'input_tokens\\': 22, \\'output_tokens\\': 9, \\'total_tokens\\': 31})\\n\\n마지막 편집일시 : 2024년 6월 19일 10:59 오후\\n\\n댓글 0 피드백\\n\\n※ 댓글 작성은 로그인이 필요합니다. (또는 피드백을 이용해 주세요.)\\n\\n이전글 : 05. LCEL 인터페이스\\n\\n다음글 : CH02 프롬프트(Prompt)\\n\\n책갈피\\n\\n이 페이지에 대한 피드백을 남겨주세요\\n\\n댓글을 신고합니다.', metadata={'source': 'https://wikidocs.net/233346'}),\n",
       " Document(page_content='<랭체인LangChain 노트> - LangChain 한국어 튜토리얼🇰🇷 CH01 LangChain 시작하기 01. OpenAI API 키 발급 및 테스트 02. LangSmith 추적 설정 03. OpenAI API 사용(GPT-4o 멀티모달) 04. LangChain Expression Language(LCEL) 05. LCEL 인터페이스 06. Runnable CH02 프롬프트(Prompt) 01. 프롬프트(Prompt) 02. 퓨샷 프롬프트(FewShotPromptTemplate) 03. LangChain Hub 04. 개인화된 프롬프트(Hub에 업로드) CH03 출력 파서(Output Parsers) 01. Pydantic 출력 파서(PydanticOutputParser) 02. 콤마 구분자 출력 파서(CommaSeparatedListOutputParser) 03. 구조화된 출력 파서(StructuredOuputParser) 04. JSON 출력 파서(JsonOutputParser) 05. 데이터프레임 출력 파서(PandasDataFrameOutputParser) 06. 날짜 형식 출력 파서(DatetimeOutputParser) 07. 열거형 출력 파서(EnumOutputParser) 08. 출력 수정 파서(OutputFixingParser) CH04 모델(Model) 01. 다양한 LLM 모델 활용 02. 캐싱(Cache) 03. 모델 직렬화(Serialization) - 저장 및 불러오기 04. 토큰 사용량 확인 05. 구글 생성 AI(Google Generative AI) 06. 허깅페이스 엔드포인트(HuggingFace Endpoints) 07. 허깅페이스 로컬(HuggingFace Local) 08. 허깅페이스 파이프라인(HuggingFace Pipeline) 09. 올라마(Ollama) 10. GPT4ALL CH05 메모리(Memory) 01. 대화 버퍼 메모리(ConversationBufferMemory) 02. 대화 버퍼 윈도우 메모리(ConversationBufferWindowMemory) 03. 대화 토큰 버퍼 메모리(ConversationTokenBufferMemory) 04. 대화 엔티티 메모리(ConversationEntityMemory) 05. 대화 지식그래프 메모리(ConversationKGMemory) 06. 대화 요약 메모리(ConversationSummaryMemory) 07. 벡터저장소 검색 메모리(VectorStoreRetrieverMemory) 08. LCEL Chain 에 메모리 추가 09. SQLite 에 대화내용 저장 10. RunnableWithMessageHistory에 ChatMessageHistory추가 CH06 문서 로더(Document Loader) 01. 도큐먼트(Document) 의 구조 02. PDF 03. 한글(HWP) 04. CSV 05. Excel 06. Word 07. PowerPoint 08. 웹 문서(WebBaseLoader) 09. 텍스트(TextLoader) 10. JSON 11. Arxiv 13. UpstageLayoutAnalysisLoader 14. LlamaParser CH07 텍스트 분할(Text Splitter) 01. 문자 텍스트 분할(CharacterTextSplitter) 02. 재귀적 문자 텍스트 분할(RecursiveCharacterTextSplitter) 03. 토큰 텍스트 분할(TokenTextSplitter) 04. 시멘틱 청커(SemanticChunker) 05. 코드 분할(Python, Markdown, JAVA, C++, C#, GO, JS, Latex 등) 06. 마크다운 헤더 텍스트 분할(MarkdownHeaderTextSplitter) 07. HTML 헤더 텍스트 분할(HTMLHeaderTextSplitter) 08. 재귀적 JSON 분할(RecursiveJsonSplitter) CH08 임베딩(Embedding) 01. OpenAIEmbeddings 02. 캐시 임베딩(CacheBackedEmbeddings) 03. 허깅페이스 임베딩(HuggingFace Embeddings) 04. UpstageEmbeddings 05. OllamaEmbeddings 06. GPT4ALL 임베딩 07. Llama CPP 임베딩 CH09 벡터저장소(VectorStore) 01. Chroma 02. FAISS 03. Pinecone CH10 검색기(Retriever) 01. 벡터저장소 지원 검색기(VectorStore-backed Retriever) 02. 문맥 압축 검색기(ContextualCompressionRetriever) 03. 앙상블 검색기(EnsembleRetriever) 04. 긴 문맥 재정렬(LongContextReorder) 05. 상위 문서 검색기(ParentDocumentRetriever) 06. 다중 쿼리 검색기(MultiQueryRetriever) 07. 다중 벡터저장소 검색기(MultiVectorRetriever) 08. 셀프 쿼리 검색기(SelfQueryRetriever) 09. 시간 가중 벡터저장소 검색기(TimeWeightedVectorStoreRetriever) 10. 한글 형태소 분석기(Kiwi, Kkma, Okt) + BM25 검색기 CH11 리랭커(Reranker) 01. Cross Encoder Reranker 02. Cohere Reranker 03. Jina Reranker 04. FlashRank Reranker CH12 Retrieval Augmented Generation(RAG) 01. PDF 문서 기반 QA(Question-Answer) 02. 네이버 뉴스기사 QA(Question-Answer) 03. RAG 의 기능별 다양한 모듈 활용기 04. RAPTOR: 긴 문맥 요약(Long Context Summary) 05. 대화내용을 기억하는 RAG 체인 CH13 LangChain Expression Language(LCEL) 01. RunnablePassthrough: 데이터 전달 02. Runnable 구조(그래프) 확인 03. RunnableLambda: 사용자 정의 함수 04. RunnableBranch: 라우팅(Routing) 05. RunnableParallel: 병렬 처리 06. configurable_fields, configurable_alternatives 07. @chain 데코레이터로 Runnable 생성 08. RunnableWithMessageHistory 09. 사용자 정의 제네레이터(generator) 10. Runtime Arguments 바인딩 11. 폴백(fallback) 모델 지정 CH14 체인(Chains) 01. 문서 요약 02. SQL CH15 에이전트(Agent) 01. Agent 사용법 톺아보기 02. 도구를 활용한 토론 에이전트(Two Agent Debates with Tools) CH16 파인튜닝(Fine Tuning) CH17 LangGraph 01. Chain of Table for Multiple Tables\\n\\nPublished with WikiDocs\\n\\n<랭체인LangChain 노트> - Lang…\\n\\nCH01 LangChain 시작하기\\n\\n04. LangChain Expression…\\n\\n위키독스\\n\\n04. LangChain Expression Language(LCEL)\\n\\n기본 예시: 프롬프트 + 모델 + 출력 파서\\n\\n가장 기본적이고 일반적인 사용 사례는 prompt 템플릿과 모델을 함께 연결하는 것입니다. 이것이 어떻게 작동하는지 보기 위해, 각 나라별 수도를 물어보는 Chain을 생성해 보겠습니다.\\n\\n# API KEY를 환경변수로 관리하기 위한 설정 파일\\nfrom dotenv import load_dotenv\\n\\n# API KEY 정보로드\\nload_dotenv()\\n\\nTrue\\n\\n# LangSmith 추적을 설정합니다. https://smith.langchain.com\\n# !pip install -qU langchain-teddynote\\nfrom langchain_teddynote import logging\\n\\n# 프로젝트 이름을 입력합니다.\\nlogging.langsmith(\"CH01-Basic\")\\n\\nLangSmith 추적을 시작합니다.\\n[프로젝트명]\\nCH01-Basic\\n\\n프롬프트 템플릿의 활용\\n\\nPromptTemplate\\n\\n사용자의 입력 변수를 사용하여 완전한 프롬프트 문자열을 만드는 데 사용되는 템플릿입니다\\n\\n사용법\\n\\ntemplate: 템플릿 문자열입니다. 이 문자열 내에서 중괄호 {}는 변수를 나타냅니다.\\n\\ninput_variables: 중괄호 안에 들어갈 변수의 이름을 리스트로 정의합니다.\\n\\ninput_variables\\n\\ninput_variables는 PromptTemplate에서 사용되는 변수의 이름을 정의하는 리스트입니다.\\n\\nfrom langchain_teddynote.messages import stream_response  # 스트리밍 출력\\nfrom langchain_core.prompts import PromptTemplate\\n\\nfrom_template() 메소드를 사용하여 PromptTemplate 객체 생성\\n\\n# template 정의\\ntemplate = \"{country}의 수도는 어디인가요?\"\\n\\n# from_template 메소드를 이용하여 PromptTemplate 객체 생성\\nprompt_template = PromptTemplate.from_template(template)\\nprompt_template\\n\\nPromptTemplate(input_variables=[\\'country\\'], template=\\'{country}의 수도는 어디인가요?\\')\\n\\n# prompt 생성\\nprompt = prompt_template.format(country=\"대한민국\")\\nprompt\\n\\n\\'대한민국의 수도는 어디인가요?\\'\\n\\n# prompt 생성\\nprompt = prompt_template.format(country=\"미국\")\\nprompt\\n\\n\\'미국의 수도는 어디인가요?\\'\\n\\nfrom langchain_openai import ChatOpenAI\\n\\nmodel = ChatOpenAI(\\n    model=\"gpt-3.5-turbo\",\\n    max_tokens=2048,\\n    temperature=0.1,\\n)\\n\\nChain 생성\\n\\nLCEL(LangChain Expression Language)\\n\\n여기서 우리는 LCEL을 사용하여 다양한 구성 요소를 단일 체인으로 결합합니다\\n\\nchain = prompt | model | output_parser\\n\\n| 기호는 unix 파이프 연산자와 유사하며, 서로 다른 구성 요소를 연결하고 한 구성 요소의 출력을 다음 구성 요소의 입력으로 전달합니다.\\n\\n이 체인에서 사용자 입력은 프롬프트 템플릿으로 전달되고, 그런 다음 프롬프트 템플릿 출력은 모델로 전달됩니다. 각 구성 요소를 개별적으로 살펴보면 무슨 일이 일어나고 있는지 이해할 수 있습니다.\\n\\n# prompt 를 PromptTemplate 객체로 생성합니다.\\nprompt = PromptTemplate.from_template(\"{topic} 에 대해 쉽게 설명해주세요.\")\\n\\nmodel = ChatOpenAI()\\n\\nchain = prompt | model\\n\\ninvoke() 호출\\n\\npython 딕셔너리 형태로 입력값을 전달합니다.(키: 값)\\n\\ninvoke() 함수 호출 시, 입력값을 전달합니다.\\n\\n# input 딕셔너리에 주제를 \\'인공지능 모델의 학습 원리\\'으로 설정합니다.\\ninput = {\"topic\": \"인공지능 모델의 학습 원리\"}\\n\\n# prompt 객체와 model 객체를 파이프(|) 연산자로 연결하고 invoke 메서드를 사용하여 input을 전달합니다.\\n# 이를 통해 AI 모델이 생성한 메시지를 반환합니다.\\nchain.invoke(input)\\n\\nAIMessage(content=\\'인공지능 모델의 학습 원리는 데이터를 이용하여 패턴을 학습하는 것입니다. 모델은 입력 데이터를 받아들이고 내부적으로 가중치를 조정하여 원하는 결과를 출력합니다. 학습 과정에서 모델은 입력 데이터와 정답 데이터를 이용하여 오차를 계산하고 이 오차를 최소화하는 방향으로 가중치를 업데이트합니다. 이렇게 반복적으로 학습을 진행하면 모델은 입력 데이터로부터 패턴을 학습하여 정확한 결과를 예측하게 됩니다. 이러한 학습 원리를 통해 인공지능 모델은 데이터를 이용하여 스스로 학습하고 문제를 해결할 수 있습니다.\\', response_metadata={\\'token_usage\\': {\\'completion_tokens\\': 214, \\'prompt_tokens\\': 33, \\'total_tokens\\': 247}, \\'model_name\\': \\'gpt-3.5-turbo\\', \\'system_fingerprint\\': None, \\'finish_reason\\': \\'stop\\', \\'logprobs\\': None}, id=\\'run-7f8a08f4-51ba-4d14-b9d2-2e092be3e7aa-0\\', usage_metadata={\\'input_tokens\\': 33, \\'output_tokens\\': 214, \\'total_tokens\\': 247})\\n\\n아래는 스트리밍을 출력하는 예시 입니다.\\n\\n# 스트리밍 출력을 위한 요청\\nanswer = chain.stream(input)\\n# 스트리밍 출력\\nstream_response(answer)\\n\\n인공지능 모델의 학습 원리는 데이터를 입력으로 받아서 패턴을 학습하고 이를 기반으로 예측이나 분류를 수행하는 과정입니다. \\n\\n학습 과정은 크게 입력층, 은닉층, 출력층으로 구성된 인공신경망을 사용합니다. 입력층에서 데이터를 받아 은닉층을 거쳐 출력층으로 결과를 출력하는 구조입니다.\\n\\n이때, 모델은 주어진 데이터를 통해 가중치를 조정하고 오차를 최소화하는 방향으로 학습을 진행합니다. 이를 위해 주어진 데이터에 대해 예측을 수행하고 실제 값과 비교하여 오차를 계산한 후, 이 오차를 줄이기 위해 가중치를 업데이트합니다.\\n\\n이러한 반복적인 과정을 통해 모델은 데이터 간의 패턴을 학습하고 새로운 데이터에 대해 정확한 예측을 수행할 수 있게 됩니다. 이렇게 학습된 모델은 새로운 데이터에 대해 일반화된 예측을 할 수 있습니다.\\n\\n출력파서(Output Parser)\\n\\nfrom langchain_core.output_parsers import StrOutputParser\\n\\noutput_parser = StrOutputParser()\\n\\nChain 에 출력파서를 추가합니다.\\n\\n# 프롬프트, 모델, 출력 파서를 연결하여 처리 체인을 구성합니다.\\nchain = prompt | model | output_parser\\n\\n# chain 객체의 invoke 메서드를 사용하여 input을 전달합니다.\\ninput = {\"topic\": \"인공지능 모델의 학습 원리\"}\\nchain.invoke(input)\\n\\n\\'인공지능 모델의 학습 원리는 데이터를 입력으로 받아서 패턴을 학습하는 것입니다. 모델은 입력 데이터를 받아서 내부적으로 가중치를 조절하면서 원하는 결과를 출력하도록 학습됩니다. 이때, 모델은 입력 데이터와 출력 데이터 간의 관계를 학습하여 새로운 입력 데이터에 대한 출력을 예측할 수 있게 됩니다. 이 과정은 반복적으로 이루어지며, 모델은 학습을 통해 점차적으로 정확도를 향상시킵니다. 이러한 방식으로 인공지능 모델은 주어진 데이터를 기반으로 판단하고 예측하는 능력을 향상시킬 수 있습니다.\\'\\n\\n# 스트리밍 출력을 위한 요청\\nanswer = chain.stream(input)\\n# 스트리밍 출력\\nstream_response(answer)\\n\\n인공지능 모델의 학습 원리는 데이터를 이용해서 패턴을 학습하는 과정입니다. 먼저 모델은 입력 데이터를 받아서 처리하고, 이때 입력 데이터와 정답 데이터를 비교하여 오차를 계산합니다. 이 오차를 최소화하기 위해 모델은 가중치와 편향을 조정하면서 점차적으로 정확한 패턴을 학습해나갑니다. 이런 과정을 반복하여 모델이 데이터에 대해 정확한 예측을 할 수 있도록 학습시키는 것이 인공지능 모델의 핵심 원리입니다.\\n\\n템플릿을 변경하여 적용\\n\\n아래의 프롬프트 내용을 얼마든지 변경 하여 테스트 해볼 수 있습니다.\\n\\nmodel_name 역시 변경하여 테스트가 가능합니다.\\n\\ntemplate = \"\"\"\\n당신은 영어를 가르치는 10년차 영어 선생님입니다. 상황에 [FORMAT]에 영어 회화를 작성해 주세요.\\n\\n상황:\\n{question}\\n\\nFORMAT:\\n- 영어 회화:\\n- 한글 해석:\\n\"\"\"\\n\\n# 프롬프트 템플릿을 이용하여 프롬프트를 생성합니다.\\nprompt = PromptTemplate.from_template(template)\\n\\n# ChatOpenAI 챗모델을 초기화합니다.\\nmodel = ChatOpenAI(model_name=\"gpt-4-turbo\")\\n\\n# 문자열 출력 파서를 초기화합니다.\\noutput_parser = StrOutputParser()\\n\\n# 체인을 구성합니다.\\nchain = prompt | model | output_parser\\n\\n# 완성된 Chain을 실행하여 답변을 얻습니다.\\n# 스트리밍 출력을 위한 요청\\nanswer = chain.stream({\"question\": \"저는 식당에 가서 음식을 주문하고 싶어요\"})\\n# 스트리밍 출력\\nstream_response(answer)\\n\\n영어 회화:\\n- Hello, could I see the menu, please? \\n- I\\'d like to order the grilled salmon and a side of mashed potatoes.\\n- Could I have a glass of water as well?\\n- Thank you!\\n\\n한글 해석:\\n- 안녕하세요, 메뉴판 좀 볼 수 있을까요?\\n- 구운 연어와 매시드 포테이토를 주문하고 싶어요.\\n- 물 한 잔도 주실 수 있나요?\\n- 감사합니다!\\n\\n# 이번에는 question 을 \\'미국에서 피자 주문\\'으로 설정하여 실행합니다.\\n# 스트리밍 출력을 위한 요청\\nanswer = chain.stream({\"question\": \"미국에서 피자 주문\"})\\n# 스트리밍 출력\\nstream_response(answer)\\n\\n영어 회화:\\n- Employee: \"Hello, Tony\\'s Pizza. How can I help you?\"\\n- Customer: \"Hi, I\\'d like to place an order for delivery, please.\"\\n- Employee: \"Sure thing! What would you like to order?\"\\n- Customer: \"I\\'ll have a large pepperoni pizza with extra cheese and a side of garlic bread.\"\\n- Employee: \"Anything to drink?\"\\n- Customer: \"Yes, a 2-liter bottle of Coke, please.\"\\n- Employee: \"Alright, your total comes to $22.50. Can I have your delivery address?\"\\n- Customer: \"It\\'s 742 Evergreen Terrace.\"\\n- Employee: \"Thank you. Your order will be there in about 30-45 minutes. Is there anything else I can help you with?\"\\n- Customer: \"No, that\\'s everything. Thank you!\"\\n- Employee: \"Thank you for choosing Tony\\'s Pizza. Have a great day!\"\\n\\n한글 해석:\\n- 직원: \"안녕하세요, 토니의 피자입니다. 어떻게 도와드릴까요?\"\\n- 고객: \"안녕하세요, 배달 주문하고 싶은데요.\"\\n- 직원: \"네, 무엇을 주문하시겠어요?\"\\n- 고객: \"큰 사이즈의 페퍼로니 피자에 치즈 추가하고, 마늘빵 하나 주세요.\"\\n- 직원: \"음료는 드릴까요?\"\\n- 고객: \"네, 콜라 2리터 한 병 주세요.\"\\n- 직원: \"알겠습니다, 합계는 $22.50입니다. 배달 주소를 알려주시겠어요?\"\\n- 고객: \"742 에버그린 테라스입니다.\"\\n- 직원: \"감사합니다. 주문하신 음식은 대략 30-45분 내에 도착할 예정입니다. 다른 도움이 필요하신가요?\"\\n- 고객: \"아니요, 이게 다예요. 감사합니다!\"\\n- 직원: \"토니의 피자를 선택해주셔서 감사합니다. 좋은 하루 되세요!\"\\n\\n마지막 편집일시 : 2024년 6월 18일 1:20 오전\\n\\n댓글 0 피드백\\n\\n※ 댓글 작성은 로그인이 필요합니다. (또는 피드백을 이용해 주세요.)\\n\\n이전글 : 03. OpenAI API 사용(GPT-4o 멀티모달)\\n\\n다음글 : 05. LCEL 인터페이스\\n\\n책갈피\\n\\n이 페이지에 대한 피드백을 남겨주세요\\n\\n댓글을 신고합니다.', metadata={'source': 'https://wikidocs.net/233344'}),\n",
       " Document(page_content='<랭체인LangChain 노트> - LangChain 한국어 튜토리얼🇰🇷 CH01 LangChain 시작하기 01. OpenAI API 키 발급 및 테스트 02. LangSmith 추적 설정 03. OpenAI API 사용(GPT-4o 멀티모달) 04. LangChain Expression Language(LCEL) 05. LCEL 인터페이스 06. Runnable CH02 프롬프트(Prompt) 01. 프롬프트(Prompt) 02. 퓨샷 프롬프트(FewShotPromptTemplate) 03. LangChain Hub 04. 개인화된 프롬프트(Hub에 업로드) CH03 출력 파서(Output Parsers) 01. Pydantic 출력 파서(PydanticOutputParser) 02. 콤마 구분자 출력 파서(CommaSeparatedListOutputParser) 03. 구조화된 출력 파서(StructuredOuputParser) 04. JSON 출력 파서(JsonOutputParser) 05. 데이터프레임 출력 파서(PandasDataFrameOutputParser) 06. 날짜 형식 출력 파서(DatetimeOutputParser) 07. 열거형 출력 파서(EnumOutputParser) 08. 출력 수정 파서(OutputFixingParser) CH04 모델(Model) 01. 다양한 LLM 모델 활용 02. 캐싱(Cache) 03. 모델 직렬화(Serialization) - 저장 및 불러오기 04. 토큰 사용량 확인 05. 구글 생성 AI(Google Generative AI) 06. 허깅페이스 엔드포인트(HuggingFace Endpoints) 07. 허깅페이스 로컬(HuggingFace Local) 08. 허깅페이스 파이프라인(HuggingFace Pipeline) 09. 올라마(Ollama) 10. GPT4ALL CH05 메모리(Memory) 01. 대화 버퍼 메모리(ConversationBufferMemory) 02. 대화 버퍼 윈도우 메모리(ConversationBufferWindowMemory) 03. 대화 토큰 버퍼 메모리(ConversationTokenBufferMemory) 04. 대화 엔티티 메모리(ConversationEntityMemory) 05. 대화 지식그래프 메모리(ConversationKGMemory) 06. 대화 요약 메모리(ConversationSummaryMemory) 07. 벡터저장소 검색 메모리(VectorStoreRetrieverMemory) 08. LCEL Chain 에 메모리 추가 09. SQLite 에 대화내용 저장 10. RunnableWithMessageHistory에 ChatMessageHistory추가 CH06 문서 로더(Document Loader) 01. 도큐먼트(Document) 의 구조 02. PDF 03. 한글(HWP) 04. CSV 05. Excel 06. Word 07. PowerPoint 08. 웹 문서(WebBaseLoader) 09. 텍스트(TextLoader) 10. JSON 11. Arxiv 13. UpstageLayoutAnalysisLoader 14. LlamaParser CH07 텍스트 분할(Text Splitter) 01. 문자 텍스트 분할(CharacterTextSplitter) 02. 재귀적 문자 텍스트 분할(RecursiveCharacterTextSplitter) 03. 토큰 텍스트 분할(TokenTextSplitter) 04. 시멘틱 청커(SemanticChunker) 05. 코드 분할(Python, Markdown, JAVA, C++, C#, GO, JS, Latex 등) 06. 마크다운 헤더 텍스트 분할(MarkdownHeaderTextSplitter) 07. HTML 헤더 텍스트 분할(HTMLHeaderTextSplitter) 08. 재귀적 JSON 분할(RecursiveJsonSplitter) CH08 임베딩(Embedding) 01. OpenAIEmbeddings 02. 캐시 임베딩(CacheBackedEmbeddings) 03. 허깅페이스 임베딩(HuggingFace Embeddings) 04. UpstageEmbeddings 05. OllamaEmbeddings 06. GPT4ALL 임베딩 07. Llama CPP 임베딩 CH09 벡터저장소(VectorStore) 01. Chroma 02. FAISS 03. Pinecone CH10 검색기(Retriever) 01. 벡터저장소 지원 검색기(VectorStore-backed Retriever) 02. 문맥 압축 검색기(ContextualCompressionRetriever) 03. 앙상블 검색기(EnsembleRetriever) 04. 긴 문맥 재정렬(LongContextReorder) 05. 상위 문서 검색기(ParentDocumentRetriever) 06. 다중 쿼리 검색기(MultiQueryRetriever) 07. 다중 벡터저장소 검색기(MultiVectorRetriever) 08. 셀프 쿼리 검색기(SelfQueryRetriever) 09. 시간 가중 벡터저장소 검색기(TimeWeightedVectorStoreRetriever) 10. 한글 형태소 분석기(Kiwi, Kkma, Okt) + BM25 검색기 CH11 리랭커(Reranker) 01. Cross Encoder Reranker 02. Cohere Reranker 03. Jina Reranker 04. FlashRank Reranker CH12 Retrieval Augmented Generation(RAG) 01. PDF 문서 기반 QA(Question-Answer) 02. 네이버 뉴스기사 QA(Question-Answer) 03. RAG 의 기능별 다양한 모듈 활용기 04. RAPTOR: 긴 문맥 요약(Long Context Summary) 05. 대화내용을 기억하는 RAG 체인 CH13 LangChain Expression Language(LCEL) 01. RunnablePassthrough: 데이터 전달 02. Runnable 구조(그래프) 확인 03. RunnableLambda: 사용자 정의 함수 04. RunnableBranch: 라우팅(Routing) 05. RunnableParallel: 병렬 처리 06. configurable_fields, configurable_alternatives 07. @chain 데코레이터로 Runnable 생성 08. RunnableWithMessageHistory 09. 사용자 정의 제네레이터(generator) 10. Runtime Arguments 바인딩 11. 폴백(fallback) 모델 지정 CH14 체인(Chains) 01. 문서 요약 02. SQL CH15 에이전트(Agent) 01. Agent 사용법 톺아보기 02. 도구를 활용한 토론 에이전트(Two Agent Debates with Tools) CH16 파인튜닝(Fine Tuning) CH17 LangGraph 01. Chain of Table for Multiple Tables\\n\\nPublished with WikiDocs\\n\\n<랭체인LangChain 노트> - Lang…\\n\\nCH01 LangChain 시작하기\\n\\n05. LCEL 인터페이스\\n\\n위키독스\\n\\n05. LCEL 인터페이스\\n\\nLCEL 인터페이스\\n\\n사용자 정의 체인을 가능한 쉽게 만들 수 있도록, Runnable 프로토콜을 구현했습니다.\\n\\nRunnable 프로토콜은 대부분의 컴포넌트에 구현되어 있습니다.\\n\\n이는 표준 인터페이스로, 사용자 정의 체인을 정의하고 표준 방식으로 호출하는 것을 쉽게 만듭니다. 표준 인터페이스에는 다음이 포함됩니다.\\n\\nstream: 응답의 청크를 스트리밍합니다.\\n\\ninvoke: 입력에 대해 체인을 호출합니다.\\n\\nbatch: 입력 목록에 대해 체인을 호출합니다.\\n\\n비동기 메소드도 있습니다.\\n\\nastream: 비동기적으로 응답의 청크를 스트리밍합니다.\\n\\nainvoke: 비동기적으로 입력에 대해 체인을 호출합니다.\\n\\nabatch: 비동기적으로 입력 목록에 대해 체인을 호출합니다.\\n\\nastream_log: 최종 응답뿐만 아니라 발생하는 중간 단계를 스트리밍합니다.\\n\\n# API KEY를 환경변수로 관리하기 위한 설정 파일\\nfrom dotenv import load_dotenv\\n\\n# API KEY 정보로드\\nload_dotenv()\\n\\nTrue\\n\\n# LangSmith 추적을 설정합니다. https://smith.langchain.com\\nfrom langchain_teddynote import logging\\n\\n# 프로젝트 이름을 입력합니다.\\nlogging.langsmith(\"CH01-Basic\")\\n\\nLCEL 문법을 사용하여 chain 을 생성합니다.\\n\\nfrom langchain_openai import ChatOpenAI\\nfrom langchain_core.prompts import PromptTemplate\\nfrom langchain_core.output_parsers import StrOutputParser\\n\\n# ChatOpenAI 모델을 인스턴스화합니다.\\nmodel = ChatOpenAI()\\n# 주어진 토픽에 대한 농담을 요청하는 프롬프트 템플릿을 생성합니다.\\nprompt = PromptTemplate.from_template(\"{topic} 에 대하여 3문장으로 설명해줘.\")\\n# 프롬프트와 모델을 연결하여 대화 체인을 생성합니다.\\nchain = prompt | model | StrOutputParser()\\n\\nstream: 실시간 출력\\n\\n이 함수는 chain.stream 메서드를 사용하여 주어진 토픽에 대한 데이터 스트림을 생성하고, 이 스트림을 반복하여 각 데이터의 내용(content)을 즉시 출력합니다. end=\"\" 인자는 출력 후 줄바꿈을 하지 않도록 설정하며, flush=True 인자는 출력 버퍼를 즉시 비우도록 합니다.\\n\\n# chain.stream 메서드를 사용하여 \\'멀티모달\\' 토픽에 대한 스트림을 생성하고 반복합니다.\\nfor token in chain.stream({\"topic\": \"멀티모달\"}):\\n    # 스트림에서 받은 데이터의 내용을 출력합니다. 줄바꿈 없이 이어서 출력하고, 버퍼를 즉시 비웁니다.\\n    print(token, end=\"\", flush=True)\\n\\n멀티모달은 여러 가지 다른 형태의 커뮤니케이션 수단을 통해 정보를 전달하고 상호작용하는 기술을 의미합니다. 예를 들어 음성, 텍스트, 이미지, 동영상 등 다양한 매체를 활용하여 사용자와 상호작용할 수 있습니다. 멀티모달 기술은 사용자 경험을 향상시키고 정보 전달의 효율성을 높이는데 도움을 줄 수 있습니다.\\n\\ninvoke: 호출\\n\\nchain 객체의 invoke 메서드는 주제를 인자로 받아 해당 주제에 대한 처리를 수행합니다.\\n\\n# chain 객체의 invoke 메서드를 호출하고, \\'ChatGPT\\'라는 주제로 딕셔너리를 전달합니다.\\nchain.invoke({\"topic\": \"ChatGPT\"})\\n\\n\\'ChatGPT는 OpenAI에서 개발한 대화형 인공지능 모델로, 다양한 주제에 대한 대화를 자연스럽게 이어나갈 수 있습니다. 사용자들은 ChatGPT를 통해 질문에 답변을 받거나 대화를 이어가며 새로운 정보를 습득할 수 있습니다. 또한 ChatGPT는 사용자의 입력을 학습하여 점차적으로 더욱 유창하고 자연스러운 대화를 제공합니다.\\'\\n\\nbatch: 배치(단위 실행)\\n\\n함수 chain.batch는 여러 개의 딕셔너리를 포함하는 리스트를 인자로 받아, 각 딕셔너리에 있는 topic 키의 값을 사용하여 일괄 처리를 수행합니다.\\n\\n# 주어진 토픽 리스트를 batch 처리하는 함수 호출\\nchain.batch([{\"topic\": \"ChatGPT\"}, {\"topic\": \"Instagram\"}])\\n\\n[\\'ChatGPT는 인공지능 챗봇으로 자연어 처리 기술을 사용하여 대화를 수행합니다. 사용자들과 자연스럽게 상호작용하며 다양한 주제에 대해 대화할 수 있습니다. ChatGPT는 정보 제공, 질문 응답, 상담 및 엔터테인먼트 등 다양한 용도로 활용될 수 있습니다.\\', \\'Instagram은 사진과 동영상을 공유하고 다른 사람들과 소통하는 소셜 미디어 플랫폼이다. 해시태그를 통해 관심사나 주제별로 사진을 검색하고 팔로워들과 소통할 수 있다. 인기 있는 인플루언서나 브랜드가 활발하게 활동하는 플랫폼으로 세계적으로 인기가 높다.\\']\\n\\nmax_concurrency 매개변수를 사용하여 동시 요청 수를 설정할 수 있습니다\\n\\nconfig 딕셔너리는 max_concurrency 키를 통해 동시에 처리할 수 있는 최대 작업 수를 설정합니다. 여기서는 최대 3개의 작업을 동시에 처리하도록 설정되어 있습니다.\\n\\nchain.batch(\\n    [\\n        {\"topic\": \"ChatGPT\"},\\n        {\"topic\": \"Instagram\"},\\n        {\"topic\": \"멀티모달\"},\\n        {\"topic\": \"프로그래밍\"},\\n        {\"topic\": \"머신러닝\"},\\n    ],\\n    config={\"max_concurrency\": 3},\\n)\\n\\n[\\'ChatGPT는 인공지능 챗봇으로, 자연어 처리 기술을 사용하여 대화 상대와 상호작용합니다. 사용자의 질문에 응답하고 대화를 이어가며 다양한 주제에 대해 대화할 수 있습니다. ChatGPT는 사용자와 자연스럽게 대화를 나누는 데 도움을 줄 뿐만 아니라 정보를 제공하고 문제 해결을 돕기도 합니다.\\', \\'Instagram은 사진과 동영상을 공유하고 다른 사람들과 소통할 수 있는 소셜 미디어 플랫폼이다. 다양한 필터와 편집 기능을 제공하여 사용자가 쉽게 멋진 사진을 업로드할 수 있으며 해시태그를 통해 관심사에 맞는 콘텐츠를 찾을 수 있다. 인기 있는 인플루언서들의 활동과 광고가 많이 이루어지는 플랫폼이기도 하다.\\', \\'멀티모달은 여러 가지의 다른 형태의 정보를 함께 제공하거나 처리하는 기술이다. 이는 텍스트, 이미지, 음성, 비디오 등 여러 형태의 데이터를 통합하여 효과적으로 전달하고 상호작용할 수 있게 한다. 멀티모달은 사용자 경험을 향상시키고 정보를 보다 쉽게 이해하고 활용할 수 있도록 도와준다.\\', \\'프로그래밍은 컴퓨터에게 실행할 작업을 지시하는 일종의 커뮤니케이션 방법이다. 이를 위해 프로그래머가 사용하는 언어는 컴퓨터가 이해할 수 있는 형태여야 하며, 문법과 로직을 통해 원하는 결과를 얻을 수 있다. 프로그래밍을 통해 소프트웨어를 개발하고 문제를 해결하는 등 다양한 분야에서 활용할 수 있다.\\', \\'머신러닝은 컴퓨터 시스템이 데이터에서 학습하고 패턴을 발견하여 예측하거나 결정을 내리는 인공지능의 한 분야입니다. 이를 통해 컴퓨터는 사람의 개입 없이 스스로 학습하고 문제를 해결할 수 있습니다. 머신러닝은 이미지 및 음성 인식, 자율 주행 자동차, 헬스케어 등 다양한 분야에서 활용되고 있습니다.\\']\\n\\nasync stream: 비동기 스트림\\n\\n함수 chain.astream은 비동기 스트림을 생성하며, 주어진 토픽에 대한 메시지를 비동기적으로 처리합니다.\\n\\n비동기 for 루프(async for)를 사용하여 스트림에서 메시지를 순차적으로 받아오고, print 함수를 통해 메시지의 내용(s.content)을 즉시 출력합니다. end=\"\"는 출력 후 줄바꿈을 하지 않도록 설정하며, flush=True는 출력 버퍼를 강제로 비워 즉시 출력되도록 합니다.\\n\\n# 비동기 스트림을 사용하여 \\'YouTube\\' 토픽의 메시지를 처리합니다.\\nasync for token in chain.astream({\"topic\": \"YouTube\"}):\\n    # 메시지 내용을 출력합니다. 줄바꿈 없이 바로 출력하고 버퍼를 비웁니다.\\n    print(token, end=\"\", flush=True)\\n\\nYouTube 는 동영상을 공유하고 시청할 수 있는 온라인 동영상 플랫폼이다. 누구나 자신의 동영상을 업로드하여 다른 사람들과 공유할 수 있고, 영상 콘텐츠를 시청하며 다양한 정보나 즐길거리를 찾을 수 있다. 또한 유명한 크리에이터들의 영상을 통해 엔터테인먼트와 정보를 얻을 수 있다.\\n\\nasync invoke: 비동기 호출\\n\\nchain 객체의 ainvoke 메서드는 비동기적으로 주어진 인자를 사용하여 작업을 수행합니다. 여기서는 topic이라는 키와 NVDA(엔비디아의 티커) 라는 값을 가진 딕셔너리를 인자로 전달하고 있습니다. 이 메서드는 특정 토픽에 대한 처리를 비동기적으로 요청하는 데 사용될 수 있습니다.\\n\\n# 비동기 체인 객체의 \\'ainvoke\\' 메서드를 호출하여 \\'NVDA\\' 토픽을 처리합니다.\\nmy_process = chain.ainvoke({\"topic\": \"NVDA\"})\\n\\n# 비동기로 처리되는 프로세스가 완료될 때까지 기다립니다.\\nawait my_process\\n\\n\\'NVDA는 엔비디아의 주식 코드로, 미국의 반도체 기업인 엔비디아(NVIDIA)의 주식을 말합니다. 엔비디아는 그래픽 처리 유닛(GPU)을 전문으로 하는 기업으로, 인공지능, 가상현실, 자율주행차 등 다양한 분야에서 기술을 제공하고 있습니다. NVDA 주식은 기술 산업의 성장과 함께 높은 수익을 창출하고 있습니다.\\'\\n\\nasync batch: 비동기 배치\\n\\n함수 abatch는 비동기적으로 일련의 작업을 일괄 처리합니다.\\n\\n이 예시에서는 chain 객체의 abatch 메서드를 사용하여 topic 에 대한 작업을 비동기적으로 처리하고 있습니다.\\n\\nawait 키워드는 해당 비동기 작업이 완료될 때까지 기다리는 데 사용됩니다.\\n\\n# 주어진 토픽에 대해 비동기적으로 일괄 처리를 수행합니다.\\nmy_abatch_process = chain.abatch(\\n    [{\"topic\": \"YouTube\"}, {\"topic\": \"Instagram\"}, {\"topic\": \"Facebook\"}]\\n)\\n\\n# 비동기로 처리되는 일괄 처리 프로세스가 완료될 때까지 기다립니다.\\nawait my_abatch_process\\n\\n[\\'YouTube는 동영상 공유 플랫폼으로 사용자들이 영상을 업로드하고 시청할 수 있는 서비스입니다. 다양한 콘텐츠를 제공하며 사용자는 무료로 영상을 시청할 수 있습니다. 유명한 유튜버들이 활동하고 수익을 창출할 수 있는 플랫폼으로도 알려져 있습니다.\\', \\'인스타그램은 사진과 동영상을 공유하는 소셜 미디어 플랫폼으로, 사용자들은 다양한 필터와 효과를 이용해 자신의 콘텐츠를 멋지게 꾸밀 수 있습니다. 또한 팔로워들과 소통하고, 다른 사용자의 게시물을 좋아하거나 댓글을 남기며 커뮤니케이션을 할 수 있습니다. 인스타그램은 비즈니스나 개인 브랜딩에도 활용되며, 많은 사람들이 일상 속 소소한 순간부터 특별한 순간까지를 공유하고 있습니다.\\', \\'Facebook은 미국의 소셜 네트워크 서비스로, 사용자들이 커뮤니케이션하고 정보를 공유할 수 있는 플랫폼이다. 현재 전 세계적으로 약 30억 명 이상의 사용자가 활동하고 있으며, 광고 및 비즈니스 활동에도 널리 활용되고 있다. 또한 개인정보 보호 문제와 가짜 뉴스 등 여러 논란을 빚어왔으나, 여전히 많은 사람들이 이용하고 있는 대표적인 SNS 서비스이다.\\']\\n\\nParallel: 병렬성\\n\\nLangChain Expression Language가 병렬 요청을 지원하는 방법을 살펴봅시다. 예를 들어, RunnableParallel을 사용할 때(자주 사전 형태로 작성됨), 각 요소를 병렬로 실행합니다.\\n\\nlangchain_core.runnables 모듈의 RunnableParallel 클래스를 사용하여 두 가지 작업을 병렬로 실행하는 예시를 보여줍니다.\\n\\nChatPromptTemplate.from_template 메서드를 사용하여 주어진 country에 대한 수도 와 면적 을 구하는 두 개의 체인(chain1, chain2)을 만듭니다.\\n\\n이 체인들은 각각 model과 파이프(|) 연산자를 통해 연결됩니다. 마지막으로, RunnableParallel 클래스를 사용하여 이 두 체인을 capital와 area이라는 키로 결합하여 동시에 실행할 수 있는 combined 객체를 생성합니다.\\n\\nfrom langchain_core.runnables import RunnableParallel\\n\\n# {country} 의 수도를 물어보는 체인을 생성합니다.\\nchain1 = (\\n    PromptTemplate.from_template(\"{country} 의 수도는 어디야?\")\\n    | model\\n    | StrOutputParser()\\n)\\n\\n# {country} 의 면적을 물어보는 체인을 생성합니다.\\nchain2 = (\\n    PromptTemplate.from_template(\"{country} 의 면적은 얼마야?\")\\n    | model\\n    | StrOutputParser()\\n)\\n\\n# 위의 2개 체인을 동시에 생성하는 병렬 실행 체인을 생성합니다.\\ncombined = RunnableParallel(capital=chain1, area=chain2)\\n\\nchain1.invoke() 함수는 chain1 객체의 invoke 메서드를 호출합니다.\\n\\n이때, country이라는 키에 대한민국라는 값을 가진 딕셔너리를 인자로 전달합니다.\\n\\n# chain1 를 실행합니다.\\nchain1.invoke({\"country\": \"대한민국\"})\\n\\n\\'대한민국의 수도는 서울이다.\\'\\n\\n이번에는 chain2.invoke() 를 호출합니다. country 키에 다른 국가인 미국 을 전달합니다.\\n\\n# chain2 를 실행합니다.\\nchain2.invoke({\"country\": \"미국\"})\\n\\n\\'미국의 면적은 약 9,826,675 제곱 킬로미터입니다.\\'\\n\\ncombined 객체의 invoke 메서드는 주어진 country에 대한 처리를 수행합니다.\\n\\n이 예제에서는 대한민국라는 주제를 invoke 메서드에 전달하여 실행합니다.\\n\\n# 병렬 실행 체인을 실행합니다.\\ncombined.invoke({\"country\": \"대한민국\"})\\n\\n{\\'capital\\': \\'대한민국의 수도는 서울입니다.\\', \\'area\\': \\'대한민국의 면적은 약 100,363.4 제곱 킬로미터 입니다.\\'}\\n\\n배치에서의 병렬 처리\\n\\n병렬 처리는 다른 실행 가능한 코드와 결합될 수 있습니다. 배치와 병렬 처리를 사용해 보도록 합시다.\\n\\nchain1.batch 함수는 여러 개의 딕셔너리를 포함하는 리스트를 인자로 받아, 각 딕셔너리에 있는 \"topic\" 키에 해당하는 값을 처리합니다. 이 예시에서는 \"대한민국\"와 \"미국\"라는 두 개의 토픽을 배치 처리하고 있습니다.\\n\\n# 배치 처리를 수행합니다.\\nchain1.batch([{\"country\": \"대한민국\"}, {\"country\": \"미국\"}])\\n\\n[\\'대한민국의 수도는 서울이에요.\\', \\'미국의 수도는 워싱턴 D.C.입니다.\\']\\n\\nchain2.batch 함수는 여러 개의 딕셔너리를 리스트 형태로 받아, 일괄 처리(batch)를 수행합니다.\\n\\n이 예시에서는 대한민국와 미국라는 두 가지 국가에 대한 처리를 요청합니다.\\n\\n# 배치 처리를 수행합니다.\\nchain2.batch([{\"country\": \"대한민국\"}, {\"country\": \"미국\"}])\\n\\n[\\'대한민국의 총 면적은 약 100,363 제곱킬로미터 입니다.\\', \\'미국의 면적은 약 9,834,000km² 입니다.\\']\\n\\ncombined.batch 함수는 주어진 데이터를 배치로 처리하는 데 사용됩니다. 이 예시에서는 두 개의 딕셔너리 객체를 포함하는 리스트를 인자로 받아 각각 대한민국와 미국 두 나라에 대한 데이터를 배치 처리합니다.\\n\\n# 주어진 데이터를 배치로 처리합니다.\\ncombined.batch([{\"country\": \"대한민국\"}, {\"country\": \"미국\"}])\\n\\n[{\\'capital\\': \\'대한민국의 수도는 서울이다.\\', \\'area\\': \\'대한민국의 면적은 약 100,363km² 입니다.\\'}, {\\'capital\\': \\'미국의 수도는 워싱턴 D.C.입니다.\\', \\'area\\': \\'미국의 면적은 약 9,833,520 km² 입니다.\\'}]\\n\\n마지막 편집일시 : 2024년 6월 17일 8:04 오후\\n\\n댓글 0 피드백\\n\\n※ 댓글 작성은 로그인이 필요합니다. (또는 피드백을 이용해 주세요.)\\n\\n이전글 : 04. LangChain Expression Language(LCEL)\\n\\n다음글 : 06. Runnable\\n\\n책갈피\\n\\n이 페이지에 대한 피드백을 남겨주세요\\n\\n댓글을 신고합니다.', metadata={'source': 'https://wikidocs.net/233345'}),\n",
       " Document(page_content='<랭체인LangChain 노트> - LangChain 한국어 튜토리얼🇰🇷 CH01 LangChain 시작하기 01. OpenAI API 키 발급 및 테스트 02. LangSmith 추적 설정 03. OpenAI API 사용(GPT-4o 멀티모달) 04. LangChain Expression Language(LCEL) 05. LCEL 인터페이스 06. Runnable CH02 프롬프트(Prompt) 01. 프롬프트(Prompt) 02. 퓨샷 프롬프트(FewShotPromptTemplate) 03. LangChain Hub 04. 개인화된 프롬프트(Hub에 업로드) CH03 출력 파서(Output Parsers) 01. Pydantic 출력 파서(PydanticOutputParser) 02. 콤마 구분자 출력 파서(CommaSeparatedListOutputParser) 03. 구조화된 출력 파서(StructuredOuputParser) 04. JSON 출력 파서(JsonOutputParser) 05. 데이터프레임 출력 파서(PandasDataFrameOutputParser) 06. 날짜 형식 출력 파서(DatetimeOutputParser) 07. 열거형 출력 파서(EnumOutputParser) 08. 출력 수정 파서(OutputFixingParser) CH04 모델(Model) 01. 다양한 LLM 모델 활용 02. 캐싱(Cache) 03. 모델 직렬화(Serialization) - 저장 및 불러오기 04. 토큰 사용량 확인 05. 구글 생성 AI(Google Generative AI) 06. 허깅페이스 엔드포인트(HuggingFace Endpoints) 07. 허깅페이스 로컬(HuggingFace Local) 08. 허깅페이스 파이프라인(HuggingFace Pipeline) 09. 올라마(Ollama) 10. GPT4ALL CH05 메모리(Memory) 01. 대화 버퍼 메모리(ConversationBufferMemory) 02. 대화 버퍼 윈도우 메모리(ConversationBufferWindowMemory) 03. 대화 토큰 버퍼 메모리(ConversationTokenBufferMemory) 04. 대화 엔티티 메모리(ConversationEntityMemory) 05. 대화 지식그래프 메모리(ConversationKGMemory) 06. 대화 요약 메모리(ConversationSummaryMemory) 07. 벡터저장소 검색 메모리(VectorStoreRetrieverMemory) 08. LCEL Chain 에 메모리 추가 09. SQLite 에 대화내용 저장 10. RunnableWithMessageHistory에 ChatMessageHistory추가 CH06 문서 로더(Document Loader) 01. 도큐먼트(Document) 의 구조 02. PDF 03. 한글(HWP) 04. CSV 05. Excel 06. Word 07. PowerPoint 08. 웹 문서(WebBaseLoader) 09. 텍스트(TextLoader) 10. JSON 11. Arxiv 13. UpstageLayoutAnalysisLoader 14. LlamaParser CH07 텍스트 분할(Text Splitter) 01. 문자 텍스트 분할(CharacterTextSplitter) 02. 재귀적 문자 텍스트 분할(RecursiveCharacterTextSplitter) 03. 토큰 텍스트 분할(TokenTextSplitter) 04. 시멘틱 청커(SemanticChunker) 05. 코드 분할(Python, Markdown, JAVA, C++, C#, GO, JS, Latex 등) 06. 마크다운 헤더 텍스트 분할(MarkdownHeaderTextSplitter) 07. HTML 헤더 텍스트 분할(HTMLHeaderTextSplitter) 08. 재귀적 JSON 분할(RecursiveJsonSplitter) CH08 임베딩(Embedding) 01. OpenAIEmbeddings 02. 캐시 임베딩(CacheBackedEmbeddings) 03. 허깅페이스 임베딩(HuggingFace Embeddings) 04. UpstageEmbeddings 05. OllamaEmbeddings 06. GPT4ALL 임베딩 07. Llama CPP 임베딩 CH09 벡터저장소(VectorStore) 01. Chroma 02. FAISS 03. Pinecone CH10 검색기(Retriever) 01. 벡터저장소 지원 검색기(VectorStore-backed Retriever) 02. 문맥 압축 검색기(ContextualCompressionRetriever) 03. 앙상블 검색기(EnsembleRetriever) 04. 긴 문맥 재정렬(LongContextReorder) 05. 상위 문서 검색기(ParentDocumentRetriever) 06. 다중 쿼리 검색기(MultiQueryRetriever) 07. 다중 벡터저장소 검색기(MultiVectorRetriever) 08. 셀프 쿼리 검색기(SelfQueryRetriever) 09. 시간 가중 벡터저장소 검색기(TimeWeightedVectorStoreRetriever) 10. 한글 형태소 분석기(Kiwi, Kkma, Okt) + BM25 검색기 CH11 리랭커(Reranker) 01. Cross Encoder Reranker 02. Cohere Reranker 03. Jina Reranker 04. FlashRank Reranker CH12 Retrieval Augmented Generation(RAG) 01. PDF 문서 기반 QA(Question-Answer) 02. 네이버 뉴스기사 QA(Question-Answer) 03. RAG 의 기능별 다양한 모듈 활용기 04. RAPTOR: 긴 문맥 요약(Long Context Summary) 05. 대화내용을 기억하는 RAG 체인 CH13 LangChain Expression Language(LCEL) 01. RunnablePassthrough: 데이터 전달 02. Runnable 구조(그래프) 확인 03. RunnableLambda: 사용자 정의 함수 04. RunnableBranch: 라우팅(Routing) 05. RunnableParallel: 병렬 처리 06. configurable_fields, configurable_alternatives 07. @chain 데코레이터로 Runnable 생성 08. RunnableWithMessageHistory 09. 사용자 정의 제네레이터(generator) 10. Runtime Arguments 바인딩 11. 폴백(fallback) 모델 지정 CH14 체인(Chains) 01. 문서 요약 02. SQL CH15 에이전트(Agent) 01. Agent 사용법 톺아보기 02. 도구를 활용한 토론 에이전트(Two Agent Debates with Tools) CH16 파인튜닝(Fine Tuning) CH17 LangGraph 01. Chain of Table for Multiple Tables\\n\\nPublished with WikiDocs\\n\\n<랭체인LangChain 노트> - Lang…\\n\\nCH01 LangChain 시작하기\\n\\n02. LangSmith 추적 설정\\n\\n위키독스\\n\\n02. LangSmith 추적 설정\\n\\nLangSmith 추적 설정하기\\n\\nLangSmith는 LLM 애플리케이션 개발, 모니터링 및 테스트 를 위한 플랫폼입니다. 프로젝트나 LangChain 학습을 시작하시는 분들이라면 LangSmith는 꼭 설정 후 진행하는 것을 추천 드립니다.\\n\\nLangSmith 의 추적기능\\n\\n추적은 LLM 애플리케이션의 동작을 이해하기 위한 강력한 도구입니다. LangSmith는 LangChain 사용 여부와 관계없이 동급 최고의 추적 기능을 제공합니다.\\n\\n추적은 다음과 같은 문제를 추적하는 데 도움이 될 수 있습니다.\\n\\n예상치 못한 최종 결과\\n\\n에이전트가 루핑되는 이유\\n\\n체인이 예상보다 느린 이유\\n\\n에이전트가 각 단계에서 사용한 토큰 수\\n\\n프로젝트 단위 추적\\n\\n프로젝트 단위로 실행 카운트, Error 발생률, 토큰 사용량, 과금 정보등을 확인할 수 있습니다.\\n\\n프로젝트를 클릭하면 실행된 모든 Run 이 나타납니다.\\n\\n1개의 실행에 대한 세부 단계별 추척\\n\\n1개의 실행을 한 뒤 retrieve 된 문서의 검색 결과 뿐만 아니라, GPT 의 입출력 내용에 대해서 자세하게 기록합니다. 따라서, 문서의 검색된 내용을 확인 후 검색 알고리즘을 변경해야할지 혹은 프롬프트를 변경해야할지 판단하는데 도움이 됩니다.\\n\\n뿐만 아니라, 상단에는 1개의 실행(Run) 이 걸린 시간(약 30초)와 사용된 토큰(5,104) 등이 표기가 되고, 토큰에 마우스 호버를 하게 되면 청구 금액까지 표기해 줍니다.\\n\\nLangSmith 추적 사용하기\\n\\n추적을 사용하는 방법은 매우 간단합니다.\\n\\nLangSmith API Key 발급\\n\\nhttps://smith.langchain.com/ 으로 접속하여 회원가입을 진행합니다.\\n\\n가입후 이메일 인증하는 절차를 진행해야 합니다.\\n\\n왼쪽 톱니바퀴(Setting) - 가운데 \"Personal\" - \"Create API Key\" 를 눌러 API 키를 발급 받습니다.\\n\\nDescription 에 본인이 알 수 있는 설명을 넣고 Create API Key 버튼을 클릭하여 생성합니다.\\n\\n생성한 키를 복사한 뒤 다음 단계로 진행합니다.\\n\\n(주의!) 생성한 키를 유출하지 않도록 안전한 곳에 복사해 두세요.\\n\\n.env 에 LangSmith 키 설정\\n\\n먼저, .env 파일에 LangSmith 에서 발급받은 키와 프로젝트 정보를 입력합니다.\\n\\nLANGCHAIN_TRACING_V2: \"true\" 로 설정하면 추적을 시작합니다.\\n\\nLANGCHAIN_ENDPOINT: https://api.smith.langchain.com 변경하지 않습니다.\\n\\nLANGCHAIN_API_KEY: 이전 단계에서 발급받은 키 를 입력합니다.\\n\\nLANGCHAIN_PROJECT: 프로젝트 명 을 기입하면 해당 프로젝트 그룹으로 모든 실행(Run) 이 추적됩니다.\\n\\nJupyter Notebook 혹은 코드에서 추적을 활성화 하기\\n\\n추적을 활성화 하는 방법은 매우 간단합니다. 환경 변수만 설정하면 됩니다.\\n\\n.env 에 설정한 내용을 불러옵니다.\\n\\nfrom dotenv import load_dotenv\\n\\nload_dotenv()\\n\\n만약 설정한 추적이 활성화 되어 있고, API KEY 와 프로젝트 명이 제대로 설정되어 있다면, 이걸로도 충분합니다.\\n\\n하지만, 프로젝트 명을 변경하거나, 추적을 변경하고 싶을 때는 아래의 코드로 변경할 수 있습니다.\\n\\nimport os\\n\\nos.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\\nos.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\\nos.environ[\"LANGCHAIN_PROJECT\"] = \"LangChain 프로젝트명\"\\nos.environ[\"LANGCHAIN_API_KEY\"] = \"LangChain API KEY 입력\"\\n\\nlangchain-teddynote\\n\\nlangchain 관련 기능을 보다 더 편리하게 사용하기 위한 목적으로 langchain-teddynote 패키지를 만들었습니다.\\n\\n설치방법\\n\\n설치코드 (터미널에서 실행 혹은 Jupyter Notebook 에서 실행)\\n\\npip install langchain-teddynote\\n\\nLangSmith 추적 설정\\n\\n.env 파일에 LangSmith API 키가 설정 되어 있어야 합니다.(LANGCHAIN_API_KEY)\\n\\nfrom langchain_teddynote import logging\\n\\n# 프로젝트 이름을 입력합니다.\\nlogging.langsmith(\"원하는 프로젝트명\")\\n\\n출력예시\\n\\nLangSmith 추적을 시작합니다.\\n[프로젝트명]\\n랭체인 튜토리얼 프로젝트\\n\\n추척을 원하지 않을 때는 다음과 같이 추적을 끌 수 있습니다.\\n\\nfrom langchain_teddynote import logging\\n\\n# set_enable=False 로 지정하면 추적을 하지 않습니다.\\nlogging.langsmith(\"랭체인 튜토리얼 프로젝트\", set_enable=False)\\n\\n마지막 편집일시 : 2024년 6월 17일 10:13 오후\\n\\n댓글 0 피드백\\n\\n※ 댓글 작성은 로그인이 필요합니다. (또는 피드백을 이용해 주세요.)\\n\\n이전글 : 01. OpenAI API 키 발급 및 테스트\\n\\n다음글 : 03. OpenAI API 사용(GPT-4o 멀티모달)\\n\\n책갈피\\n\\n이 페이지에 대한 피드백을 남겨주세요\\n\\n댓글을 신고합니다.', metadata={'source': 'https://wikidocs.net/250954'}),\n",
       " Document(page_content='<랭체인LangChain 노트> - LangChain 한국어 튜토리얼🇰🇷 CH01 LangChain 시작하기 01. OpenAI API 키 발급 및 테스트 02. LangSmith 추적 설정 03. OpenAI API 사용(GPT-4o 멀티모달) 04. LangChain Expression Language(LCEL) 05. LCEL 인터페이스 06. Runnable CH02 프롬프트(Prompt) 01. 프롬프트(Prompt) 02. 퓨샷 프롬프트(FewShotPromptTemplate) 03. LangChain Hub 04. 개인화된 프롬프트(Hub에 업로드) CH03 출력 파서(Output Parsers) 01. Pydantic 출력 파서(PydanticOutputParser) 02. 콤마 구분자 출력 파서(CommaSeparatedListOutputParser) 03. 구조화된 출력 파서(StructuredOuputParser) 04. JSON 출력 파서(JsonOutputParser) 05. 데이터프레임 출력 파서(PandasDataFrameOutputParser) 06. 날짜 형식 출력 파서(DatetimeOutputParser) 07. 열거형 출력 파서(EnumOutputParser) 08. 출력 수정 파서(OutputFixingParser) CH04 모델(Model) 01. 다양한 LLM 모델 활용 02. 캐싱(Cache) 03. 모델 직렬화(Serialization) - 저장 및 불러오기 04. 토큰 사용량 확인 05. 구글 생성 AI(Google Generative AI) 06. 허깅페이스 엔드포인트(HuggingFace Endpoints) 07. 허깅페이스 로컬(HuggingFace Local) 08. 허깅페이스 파이프라인(HuggingFace Pipeline) 09. 올라마(Ollama) 10. GPT4ALL CH05 메모리(Memory) 01. 대화 버퍼 메모리(ConversationBufferMemory) 02. 대화 버퍼 윈도우 메모리(ConversationBufferWindowMemory) 03. 대화 토큰 버퍼 메모리(ConversationTokenBufferMemory) 04. 대화 엔티티 메모리(ConversationEntityMemory) 05. 대화 지식그래프 메모리(ConversationKGMemory) 06. 대화 요약 메모리(ConversationSummaryMemory) 07. 벡터저장소 검색 메모리(VectorStoreRetrieverMemory) 08. LCEL Chain 에 메모리 추가 09. SQLite 에 대화내용 저장 10. RunnableWithMessageHistory에 ChatMessageHistory추가 CH06 문서 로더(Document Loader) 01. 도큐먼트(Document) 의 구조 02. PDF 03. 한글(HWP) 04. CSV 05. Excel 06. Word 07. PowerPoint 08. 웹 문서(WebBaseLoader) 09. 텍스트(TextLoader) 10. JSON 11. Arxiv 13. UpstageLayoutAnalysisLoader 14. LlamaParser CH07 텍스트 분할(Text Splitter) 01. 문자 텍스트 분할(CharacterTextSplitter) 02. 재귀적 문자 텍스트 분할(RecursiveCharacterTextSplitter) 03. 토큰 텍스트 분할(TokenTextSplitter) 04. 시멘틱 청커(SemanticChunker) 05. 코드 분할(Python, Markdown, JAVA, C++, C#, GO, JS, Latex 등) 06. 마크다운 헤더 텍스트 분할(MarkdownHeaderTextSplitter) 07. HTML 헤더 텍스트 분할(HTMLHeaderTextSplitter) 08. 재귀적 JSON 분할(RecursiveJsonSplitter) CH08 임베딩(Embedding) 01. OpenAIEmbeddings 02. 캐시 임베딩(CacheBackedEmbeddings) 03. 허깅페이스 임베딩(HuggingFace Embeddings) 04. UpstageEmbeddings 05. OllamaEmbeddings 06. GPT4ALL 임베딩 07. Llama CPP 임베딩 CH09 벡터저장소(VectorStore) 01. Chroma 02. FAISS 03. Pinecone CH10 검색기(Retriever) 01. 벡터저장소 지원 검색기(VectorStore-backed Retriever) 02. 문맥 압축 검색기(ContextualCompressionRetriever) 03. 앙상블 검색기(EnsembleRetriever) 04. 긴 문맥 재정렬(LongContextReorder) 05. 상위 문서 검색기(ParentDocumentRetriever) 06. 다중 쿼리 검색기(MultiQueryRetriever) 07. 다중 벡터저장소 검색기(MultiVectorRetriever) 08. 셀프 쿼리 검색기(SelfQueryRetriever) 09. 시간 가중 벡터저장소 검색기(TimeWeightedVectorStoreRetriever) 10. 한글 형태소 분석기(Kiwi, Kkma, Okt) + BM25 검색기 CH11 리랭커(Reranker) 01. Cross Encoder Reranker 02. Cohere Reranker 03. Jina Reranker 04. FlashRank Reranker CH12 Retrieval Augmented Generation(RAG) 01. PDF 문서 기반 QA(Question-Answer) 02. 네이버 뉴스기사 QA(Question-Answer) 03. RAG 의 기능별 다양한 모듈 활용기 04. RAPTOR: 긴 문맥 요약(Long Context Summary) 05. 대화내용을 기억하는 RAG 체인 CH13 LangChain Expression Language(LCEL) 01. RunnablePassthrough: 데이터 전달 02. Runnable 구조(그래프) 확인 03. RunnableLambda: 사용자 정의 함수 04. RunnableBranch: 라우팅(Routing) 05. RunnableParallel: 병렬 처리 06. configurable_fields, configurable_alternatives 07. @chain 데코레이터로 Runnable 생성 08. RunnableWithMessageHistory 09. 사용자 정의 제네레이터(generator) 10. Runtime Arguments 바인딩 11. 폴백(fallback) 모델 지정 CH14 체인(Chains) 01. 문서 요약 02. SQL CH15 에이전트(Agent) 01. Agent 사용법 톺아보기 02. 도구를 활용한 토론 에이전트(Two Agent Debates with Tools) CH16 파인튜닝(Fine Tuning) CH17 LangGraph 01. Chain of Table for Multiple Tables\\n\\nPublished with WikiDocs\\n\\n<랭체인LangChain 노트> - Lang…\\n\\nCH01 LangChain 시작하기\\n\\n01. OpenAI API 키 발급 및 테스트\\n\\n위키독스\\n\\n01. OpenAI API 키 발급 및 테스트\\n\\nOpenAI API 키 발급 및 설정\\n\\n1) OpenAI API 키 발급\\n\\nOpenAI API 웹사이트에 접속합니다.\\n\\n링크: https://platform.openai.com/docs/overview\\n\\n우측 상단 \"Sign Up\" 을 눌러 회원가입을 진행합니다. (만약, 이미 가입되어 있는 상태라면 \"Log in\" 버튼을 눌러 로그인 합니다.\\n\\n우측 상단 톱니바퀴(Setting) 를 눌러 설정으로 이동합니다.\\n\\n왼쪽 \"Billing\" 메뉴에서 \"Payment methods\" 를 클릭하여 신용카드를 등록 합니다.\\n\\n신용카드를 등록했다면 아래와 같이 등록된 신용카드가 목록에 나타납니다.\\n\\n\"Add to credit balance\" 버튼을 눌러 사용할만큼의 미화(달러) 를 입력합니다.\\n\\n금액은 $5 부터 추가가 가능합니다. (즉, 최소결제금액인 $5 이상은 결제를 해야 합니다)\\n\\n금액을 입력한 후 \"Continue\" 를 눌러 결제를 진행합니다.\\n\\n왼쪽의 \"Limits\" 탭에서 월간 사용한도를 설정할 수 있습니다.\\n\\n\"Set a monthly budge\": 월간 사용한도를 지정합니다. 이 금액에 도달하면 더이상 과금하지 않고 API 는 사용을 멈춥니다.\\n\\n\"Set an email notification threshold\": 이메일이 발송되는 요금을 지정할 수 있습니다. 이 금액에 도달하면 이메일이 발송됩니다.\\n\\n우측 프로필 이미지 클릭 - \"Your profile\"\\n\\nAPI Key 관리 메뉴 로 접속합니다.\\n\\nhttps://platform.openai.com/api-keys\\n\\n\"Create new secret key\" 를 클릭합니다.\\n\\nName 과 프로젝트 를 입력합니다. (별도 생성한 프로젝트가 없다면 Default project 를 설정합니다)\\n\\n우측 \"Copy\" 버튼을 눌러 키를 복사합니다.\\n\\n주의!!!\\n\\n키가 유출되면 다른 사람이 내 API KEY 를 사용하여 GPT 를 사용할 수 있으며, 결제는 제 지갑에서 결제됩니다.\\n\\n절대 키는 타인에게 공유하지 마시고, 안전한 곳에 보관 하세요! (암호라고 생각하세요)\\n\\n2) .env 파일 설정\\n\\n프로젝트 루트 디렉토리에 .env 파일을 생성합니다.\\n\\n.env 파일에 OPENAI_API_KEY=방금복사한 키를 입력 한 뒤 Ctrl + S 를 눌러 저장하고 파일을 닫습니다.\\n\\n# LangChain 업데이트\\n!pip install -r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt\\n\\n# API KEY를 환경변수로 관리하기 위한 설정 파일\\n# 설치: pip install python-dotenv\\nfrom dotenv import load_dotenv\\n\\n# API KEY 정보로드\\nload_dotenv()\\n\\nTrue\\n\\nAPI Key 가 잘 설정되었는지 확인합니다.\\n\\nimport os\\n\\nprint(f\"[API KEY]\\\\n{os.environ[\\'OPENAI_API_KEY\\']}\")\\n\\n마지막 편집일시 : 2024년 6월 17일 8:24 오후\\n\\n댓글 0 피드백\\n\\n※ 댓글 작성은 로그인이 필요합니다. (또는 피드백을 이용해 주세요.)\\n\\n이전글 : CH01 LangChain 시작하기\\n\\n다음글 : 02. LangSmith 추적 설정\\n\\n책갈피\\n\\n이 페이지에 대한 피드백을 남겨주세요\\n\\n댓글을 신고합니다.', metadata={'source': 'https://wikidocs.net/233342'}),\n",
       " Document(page_content='<랭체인LangChain 노트> - LangChain 한국어 튜토리얼🇰🇷 CH01 LangChain 시작하기 01. OpenAI API 키 발급 및 테스트 02. LangSmith 추적 설정 03. OpenAI API 사용(GPT-4o 멀티모달) 04. LangChain Expression Language(LCEL) 05. LCEL 인터페이스 06. Runnable CH02 프롬프트(Prompt) 01. 프롬프트(Prompt) 02. 퓨샷 프롬프트(FewShotPromptTemplate) 03. LangChain Hub 04. 개인화된 프롬프트(Hub에 업로드) CH03 출력 파서(Output Parsers) 01. Pydantic 출력 파서(PydanticOutputParser) 02. 콤마 구분자 출력 파서(CommaSeparatedListOutputParser) 03. 구조화된 출력 파서(StructuredOuputParser) 04. JSON 출력 파서(JsonOutputParser) 05. 데이터프레임 출력 파서(PandasDataFrameOutputParser) 06. 날짜 형식 출력 파서(DatetimeOutputParser) 07. 열거형 출력 파서(EnumOutputParser) 08. 출력 수정 파서(OutputFixingParser) CH04 모델(Model) 01. 다양한 LLM 모델 활용 02. 캐싱(Cache) 03. 모델 직렬화(Serialization) - 저장 및 불러오기 04. 토큰 사용량 확인 05. 구글 생성 AI(Google Generative AI) 06. 허깅페이스 엔드포인트(HuggingFace Endpoints) 07. 허깅페이스 로컬(HuggingFace Local) 08. 허깅페이스 파이프라인(HuggingFace Pipeline) 09. 올라마(Ollama) 10. GPT4ALL CH05 메모리(Memory) 01. 대화 버퍼 메모리(ConversationBufferMemory) 02. 대화 버퍼 윈도우 메모리(ConversationBufferWindowMemory) 03. 대화 토큰 버퍼 메모리(ConversationTokenBufferMemory) 04. 대화 엔티티 메모리(ConversationEntityMemory) 05. 대화 지식그래프 메모리(ConversationKGMemory) 06. 대화 요약 메모리(ConversationSummaryMemory) 07. 벡터저장소 검색 메모리(VectorStoreRetrieverMemory) 08. LCEL Chain 에 메모리 추가 09. SQLite 에 대화내용 저장 10. RunnableWithMessageHistory에 ChatMessageHistory추가 CH06 문서 로더(Document Loader) 01. 도큐먼트(Document) 의 구조 02. PDF 03. 한글(HWP) 04. CSV 05. Excel 06. Word 07. PowerPoint 08. 웹 문서(WebBaseLoader) 09. 텍스트(TextLoader) 10. JSON 11. Arxiv 13. UpstageLayoutAnalysisLoader 14. LlamaParser CH07 텍스트 분할(Text Splitter) 01. 문자 텍스트 분할(CharacterTextSplitter) 02. 재귀적 문자 텍스트 분할(RecursiveCharacterTextSplitter) 03. 토큰 텍스트 분할(TokenTextSplitter) 04. 시멘틱 청커(SemanticChunker) 05. 코드 분할(Python, Markdown, JAVA, C++, C#, GO, JS, Latex 등) 06. 마크다운 헤더 텍스트 분할(MarkdownHeaderTextSplitter) 07. HTML 헤더 텍스트 분할(HTMLHeaderTextSplitter) 08. 재귀적 JSON 분할(RecursiveJsonSplitter) CH08 임베딩(Embedding) 01. OpenAIEmbeddings 02. 캐시 임베딩(CacheBackedEmbeddings) 03. 허깅페이스 임베딩(HuggingFace Embeddings) 04. UpstageEmbeddings 05. OllamaEmbeddings 06. GPT4ALL 임베딩 07. Llama CPP 임베딩 CH09 벡터저장소(VectorStore) 01. Chroma 02. FAISS 03. Pinecone CH10 검색기(Retriever) 01. 벡터저장소 지원 검색기(VectorStore-backed Retriever) 02. 문맥 압축 검색기(ContextualCompressionRetriever) 03. 앙상블 검색기(EnsembleRetriever) 04. 긴 문맥 재정렬(LongContextReorder) 05. 상위 문서 검색기(ParentDocumentRetriever) 06. 다중 쿼리 검색기(MultiQueryRetriever) 07. 다중 벡터저장소 검색기(MultiVectorRetriever) 08. 셀프 쿼리 검색기(SelfQueryRetriever) 09. 시간 가중 벡터저장소 검색기(TimeWeightedVectorStoreRetriever) 10. 한글 형태소 분석기(Kiwi, Kkma, Okt) + BM25 검색기 CH11 리랭커(Reranker) 01. Cross Encoder Reranker 02. Cohere Reranker 03. Jina Reranker 04. FlashRank Reranker CH12 Retrieval Augmented Generation(RAG) 01. PDF 문서 기반 QA(Question-Answer) 02. 네이버 뉴스기사 QA(Question-Answer) 03. RAG 의 기능별 다양한 모듈 활용기 04. RAPTOR: 긴 문맥 요약(Long Context Summary) 05. 대화내용을 기억하는 RAG 체인 CH13 LangChain Expression Language(LCEL) 01. RunnablePassthrough: 데이터 전달 02. Runnable 구조(그래프) 확인 03. RunnableLambda: 사용자 정의 함수 04. RunnableBranch: 라우팅(Routing) 05. RunnableParallel: 병렬 처리 06. configurable_fields, configurable_alternatives 07. @chain 데코레이터로 Runnable 생성 08. RunnableWithMessageHistory 09. 사용자 정의 제네레이터(generator) 10. Runtime Arguments 바인딩 11. 폴백(fallback) 모델 지정 CH14 체인(Chains) 01. 문서 요약 02. SQL CH15 에이전트(Agent) 01. Agent 사용법 톺아보기 02. 도구를 활용한 토론 에이전트(Two Agent Debates with Tools) CH16 파인튜닝(Fine Tuning) CH17 LangGraph 01. Chain of Table for Multiple Tables\\n\\nPublished with WikiDocs\\n\\n<랭체인LangChain 노트> - Lang…\\n\\nCH01 LangChain 시작하기\\n\\n03. OpenAI API 사용(GPT-4o…\\n\\n위키독스\\n\\n03. OpenAI API 사용(GPT-4o 멀티모달)\\n\\n# API KEY를 환경변수로 관리하기 위한 설정 파일\\nfrom dotenv import load_dotenv\\n\\n# API KEY 정보로드\\nload_dotenv()\\n\\nTrue\\n\\n# LangSmith 추적을 설정합니다. https://smith.langchain.com\\n# .env 파일에 LANGCHAIN_API_KEY를 입력합니다.\\n# !pip install -qU langchain-teddynote\\nfrom langchain_teddynote import logging\\n\\n# 프로젝트 이름을 입력합니다.\\nlogging.langsmith(\"CH01-Basic\")\\n\\nLangSmith 추적을 시작합니다.\\n[프로젝트명]\\nCH01-Basic\\n\\nChatOpenAI\\n\\nOpenAI 사의 채팅 전용 Large Language Model(llm) 입니다.\\n\\n객체를 생성할 때 다음을 옵션 값을 지정할 수 있습니다. 옵션에 대한 상세 설명은 다음과 같습니다.\\n\\ntemperature\\n\\n사용할 샘플링 온도는 0과 2 사이에서 선택합니다. 0.8과 같은 높은 값은 출력을 더 무작위하게 만들고, 0.2와 같은 낮은 값은 출력을 더 집중되고 결정론적으로 만듭니다.\\n\\nmax_tokens\\n\\n채팅 완성에서 생성할 토큰의 최대 개수입니다.\\n\\nmodel_name: 적용 가능한 모델 리스트 - gpt-3.5-turbo - gpt-4-turbo - gpt-4o\\n\\n링크: https://platform.openai.com/docs/models\\n\\nfrom langchain_openai import ChatOpenAI\\n\\n# 객체 생성\\nllm = ChatOpenAI(\\n    temperature=0.1,  # 창의성 (0.0 ~ 2.0)\\n    model_name=\"gpt-4o\",  # 모델명\\n)\\n\\n# 질의내용\\nquestion = \"대한민국의 수도는 어디인가요?\"\\n\\n# 질의\\nprint(f\"[답변]: {llm.invoke(question)}\")\\n\\n[답변]: content=\\'대한민국의 수도는 서울입니다. 서울은 대한민국의 정치, 경제, 문화의 중심지로서 많은 인구와 다양한 명소를 자랑하는 도시입니다.\\' response_metadata={\\'token_usage\\': {\\'completion_tokens\\': 36, \\'prompt_tokens\\': 16, \\'total_tokens\\': 52}, \\'model_name\\': \\'gpt-4o\\', \\'system_fingerprint\\': \\'fp_f4e629d0a5\\', \\'finish_reason\\': \\'stop\\', \\'logprobs\\': None} id=\\'run-dcda4cfa-3143-4982-b24c-4a25ce0a447e-0\\' usage_metadata={\\'input_tokens\\': 16, \\'output_tokens\\': 36, \\'total_tokens\\': 52}\\n\\n답변의 형식(AI Message)\\n\\n# 질의내용\\nquestion = \"대한민국의 수도는 어디인가요?\"\\n\\n# 질의\\nresponse = llm.invoke(question)\\n\\nresponse\\n\\nAIMessage(content=\\'대한민국의 수도는 서울입니다. 서울은 대한민국의 정치, 경제, 문화의 중심지로서 많은 인구와 다양한 명소를 자랑하는 도시입니다.\\', response_metadata={\\'token_usage\\': {\\'completion_tokens\\': 36, \\'prompt_tokens\\': 16, \\'total_tokens\\': 52}, \\'model_name\\': \\'gpt-4o\\', \\'system_fingerprint\\': \\'fp_aa87380ac5\\', \\'finish_reason\\': \\'stop\\', \\'logprobs\\': None}, id=\\'run-3296402a-f47b-4ace-88cd-b74efb7465fb-0\\', usage_metadata={\\'input_tokens\\': 16, \\'output_tokens\\': 36, \\'total_tokens\\': 52})\\n\\nresponse.content\\n\\n\\'대한민국의 수도는 서울입니다. 서울은 대한민국의 정치, 경제, 문화의 중심지로서 많은 인구와 다양한 명소를 자랑하는 도시입니다.\\'\\n\\nresponse.response_metadata\\n\\n{\\'token_usage\\': {\\'completion_tokens\\': 36,  \\'prompt_tokens\\': 16,  \\'total_tokens\\': 52}, \\'model_name\\': \\'gpt-4o\\', \\'system_fingerprint\\': \\'fp_aa87380ac5\\', \\'finish_reason\\': \\'stop\\', \\'logprobs\\': None}\\n\\nLogProb 활성화\\n\\n주어진 텍스트에 대한 모델의 토큰 확률의 로그 값 을 의미합니다. 토큰이란 문장을 구성하는 개별 단어나 문자 등의 요소를 의미하고, 확률은 모델이 그 토큰을 예측할 확률을 나타냅니다.\\n\\n# 객체 생성\\nllm_with_logprob = ChatOpenAI(\\n    temperature=0.1,  # 창의성 (0.0 ~ 2.0)\\n    max_tokens=2048,  # 최대 토큰수\\n    model_name=\"gpt-3.5-turbo\",  # 모델명\\n).bind(logprobs=True)\\n\\n# 질의내용\\nquestion = \"대한민국의 수도는 어디인가요?\"\\n\\n# 질의\\nresponse = llm_with_logprob.invoke(question)\\n\\n# 결과 출력\\nresponse.response_metadata\\n\\n{\\'token_usage\\': {\\'completion_tokens\\': 15,  \\'prompt_tokens\\': 24,  \\'total_tokens\\': 39}, \\'model_name\\': \\'gpt-3.5-turbo\\', \\'system_fingerprint\\': None, \\'finish_reason\\': \\'stop\\', \\'logprobs\\': {\\'content\\': [{\\'token\\': \\'대\\',    \\'bytes\\': [235, 140, 128],    \\'logprob\\': -0.03859115,    \\'top_logprobs\\': []},   {\\'token\\': \\'한\\',    \\'bytes\\': [237, 149, 156],    \\'logprob\\': -5.5122365e-07,    \\'top_logprobs\\': []},   {\\'token\\': \\'\\\\\\\\xeb\\\\\\\\xaf\\',    \\'bytes\\': [235, 175],    \\'logprob\\': -2.8160932e-06,    \\'top_logprobs\\': []},   {\\'token\\': \\'\\\\\\\\xbc\\', \\'bytes\\': [188], \\'logprob\\': 0.0, \\'top_logprobs\\': []},   {\\'token\\': \\'\\\\\\\\xea\\\\\\\\xb5\\',    \\'bytes\\': [234, 181],    \\'logprob\\': -6.704273e-07,    \\'top_logprobs\\': []},   {\\'token\\': \\'\\\\\\\\xad\\', \\'bytes\\': [173], \\'logprob\\': 0.0, \\'top_logprobs\\': []},   {\\'token\\': \\'의\\',    \\'bytes\\': [236, 157, 152],    \\'logprob\\': -6.2729996e-06,    \\'top_logprobs\\': []},   {\\'token\\': \\' 수\\',    \\'bytes\\': [32, 236, 136, 152],    \\'logprob\\': -5.5122365e-07,    \\'top_logprobs\\': []},   {\\'token\\': \\'도\\',    \\'bytes\\': [235, 143, 132],    \\'logprob\\': -5.5122365e-07,    \\'top_logprobs\\': []},   {\\'token\\': \\'는\\',    \\'bytes\\': [235, 138, 148],    \\'logprob\\': -1.9361265e-07,    \\'top_logprobs\\': []},   {\\'token\\': \\' 서\\',    \\'bytes\\': [32, 236, 132, 156],    \\'logprob\\': -5.080963e-06,    \\'top_logprobs\\': []},   {\\'token\\': \\'\\\\\\\\xec\\\\\\\\x9a\\',    \\'bytes\\': [236, 154],    \\'logprob\\': 0.0,    \\'top_logprobs\\': []},   {\\'token\\': \\'\\\\\\\\xb8\\', \\'bytes\\': [184], \\'logprob\\': 0.0, \\'top_logprobs\\': []},   {\\'token\\': \\'입니다\\',    \\'bytes\\': [236, 158, 133, 235, 139, 136, 235, 139, 164],    \\'logprob\\': -0.13815464,    \\'top_logprobs\\': []},   {\\'token\\': \\'.\\',    \\'bytes\\': [46],    \\'logprob\\': -9.0883464e-07,    \\'top_logprobs\\': []}]}}\\n\\n스트리밍 출력\\n\\n스트리밍 옵션은 질의에 대한 답변을 실시간으로 받을 때 유용합니다.\\n\\n# 스트림 방식으로 질의\\n# answer 에 스트리밍 답변의 결과를 받습니다.\\nanswer = llm.stream(\"대한민국의 아름다운 관광지 10곳과 주소를 알려주세요!\")\\n\\n# 스트리밍 방식으로 각 토큰을 출력합니다. (실시간 출력)\\nfor token in answer:\\n    print(token.content, end=\"\", flush=True)\\n\\n물론입니다! 대한민국에는 아름다운 관광지가 많이 있습니다. 다음은 그 중 10곳과 그 주소입니다:\\n\\n1. **경복궁**\\n   - 주소: 서울특별시 종로구 사직로 161\\n\\n2. **부산 해운대 해수욕장**\\n   - 주소: 부산광역시 해운대구 우동\\n\\n3. **제주도 한라산 국립공원**\\n   - 주소: 제주특별자치도 제주시 1100로 2070-61\\n\\n4. **경주 불국사**\\n   - 주소: 경상북도 경주시 불국로 385\\n\\n5. **설악산 국립공원**\\n   - 주소: 강원도 속초시 설악산로 833\\n\\n6. **남이섬**\\n   - 주소: 강원도 춘천시 남산면 남이섬길 1\\n\\n7. **안동 하회마을**\\n   - 주소: 경상북도 안동시 풍천면 하회종가길 40\\n\\n8. **전주 한옥마을**\\n   - 주소: 전라북도 전주시 완산구 기린대로 99\\n\\n9. **서울 남산타워 (N서울타워)**\\n   - 주소: 서울특별시 용산구 남산공원길 105\\n\\n10. **보성 녹차밭 대한다원**\\n    - 주소: 전라남도 보성군 보성읍 녹차로 763-67\\n\\n이 관광지들은 각기 다른 매력을 가지고 있어 다양한 경험을 할 수 있습니다. 즐거운 여행 되세요!\\n\\nfrom langchain_teddynote.messages import stream_response\\n\\n# 스트림 방식으로 질의\\n# answer 에 스트리밍 답변의 결과를 받습니다.\\nanswer = llm.stream(\"대한민국의 아름다운 관광지 10곳과 주소를 알려주세요!\")\\nstream_response(answer)\\n\\n물론입니다! 대한민국에는 아름다운 관광지가 많이 있습니다. 다음은 그 중 10곳과 그 주소입니다:\\n\\n1. **경복궁**\\n   - 주소: 서울특별시 종로구 사직로 161\\n\\n2. **부산 해운대 해수욕장**\\n   - 주소: 부산광역시 해운대구 우동\\n\\n3. **제주도 한라산 국립공원**\\n   - 주소: 제주특별자치도 제주시 1100로 2070-61\\n\\n4. **경주 불국사**\\n   - 주소: 경상북도 경주시 불국로 385\\n\\n5. **설악산 국립공원**\\n   - 주소: 강원도 속초시 설악산로 833\\n\\n6. **남이섬**\\n   - 주소: 강원도 춘천시 남산면 남이섬길 1\\n\\n7. **전주 한옥마을**\\n   - 주소: 전라북도 전주시 완산구 기린대로 99\\n\\n8. **안동 하회마을**\\n   - 주소: 경상북도 안동시 풍천면 하회종가길 40\\n\\n9. **서울 남산타워 (N서울타워)**\\n   - 주소: 서울특별시 용산구 남산공원길 105\\n\\n10. **순천만 국가정원**\\n    - 주소: 전라남도 순천시 국가정원1호길 47\\n\\n이 관광지들은 각기 다른 매력을 가지고 있어 다양한 경험을 할 수 있습니다. 즐거운 여행 되세요!\\n\\n멀티모달 모델(이미지 인식)\\n\\n멀티모달은 여러 가지 형태의 정보(모달)를 통합하여 처리하는 기술이나 접근 방식을 의미합니다. 이는 다음과 같은 다양한 데이터 유형을 포함할 수 있습니다.\\n\\n텍스트: 문서, 책, 웹 페이지 등의 글자로 된 정보\\n\\n이미지: 사진, 그래픽, 그림 등 시각적 정보\\n\\n오디오: 음성, 음악, 소리 효과 등의 청각적 정보\\n\\n비디오: 동영상 클립, 실시간 스트리밍 등 시각적 및 청각적 정보의 결합\\n\\ngpt-4o 나 gpt-4-turbo 모델은 이미지 인식 기능(Vision) 이 추가되어 있는 모델입니다.\\n\\nfrom langchain_teddynote.models import MultiModal\\nfrom langchain_teddynote.messages import stream_response\\n\\n# 객체 생성\\nllm = ChatOpenAI(\\n    temperature=0.1,  # 창의성 (0.0 ~ 2.0)\\n    max_tokens=2048,  # 최대 토큰수\\n    model_name=\"gpt-4o\",  # 모델명\\n)\\n\\n# 멀티모달 객체 생성\\nmultimodal_llm = MultiModal(llm)\\n\\n# 샘플 이미지 주소(웹사이트로 부터 바로 인식)\\nIMAGE_URL = \"https://t3.ftcdn.net/jpg/03/77/33/96/360_F_377339633_Rtv9I77sSmSNcev8bEcnVxTHrXB4nRJ5.jpg\"\\n\\n# 이미지 파일로 부터 질의\\nanswer = multimodal_llm.stream(IMAGE_URL)\\n# 스트리밍 방식으로 각 토큰을 출력합니다. (실시간 출력)\\nstream_response(answer)\\n\\n이 이미지는 표 형식의 데이터 테이블을 보여줍니다. 테이블의 제목은 \"TABLE 001: LOREM IPSUM DOLOR AMIS ENIMA ACCUMER TUNA\"입니다. 테이블은 다섯 개의 열과 여덟 개의 행으로 구성되어 있습니다.\\n\\n열 제목은 다음과 같습니다:\\n1. Loremis\\n2. Amis terim\\n3. Gato lepis\\n4. Tortores\\n\\n각 행의 데이터는 다음과 같습니다:\\n1. Lorem dolor siamet: 8,288, 123%, YES, $89\\n2. Consecter odio: 123, 87%, NO, $129\\n3. Gatoque accums: 1,005, 12%, NO, $199\\n4. Sed hac enim rem: 56, 69%, N/A, $199\\n5. Rempus tortor just: 5,554, 18%, NO, $999\\n6. Klimas nsecter: 455, 56%, NO, $245\\n7. Babiask atque accu: 1,222, 2%, YES, $977\\n8. Enim rem kos: 5,002, 91%, N/A, $522\\n\\n표 하단에는 작은 글씨로 Lorem ipsum 텍스트가 포함되어 있습니다.\\n\\n# 로컬 PC 에 저장되어 있는 이미지의 경로 입력\\nIMAGE_PATH_FROM_FILE = \"./images/sample-image.png\"\\n\\n# 이미지 파일로 부터 질의(스트림 방식)\\nanswer = multimodal_llm.stream(IMAGE_PATH_FROM_FILE)\\n# 스트리밍 방식으로 각 토큰을 출력합니다. (실시간 출력)\\nstream_response(answer)\\n\\n이미지 설명 대체 텍스트:\\n\\n이미지에는 \"FIRST OPENAI DEVDAY EVENT\"라는 제목이 상단에 크게 표시되어 있습니다. 이벤트 날짜는 2023년 11월 6일입니다. 주요 업데이트 항목으로는 GPT 4 Turbo, 128k Tokens, Custom GPTs, Assistant API, Price Reduction이 나열되어 있습니다.\\n\\n이미지 왼쪽 상단에는 \"ASTRA TECHZ\" 로고가 있습니다.\\n\\n이미지 중앙에는 \"MAIN UPDATES SUMMARISED\"라는 제목 아래 주요 업데이트 내용이 요약되어 있습니다. 각 항목 옆에는 체크 표시가 있으며, 세부 내용은 다음과 같습니다:\\n\\n- Token Length: 128K\\n- Custom GPTs: Private or Public\\n- Multi Modal: Img, Video, Voice\\n- JSON Mode: Guaranteed\\n- Assistant API: Developers\\n- Text 2 Speech: Beta Release\\n- Natural Voice Options: 6 Voices\\n- GPT Store: Revenue Shared\\n- Conversation Threading: Per Conversation\\n- File Uploading: Multiple\\n- API Price Reduction: 2.5x - 3.5x\\n- Code Interpreter: Built In\\n- Function Calling: Built In\\n\\n이미지 하단에는 \"visit www.astratechz.com to build AI solutions\"라는 문구가 있습니다.\\n\\nSystem, User 프롬프트 수정\\n\\nsystem_prompt = \"\"\"당신은 표(재무제표) 를 해석하는 금융 AI 어시스턴트 입니다. \\n당신의 임무는 주어진 테이블 형식의 재무제표를 바탕으로 흥미로운 사실을 정리하여 친절하게 답변하는 것입니다.\"\"\"\\n\\nuser_prompt = \"\"\"당신에게 주어진 표는 회사의 재무제표 입니다. 흥미로운 사실을 정리하여 답변하세요.\"\"\"\\n\\n# 멀티모달 객체 생성\\nmultimodal_llm_with_prompt = MultiModal(\\n    llm, system_prompt=system_prompt, user_prompt=user_prompt\\n)\\n\\n# 로컬 PC 에 저장되어 있는 이미지의 경로 입력\\nIMAGE_PATH_FROM_FILE = \"https://storage.googleapis.com/static.fastcampus.co.kr/prod/uploads/202212/080345-661/kwon-01.png\"\\n\\n# 이미지 파일로 부터 질의(스트림 방식)\\nanswer = multimodal_llm_with_prompt.stream(IMAGE_PATH_FROM_FILE)\\n\\n# 스트리밍 방식으로 각 토큰을 출력합니다. (실시간 출력)\\nstream_response(answer)\\n\\n주어진 재무제표를 바탕으로 몇 가지 흥미로운 사실을 정리해 보았습니다:\\n\\n1. **유동자산의 변화**:\\n   - 제 19기(2019년) 유동자산은 8,349,633백만원으로, 제 18기(2018년) 8,602,837백만원에 비해 감소하였습니다.\\n   - 특히 현금 및 현금성 자산이 제 18기 1,690,862백만원에서 제 19기 1,002,263백만원으로 크게 감소하였습니다.\\n\\n2. **매출채권**:\\n   - 매출채권은 제 18기 4,004,920백만원에서 제 19기 3,981,935백만원으로 소폭 감소하였습니다.\\n\\n3. **기타수취채권**:\\n   - 기타수취채권은 제 18기 321,866백만원에서 제 19기 366,141백만원으로 증가하였습니다.\\n\\n4. **비유동자산의 증가**:\\n   - 비유동자산은 제 18기 15,127,741백만원에서 제 19기 18,677,453백만원으로 크게 증가하였습니다.\\n   - 특히, 재고자산이 제 18기 2,426,364백만원에서 제 19기 2,670,294백만원으로 증가하였습니다.\\n\\n5. **기타유동자산**:\\n   - 기타유동자산은 제 18기 156,538백만원에서 제 19기 207,596백만원으로 증가하였습니다.\\n\\n6. **기타장기수취채권**:\\n   - 기타장기수취채권은 제 18기 118,086백만원에서 제 19기 505,489백만원으로 크게 증가하였습니다.\\n\\n이러한 변화들은 회사의 자산 구조와 재무 상태에 중요한 영향을 미칠 수 있으며, 특히 현금성 자산의 감소와 비유동자산의 증가가 눈에 띕니다. 이는 회사의 유동성 관리와 장기 투자 전략에 대한 추가적인 분석이 필요함을 시사합니다.\\n\\n마지막 편집일시 : 2024년 6월 18일 1:19 오전\\n\\n댓글 0 피드백\\n\\n※ 댓글 작성은 로그인이 필요합니다. (또는 피드백을 이용해 주세요.)\\n\\n이전글 : 02. LangSmith 추적 설정\\n\\n다음글 : 04. LangChain Expression Language(LCEL)\\n\\n책갈피\\n\\n이 페이지에 대한 피드백을 남겨주세요\\n\\n댓글을 신고합니다.', metadata={'source': 'https://wikidocs.net/233343'})]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "langchainwiki_flattened "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Chunking\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "임베딩 모델이 처리할 수 있는 적당한 크기로 raw data를 나누는 것은 매우 중요합니다. 이는 임베딩 모델마다 한 번에 처리할 수 있는 토큰 수의 한계가 있기 때문입니다. CLOVA Studio의 문단 나누기 API는 모델이 직접 문장들간의 의미 유사도를 찾아 최적의 chunk 개수와 사용자가 원하는 1개 chunk의 크기(글자 수)를 직접 설정하여 문단을 나눌 수도 있습니다. 추가로, 후처리(postProcess = True)를 통해 chunk당 글자 수의 상한선과 하한선을 postProcessMaxSize와 postProcessMinSize로 조절할 수도 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/7 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 1/7 [00:02<00:14,  2.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "{'status': {'code': '20000', 'message': 'OK'}, 'result': {'topicSeg': [['<랭체인LangChain 노트> - LangChain 한국어 튜토리얼🇰🇷 CH01 LangChain 시작하기'], ['01. OpenAI API 키 발급 및 테스트'], ['02. LangSmith 추적 설정'], ['03. OpenAI API 사용(GPT-4o 멀티모달)'], ['04. LangChain Expression Language(LCEL)'], ['05. LCEL 인터페이스'], ['06. Runnable CH02 프롬프트(Prompt)'], ['01. 프롬프트(Prompt)'], ['02. 퓨샷 프롬프트(FewShotPromptTemplate)'], ['03. LangChain Hub'], ['04. 개인화된 프롬프트(Hub에 업로드) CH03 출력 파서(Output Parsers)'], ['01. Pydantic 출력 파서(PydanticOutputParser)'], ['02. 콤마 구분자 출력 파서(CommaSeparatedListOutputParser)'], ['03. 구조화된 출력 파서(StructuredOuputParser)'], ['04. JSON 출력 파서(JsonOutputParser)'], ['05. 데이터프레임 출력 파서(PandasDataFrameOutputParser)'], ['06. 날짜 형식 출력 파서(DatetimeOutputParser)'], ['07. 열거형 출력 파서(EnumOutputParser)'], ['08. 출력 수정 파서(OutputFixingParser) CH04 모델(Model)'], ['01. 다양한 LLM 모델 활용'], ['02. 캐싱(Cache)'], ['03. 모델 직렬화(Serialization) - 저장 및 불러오기'], ['04. 토큰 사용량 확인'], ['05. 구글 생성 AI(Google Generative AI)'], ['06. 허깅페이스 엔드포인트(HuggingFace Endpoints)'], ['07. 허깅페이스 로컬(HuggingFace Local)'], ['08. 허깅페이스 파이프라인(HuggingFace Pipeline)'], ['09. 올라마(Ollama)'], ['10. GPT4ALL CH05 메모리(Memory)'], ['01. 대화 버퍼 메모리(ConversationBufferMemory)'], ['02. 대화 버퍼 윈도우 메모리(ConversationBufferWindowMemory)'], ['03. 대화 토큰 버퍼 메모리(ConversationTokenBufferMemory)'], ['04. 대화 엔티티 메모리(ConversationEntityMemory)'], ['05. 대화 지식그래프 메모리(ConversationKGMemory)'], ['06. 대화 요약 메모리(ConversationSummaryMemory)'], ['07. 벡터저장소 검색 메모리(VectorStoreRetrieverMemory)'], ['08. LCEL Chain 에 메모리 추가', '09. SQLite 에 대화내용 저장'], ['10. RunnableWithMessageHistory에 ChatMessageHistory추가 CH06 문서 로더(Document Loader)'], ['01. 도큐먼트(Document) 의 구조'], ['02. PDF'], ['03. 한글(HWP)'], ['04. CSV'], ['05. Excel'], ['06. Word'], ['07. PowerPoint'], ['08. 웹 문서(WebBaseLoader)'], ['09. 텍스트(TextLoader)'], ['10. JSON'], ['11. Arxiv'], ['13. UpstageLayoutAnalysisLoader'], ['14. LlamaParser CH07 텍스트 분할(Text Splitter)'], ['01. 문자 텍스트 분할(CharacterTextSplitter)'], ['02. 재귀적 문자 텍스트 분할(RecursiveCharacterTextSplitter)'], ['03. 토큰 텍스트 분할(TokenTextSplitter)'], ['04. 시멘틱 청커(SemanticChunker)'], ['05. 코드 분할(Python, Markdown, JAVA, C++, C#, GO, JS, Latex 등)'], ['06. 마크다운 헤더 텍스트 분할(MarkdownHeaderTextSplitter)'], ['07. HTML 헤더 텍스트 분할(HTMLHeaderTextSplitter)'], ['08. 재귀적 JSON 분할(RecursiveJsonSplitter) CH08 임베딩(Embedding)'], ['01. OpenAIEmbeddings'], ['02. 캐시 임베딩(CacheBackedEmbeddings)'], ['03. 허깅페이스 임베딩(HuggingFace Embeddings)'], ['04. UpstageEmbeddings'], ['05. OllamaEmbeddings'], ['06. GPT4ALL 임베딩'], ['07. Llama CPP 임베딩 CH09 벡터저장소(VectorStore)'], ['01. Chroma'], ['02. FAISS'], ['03. Pinecone CH10 검색기(Retriever)'], ['01. 벡터저장소 지원 검색기(VectorStore-backed Retriever)'], ['02. 문맥 압축 검색기(ContextualCompressionRetriever)'], ['03. 앙상블 검색기(EnsembleRetriever)'], ['04. 긴 문맥 재정렬(LongContextReorder)'], ['05. 상위 문서 검색기(ParentDocumentRetriever)'], ['06. 다중 쿼리 검색기(MultiQueryRetriever)'], ['07. 다중 벡터저장소 검색기(MultiVectorRetriever)'], ['08. 셀프 쿼리 검색기(SelfQueryRetriever)'], ['09. 시간 가중 벡터저장소 검색기(TimeWeightedVectorStoreRetriever)'], ['10. 한글 형태소 분석기(Kiwi, Kkma, Okt) + BM25 검색기 CH11 리랭커(Reranker)'], ['01. Cross Encoder Reranker'], ['02. Cohere Reranker'], ['03. Jina Reranker'], ['04. FlashRank Reranker CH12 Retrieval Augmented Generation(RAG)'], ['01. PDF 문서 기반 QA(Question-Answer)'], ['02. 네이버 뉴스기사 QA(Question-Answer)'], ['03. RAG 의 기능별 다양한 모듈 활용기'], ['04. RAPTOR: 긴 문맥 요약(Long Context Summary)'], ['05. 대화내용을 기억하는 RAG 체인 CH13 LangChain Expression Language(LCEL)'], ['01. RunnablePassthrough: 데이터 전달'], ['02. Runnable 구조(그래프) 확인'], ['03. RunnableLambda: 사용자 정의 함수'], ['04. RunnableBranch: 라우팅(Routing)'], ['05. RunnableParallel: 병렬 처리'], ['06. configurable_fields, configurable_alternatives 07. @chain 데코레이터로 Runnable 생성', '08. RunnableWithMessageHistory'], ['09. 사용자 정의 제네레이터(generator)'], ['10. Runtime Arguments 바인딩'], ['11. 폴백(fallback) 모델 지정 CH14 체인(Chains)'], ['01. 문서 요약'], ['02. SQL CH15 에이전트(Agent)'], ['01. Agent 사용법 톺아보기'], ['02. 도구를 활용한 토론 에이전트(Two Agent Debates with Tools) CH16 파인튜닝(Fine Tuning)'], ['CH17 LangGraph'], ['01. Chain of Table for Multiple Tables'], ['Published with WikiDocs'], ['<랭체인LangChain 노트> - Lang…'], ['CH01 LangChain 시작하기', '위키독스'], ['CH01 LangChain 시작하기'], ['🦜️🔗 랭체인 LangChain'], ['LangChain 은 언어 모델을 활용해 다양한 애플리케이션을 개발할 수 있는 프레임워크를 말합니다.', '이 프레임워크를 통해 언어 모델은 다음과 같은 기능을 수행할 수 있게 됩니다.'], ['문맥을 인식하는 기능: LangChain은 언어 모델을 다양한 문맥 소스와 연결합니다.', '여기에는 프롬프트 지시사항, 소수의 예시, 응답에 근거한 내용 등이 포함됩니다.', '이를 통해 언어 모델은 제공된 정보를 기반으로 더 정확하고 관련성 높은 답변을 생성할 수 있습니다.', '추론하는 기능: 또한, 언어 모델은 주어진 문맥을 바탕으로 어떠한 답변을 제공하거나, 어떤 조치를 취해야 할지를 스스로 추론할 수 있습니다.', '이는 언어 모델이 단순히 정보를 재생산하는 것을 넘어서, 주어진 상황을 분석하고 적절한 해결책을 제시할 수 있음을 의미합니다.', 'LangChain 을 활용하면 이전에 언급한 기능을 바탕으로 검색 증강 생성(RAG) 어플리케이션 제작, 구조화된 데이터 분석, 챗봇 등을 만들 수 있습니다.'], ['더 많은 예제는 유튜브 채널 테디노트 에서 확인하실 수 있습니다.'], ['설치'], ['권장하는 파이썬 버전은 3.11 버전입니다.'], ['pip 를 이용한 설치', 'pip install -r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt'], ['최소한의 기능만 설치하기 위한 mini 버전 (일부 패키지만 설치하는 경우)'], ['pip install -r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements-mini.txt'], ['구성'], ['이 프레임워크는 여러 부분으로 구성되어 있습니다.'], ['LangChain 라이브러리: Python 및 JavaScript 라이브러리.'], ['다양한 컴포넌트의 인터페이스와 통합, 이러한 컴포넌트를 체인과 에이전트로 결합하는 기본 런타임, 그리고 즉시 사용 가능한 체인과 에이전트의 구현을 포함합니다.'], ['LangChain 템플릿: 다양한 작업을 위한 쉽게 배포할 수 있는 참조 아키텍처 모음입니다.'], ['LangServe: LangChain 체인을 REST API로 배포하기 위한 라이브러리입니다.'], ['LangSmith: 어떤 LLM 프레임워크에도 구축된 체인을 디버그, 테스트, 평가, 모니터링할 수 있게 해주며 LangChain과 원활하게 통합되는 개발자 플랫폼입니다.'], ['LangGraph: LLM을 사용한 상태유지가 가능한 다중 액터 애플리케이션을 구축하기 위한 라이브러리로, LangChain 위에 구축되었으며 LangChain과 함께 사용하도록 설계되었습니다.', '여러 계산 단계에서 다중 체인(또는 액터)을 순환 방식으로 조정할 수 있는 능력을 LangChain 표현 언어에 추가합니다.'], ['개발 용이성✨'], ['컴포넌트의 조립 및 통합 🔧', 'LangChain은 언어 모델과의 작업을 위한 조립 가능한 도구 및 통합을 제공합니다.', '컴포넌트는 모듈식으로 설계되어, 사용하기 쉽습니다.', '이는 개발자가 LangChain 프레임워크를 자유롭게 활용할 수 있게 해줍니다.', '즉시 사용 가능한 체인 🚀', '고수준 작업을 수행하기 위한 컴포넌트의 내장 조합을 제공합니다.', '이러한 체인은 개발 과정을 간소화하고 속도를 높여줍니다.'], ['주요 모듈 📌', '모델 I/O 📃', '프롬프트 관리, 최적화 및 LLM과의 일반적인 인터페이스와 작업을 위한 유틸리티를 포함합니다.'], ['검색 📚'], [\"'데이터 강화 생성'에 초점을 맞춘 이 모듈은 생성 단계에서 필요한 데이터를 외부 데이터 소스에서 가져오는 작업을 담당합니다.\"], ['에이전트 🤖'], ['언어 모델이 어떤 조치를 취할지 결정하고, 해당 조치를 실행하며, 관찰하고, 필요한 경우 반복하는 과정을 포함합니다.'], ['LangChain을 활용하면, 언어 모델 기반 애플리케이션의 개발을 보다 쉽게 시작할 수 있으며, 필요에 맞게 기능을 맞춤 설정하고, 다양한 데이터 소스와 통합하여 복잡한 작업을 처리할 수 있게 됩니다.'], ['마지막 편집일시 : 2024년 7월 16일 2:40 오전'], ['댓글 0 피드백', '※ 댓글 작성은 로그인이 필요합니다.', '(또는 피드백을 이용해 주세요.)'], ['이전글 : <랭체인LangChain 노트> - LangChain 한국어 튜토리얼🇰🇷'], ['다음글 : 01.'], ['OpenAI API 키 발급 및 테스트'], ['책갈피'], ['이 페이지에 대한 피드백을 남겨주세요'], ['댓글을 신고합니다.']], 'span': [[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15], [16], [17], [18], [19], [20], [21], [22], [23], [24], [25], [26], [27], [28], [29], [30], [31], [32], [33], [34], [35], [36, 37], [38], [39], [40], [41], [42], [43], [44], [45], [46], [47], [48], [49], [50], [51], [52], [53], [54], [55], [56], [57], [58], [59], [60], [61], [62], [63], [64], [65], [66], [67], [68], [69], [70], [71], [72], [73], [74], [75], [76], [77], [78], [79], [80], [81], [82], [83], [84], [85], [86], [87], [88], [89], [90], [91], [92], [93], [94, 95], [96], [97], [98], [99], [100], [101], [102], [103], [104], [105], [106], [107, 108], [109], [110], [111, 112], [113, 114, 115, 116, 117, 118], [119], [120], [121], [122, 123], [124], [125], [126], [127], [128], [129], [130], [131], [132], [133, 134], [135], [136, 137, 138, 139, 140, 141, 142], [143, 144, 145], [146], [147], [148], [149], [150], [151], [152, 153, 154], [155], [156], [157], [158], [159], [160]], 'inputTokens': 4016}}\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▊       | 2/7 [00:06<00:16,  3.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "{'status': {'code': '20000', 'message': 'OK'}, 'result': {'topicSeg': [['<랭체인LangChain 노트> - LangChain 한국어 튜토리얼🇰🇷 CH01 LangChain 시작하기'], ['01. OpenAI API 키 발급 및 테스트'], ['02. LangSmith 추적 설정'], ['03. OpenAI API 사용(GPT-4o 멀티모달)'], ['04. LangChain Expression Language(LCEL)'], ['05. LCEL 인터페이스'], ['06. Runnable CH02 프롬프트(Prompt)'], ['01. 프롬프트(Prompt)'], ['02. 퓨샷 프롬프트(FewShotPromptTemplate)'], ['03. LangChain Hub'], ['04. 개인화된 프롬프트(Hub에 업로드) CH03 출력 파서(Output Parsers)'], ['01. Pydantic 출력 파서(PydanticOutputParser)'], ['02. 콤마 구분자 출력 파서(CommaSeparatedListOutputParser)'], ['03. 구조화된 출력 파서(StructuredOuputParser)'], ['04. JSON 출력 파서(JsonOutputParser)'], ['05. 데이터프레임 출력 파서(PandasDataFrameOutputParser)'], ['06. 날짜 형식 출력 파서(DatetimeOutputParser)'], ['07. 열거형 출력 파서(EnumOutputParser)'], ['08. 출력 수정 파서(OutputFixingParser) CH04 모델(Model)'], ['01. 다양한 LLM 모델 활용'], ['02. 캐싱(Cache)'], ['03. 모델 직렬화(Serialization) - 저장 및 불러오기'], ['04. 토큰 사용량 확인'], ['05. 구글 생성 AI(Google Generative AI)'], ['06. 허깅페이스 엔드포인트(HuggingFace Endpoints)'], ['07. 허깅페이스 로컬(HuggingFace Local)'], ['08. 허깅페이스 파이프라인(HuggingFace Pipeline)'], ['09. 올라마(Ollama)'], ['10. GPT4ALL CH05 메모리(Memory)'], ['01. 대화 버퍼 메모리(ConversationBufferMemory)'], ['02. 대화 버퍼 윈도우 메모리(ConversationBufferWindowMemory)'], ['03. 대화 토큰 버퍼 메모리(ConversationTokenBufferMemory)'], ['04. 대화 엔티티 메모리(ConversationEntityMemory)'], ['05. 대화 지식그래프 메모리(ConversationKGMemory)'], ['06. 대화 요약 메모리(ConversationSummaryMemory)'], ['07. 벡터저장소 검색 메모리(VectorStoreRetrieverMemory)'], ['08. LCEL Chain 에 메모리 추가', '09. SQLite 에 대화내용 저장'], ['10. RunnableWithMessageHistory에 ChatMessageHistory추가 CH06 문서 로더(Document Loader)'], ['01. 도큐먼트(Document) 의 구조'], ['02. PDF'], ['03. 한글(HWP)'], ['04. CSV'], ['05. Excel'], ['06. Word'], ['07. PowerPoint'], ['08. 웹 문서(WebBaseLoader)'], ['09. 텍스트(TextLoader)'], ['10. JSON'], ['11. Arxiv'], ['13. UpstageLayoutAnalysisLoader'], ['14. LlamaParser CH07 텍스트 분할(Text Splitter)'], ['01. 문자 텍스트 분할(CharacterTextSplitter)'], ['02. 재귀적 문자 텍스트 분할(RecursiveCharacterTextSplitter)'], ['03. 토큰 텍스트 분할(TokenTextSplitter)'], ['04. 시멘틱 청커(SemanticChunker)'], ['05. 코드 분할(Python, Markdown, JAVA, C++, C#, GO, JS, Latex 등)'], ['06. 마크다운 헤더 텍스트 분할(MarkdownHeaderTextSplitter)'], ['07. HTML 헤더 텍스트 분할(HTMLHeaderTextSplitter)'], ['08. 재귀적 JSON 분할(RecursiveJsonSplitter) CH08 임베딩(Embedding)'], ['01. OpenAIEmbeddings'], ['02. 캐시 임베딩(CacheBackedEmbeddings)'], ['03. 허깅페이스 임베딩(HuggingFace Embeddings)'], ['04. UpstageEmbeddings'], ['05. OllamaEmbeddings'], ['06. GPT4ALL 임베딩'], ['07. Llama CPP 임베딩 CH09 벡터저장소(VectorStore)'], ['01. Chroma'], ['02. FAISS'], ['03. Pinecone CH10 검색기(Retriever)'], ['01. 벡터저장소 지원 검색기(VectorStore-backed Retriever)'], ['02. 문맥 압축 검색기(ContextualCompressionRetriever)'], ['03. 앙상블 검색기(EnsembleRetriever)'], ['04. 긴 문맥 재정렬(LongContextReorder)'], ['05. 상위 문서 검색기(ParentDocumentRetriever)'], ['06. 다중 쿼리 검색기(MultiQueryRetriever)'], ['07. 다중 벡터저장소 검색기(MultiVectorRetriever)'], ['08. 셀프 쿼리 검색기(SelfQueryRetriever)'], ['09. 시간 가중 벡터저장소 검색기(TimeWeightedVectorStoreRetriever)'], ['10. 한글 형태소 분석기(Kiwi, Kkma, Okt) + BM25 검색기 CH11 리랭커(Reranker)'], ['01. Cross Encoder Reranker'], ['02. Cohere Reranker'], ['03. Jina Reranker'], ['04. FlashRank Reranker CH12 Retrieval Augmented Generation(RAG)'], ['01. PDF 문서 기반 QA(Question-Answer)'], ['02. 네이버 뉴스기사 QA(Question-Answer)'], ['03. RAG 의 기능별 다양한 모듈 활용기'], ['04. RAPTOR: 긴 문맥 요약(Long Context Summary)'], ['05. 대화내용을 기억하는 RAG 체인 CH13 LangChain Expression Language(LCEL)'], ['01. RunnablePassthrough: 데이터 전달'], ['02. Runnable 구조(그래프) 확인'], ['03. RunnableLambda: 사용자 정의 함수'], ['04. RunnableBranch: 라우팅(Routing)'], ['05. RunnableParallel: 병렬 처리'], ['06. configurable_fields, configurable_alternatives 07. @chain 데코레이터로 Runnable 생성', '08. RunnableWithMessageHistory'], ['09. 사용자 정의 제네레이터(generator)'], ['10. Runtime Arguments 바인딩'], ['11. 폴백(fallback) 모델 지정 CH14 체인(Chains)'], ['01. 문서 요약'], ['02. SQL CH15 에이전트(Agent)'], ['01. Agent 사용법 톺아보기'], ['02. 도구를 활용한 토론 에이전트(Two Agent Debates with Tools) CH16 파인튜닝(Fine Tuning)'], ['CH17 LangGraph'], ['01. Chain of Table for Multiple Tables'], ['Published with WikiDocs'], ['<랭체인LangChain 노트> - Lang…'], ['CH01 LangChain 시작하기'], ['06. Runnable'], ['위키독스'], ['06. Runnable'], ['# .env 파일을 읽어서 환경변수로 설정', 'from dotenv import load_dotenv'], ['# 토큰 정보로드'], ['load_dotenv()'], ['True'], ['# LangSmith 추적을 설정합니다.', 'https://smith.langchain.com'], ['# !pip install -qU langchain-teddynote'], ['from langchain_teddynote import logging', '# 프로젝트 이름을 입력합니다.', 'logging.langsmith(\"CH01-Basic\")'], ['LangSmith 추적을 시작합니다.'], ['[프로젝트명]'], ['CH01-Basic'], ['데이터를 효과적으로 전달하는 방법'], ['RunnablePassthrough 는 입력을 변경하지 않거나 추가 키를 더하여 전달할 수 있습니다.', 'RunnablePassthrough() 가 단독으로 호출되면, 단순히 입력을 받아 그대로 전달합니다.', 'RunnablePassthrough.assign(...)'], ['방식으로 호출되면, 입력을 받아 assign 함수에 전달된 추가 인수를 추가합니다.'], ['RunnablePassthrough'], ['from langchain_core.prompts import PromptTemplate'], ['from langchain_openai import ChatOpenAI'], ['# prompt 와 llm 을 생성합니다.', 'prompt = PromptTemplate.from_template(\"{num} 의 10배는?\")', 'llm = ChatOpenAI(temperature=0)'], ['# chain 을 생성합니다.', 'chain = prompt | llm', 'chain 을 invoke() 하여 실행할 때는 입력 데이터의 타입이 딕셔너리여야 합니다.'], ['# chain 을 실행합니다.', 'chain.invoke({\"num\": 5})'], [\"AIMessage(content='50입니다.', response_metadata={'token_usage': {'completion_tokens': 3, 'prompt_tokens': 16, 'total_tokens': 19}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-29242a8b-01c0-41ad-8f5b-7613e6876dc5-0', usage_metadata={'input_tokens': 16, 'output_tokens': 3, 'total_tokens': 19})\"], ['하지만, langchain 라이브러리가 업데이트 되면서 1개의 변수만 템플릿에 포함하고 있다면, 값만 전달하는 것도 가능합니다.'], ['# chain 을 실행합니다.'], ['chain.invoke(5)'], [\"AIMessage(content='50', response_metadata={'token_usage': {'completion_tokens': 1, 'prompt_tokens': 16, 'total_tokens': 17}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-44f606db-2437-4d1f-9cee-ddfc69428745-0', usage_metadata={'input_tokens': 16, 'output_tokens': 1, 'total_tokens': 17})\"], ['아래는 RunnablePassthrough 를 사용한 예제입니다.'], ['RunnablePassthrough 는 runnable 객체이며, runnable 객체는 invoke() 메소드를 사용하여 별도 실행이 가능합니다.'], ['from langchain_core.runnables import RunnablePassthrough'], ['# runnable'], ['RunnablePassthrough().invoke({\"num\": 10})'], [\"{'num': 10}\"], ['아래는 RunnablePassthrough 로 체인을 구성하는 예제입니다.', 'runnable_chain = {\"num\": RunnablePassthrough()} | prompt | ChatOpenAI()'], ['# dict 값이 RunnablePassthrough() 로 변경되었습니다.'], ['runnable_chain.invoke(10)'], [\"AIMessage(content='100입니다.', response_metadata={'token_usage': {'completion_tokens': 3, 'prompt_tokens': 16, 'total_tokens': 19}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-66270ca2-4d62-4c71-859b-de6318f29909-0', usage_metadata={'input_tokens': 16, 'output_tokens': 3, 'total_tokens': 19})\"], ['다음은 RunnablePassthrough.assign() 을 사용하는 경우와 비교한 결과입니다.'], ['RunnablePassthrough().invoke({\"num\": 1})'], [\"{'num': 1}\"], ['RunnablePassthrough.assign()'], ['입력 값으로 들어온 값의 key/value 쌍과 새롭게 할당된 key/value 쌍을 합칩니다.'], ['# 입력 키: num, 할당(assign) 키: new_num'], ['(RunnablePassthrough.assign(new_num=lambda x: x[\"num\"] * 3)).invoke({\"num\": 1})'], [\"{'num': 1, 'new_num': 3}\"], ['RunnableParallel'], ['from langchain_core.runnables import RunnableParallel'], ['# RunnableParallel 인스턴스를 생성합니다.', '이 인스턴스는 여러 Runnable 인스턴스를 병렬로 실행할 수 있습니다.', 'runnable = RunnableParallel('], [\"# RunnablePassthrough 인스턴스를 'passed' 키워드 인자로 전달합니다.\", '이는 입력된 데이터를 그대로 통과시키는 역할을 합니다.', 'passed=RunnablePassthrough(),'], [\"# 'extra' 키워드 인자로 RunnablePassthrough.assign을 사용하여, 'mult' 람다 함수를 할당합니다.\", \"이 함수는 입력된 딕셔너리의 'num' 키에 해당하는 값을 3배로 증가시킵니다.\"], ['extra=RunnablePassthrough.assign(mult=lambda x: x[\"num\"] * 3),'], [\"# 'modified' 키워드 인자로 람다 함수를 전달합니다.\", \"이 함수는 입력된 딕셔너리의 'num' 키에 해당하는 값에 1을 더합니다.\", 'modified=lambda x: x[\"num\"] + 1,'], [')'], [\"# runnable 인스턴스에 {'num': 1} 딕셔너리를 입력으로 전달하여 invoke 메소드를 호출합니다.\", 'runnable.invoke({\"num\": 1})'], [\"{'passed': {'num': 1}, 'extra': {'num': 1, 'mult': 3}, 'modified': 2}\"], ['Chain 도 RunnableParallel 적용할 수 있습니다.'], ['chain1 = ('], ['{\"country\": RunnablePassthrough()}'], ['| PromptTemplate.from_template(\"{country} 의 수도는?\")'], ['| ChatOpenAI()'], [')'], ['chain2 = ('], ['{\"country\": RunnablePassthrough()}'], ['| PromptTemplate.from_template(\"{country} 의 면적은?\")'], ['| ChatOpenAI()'], [')'], ['combined_chain = RunnableParallel(capital=chain1, area=chain2)'], ['combined_chain.invoke(\"대한민국\")'], [\"{'capital': AIMessage(content='서울입니다.', response_metadata={'token_usage': {'completion_tokens': 5, 'prompt_tokens': 19, 'total_tokens': 24}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-d9324c24-9670-4430-97d6-1272f5dbe0f2-0', usage_metadata={'input_tokens': 19, 'output_tokens': 5, 'total_tokens': 24}), 'area': AIMessage(content='대한민국의 총 면적은 약 100,363 km²입니다.', response_metadata={'token_usage': {'completion_tokens': 24, 'prompt_tokens': 20, 'total_tokens': 44}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-f27442a3-fc9c-4d08-9fdf-189c1b4585c8-0', usage_metadata={'input_tokens': 20, 'output_tokens': 24, 'total_tokens': 44})}\"], ['RunnableLambda'], ['RunnableLambda 를 사용하여 사용자 정의 함수를 맵핑할 수 있습니다.'], ['from langchain_core.output_parsers import StrOutputParser'], ['from langchain_core.prompts import PromptTemplate'], ['from langchain_openai import ChatOpenAI'], ['from datetime import datetime'], ['def get_today(a):'], ['# 오늘 날짜를 가져오기', 'return datetime.today().strftime(\"%b-%d\")'], ['# 오늘 날짜를 출력'], ['get_today(None)'], [\"'Jun-19'\"], ['from langchain_core.runnables import RunnableLambda, RunnablePassthrough'], ['# prompt 와 llm 을 생성합니다.', 'prompt = PromptTemplate.from_template('], ['\"{today} 가 생일인 유명인 {n} 명을 나열하세요.', '생년월일을 표기해 주세요.\"'], [')'], ['llm = ChatOpenAI(temperature=0, model_name=\"gpt-4o\")'], ['# chain 을 생성합니다.', 'chain = ('], ['{\"today\": RunnableLambda(get_today), \"n\": RunnablePassthrough()}'], ['| prompt'], ['| llm'], ['| StrOutputParser()'], [')'], ['# 출력'], ['print(chain.invoke(3))'], ['다음은 6월 19일이 생일인 몇몇 유명인들입니다:'], ['1. 폴 도노반 (Paul Dano) - 1984년 6월 19일'], ['2. 디렉 노박 조코비치 (Novak Djokovic) - 1987년 6월 19일'], ['3. 필리페 쿠티뉴 (Philippe Coutinho) - 1992년 6월 19일'], ['이들은 각각 배우, 테니스 선수, 축구 선수로서 다양한 분야에서 활동하고 있습니다.'], ['itemgetter 를 사용하여 특정 키를 추출합니다.'], ['from operator import itemgetter'], ['from langchain_core.prompts import ChatPromptTemplate'], ['from langchain_core.runnables import RunnableLambda'], ['from langchain_openai import ChatOpenAI'], ['# 문장의 길이를 반환하는 함수입니다.'], ['def length_function(text):', 'return len(text)'], ['# 두 문장의 길이를 곱한 값을 반환하는 함수입니다.'], ['def _multiple_length_function(text1, text2):'], ['return len(text1) * len(text2)'], ['# _multiple_length_function 함수를 사용하여 두 문장의 길이를 곱한 값을 반환하는 함수입니다.'], ['def multiple_length_function(_dict):'], ['return _multiple_length_function(_dict[\"text1\"], _dict[\"text2\"])'], ['prompt = ChatPromptTemplate.from_template(\"{a} + {b} 는 무엇인가요?\")', 'model = ChatOpenAI()'], ['chain1 = prompt | model'], ['chain = ('], ['{'], ['\"a\": itemgetter(\"word1\") | RunnableLambda(length_function),'], ['\"b\": {\"text1\": itemgetter(\"word1\"), \"text2\": itemgetter(\"word2\")}'], ['| RunnableLambda(multiple_length_function),'], ['}'], ['| prompt'], ['| model'], [')'], ['chain.invoke({\"word1\": \"hello\", \"word2\": \"world\"})'], [\"AIMessage(content='5 + 25 = 30입니다.', response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 22, 'total_tokens': 31}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-5db9b475-09ee-4edb-af9d-b37b320bee1e-0', usage_metadata={'input_tokens': 22, 'output_tokens': 9, 'total_tokens': 31})\"], ['마지막 편집일시 : 2024년 6월 19일 10:59 오후'], ['댓글 0 피드백'], ['※ 댓글 작성은 로그인이 필요합니다.', '(또는 피드백을 이용해 주세요.)'], ['이전글 : 05.'], ['LCEL 인터페이스'], ['다음글 : CH02 프롬프트(Prompt)'], ['책갈피'], ['이 페이지에 대한 피드백을 남겨주세요'], ['댓글을 신고합니다.']], 'span': [[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15], [16], [17], [18], [19], [20], [21], [22], [23], [24], [25], [26], [27], [28], [29], [30], [31], [32], [33], [34], [35], [36, 37], [38], [39], [40], [41], [42], [43], [44], [45], [46], [47], [48], [49], [50], [51], [52], [53], [54], [55], [56], [57], [58], [59], [60], [61], [62], [63], [64], [65], [66], [67], [68], [69], [70], [71], [72], [73], [74], [75], [76], [77], [78], [79], [80], [81], [82], [83], [84], [85], [86], [87], [88], [89], [90], [91], [92], [93], [94, 95], [96], [97], [98], [99], [100], [101], [102], [103], [104], [105], [106], [107], [108], [109], [110], [111, 112], [113], [114], [115], [116, 117], [118], [119, 120, 121], [122], [123], [124], [125], [126, 127, 128], [129], [130], [131], [132], [133, 134, 135], [136, 137, 138], [139, 140], [141], [142], [143], [144], [145], [146], [147], [148], [149], [150], [151], [152, 153], [154], [155], [156], [157], [158], [159], [160], [161], [162], [163], [164], [165], [166], [167, 168, 169], [170, 171, 172], [173, 174], [175], [176, 177, 178], [179], [180, 181], [182], [183], [184], [185], [186], [187], [188], [189], [190], [191], [192], [193], [194], [195], [196], [197], [198], [199], [200], [201], [202], [203], [204, 205], [206], [207], [208], [209], [210, 211], [212, 213], [214], [215], [216, 217], [218], [219], [220], [221], [222], [223], [224], [225], [226], [227], [228], [229], [230], [231], [232], [233], [234], [235], [236, 237], [238], [239], [240], [241], [242], [243], [244, 245], [246], [247], [248], [249], [250], [251], [252], [253], [254], [255], [256], [257], [258], [259], [260, 261], [262], [263], [264], [265], [266], [267]], 'inputTokens': 7404}}\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 3/7 [00:10<00:15,  3.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "{'status': {'code': '20000', 'message': 'OK'}, 'result': {'topicSeg': [['<랭체인LangChain 노트> - LangChain 한국어 튜토리얼🇰🇷 CH01 LangChain 시작하기'], ['01. OpenAI API 키 발급 및 테스트'], ['02. LangSmith 추적 설정'], ['03. OpenAI API 사용(GPT-4o 멀티모달)'], ['04. LangChain Expression Language(LCEL)'], ['05. LCEL 인터페이스'], ['06. Runnable CH02 프롬프트(Prompt)'], ['01. 프롬프트(Prompt)'], ['02. 퓨샷 프롬프트(FewShotPromptTemplate)'], ['03. LangChain Hub'], ['04. 개인화된 프롬프트(Hub에 업로드) CH03 출력 파서(Output Parsers)'], ['01. Pydantic 출력 파서(PydanticOutputParser)'], ['02. 콤마 구분자 출력 파서(CommaSeparatedListOutputParser)'], ['03. 구조화된 출력 파서(StructuredOuputParser)'], ['04. JSON 출력 파서(JsonOutputParser)'], ['05. 데이터프레임 출력 파서(PandasDataFrameOutputParser)'], ['06. 날짜 형식 출력 파서(DatetimeOutputParser)'], ['07. 열거형 출력 파서(EnumOutputParser)'], ['08. 출력 수정 파서(OutputFixingParser) CH04 모델(Model)'], ['01. 다양한 LLM 모델 활용'], ['02. 캐싱(Cache)'], ['03. 모델 직렬화(Serialization) - 저장 및 불러오기'], ['04. 토큰 사용량 확인'], ['05. 구글 생성 AI(Google Generative AI)'], ['06. 허깅페이스 엔드포인트(HuggingFace Endpoints)'], ['07. 허깅페이스 로컬(HuggingFace Local)'], ['08. 허깅페이스 파이프라인(HuggingFace Pipeline)'], ['09. 올라마(Ollama)'], ['10. GPT4ALL CH05 메모리(Memory)'], ['01. 대화 버퍼 메모리(ConversationBufferMemory)'], ['02. 대화 버퍼 윈도우 메모리(ConversationBufferWindowMemory)'], ['03. 대화 토큰 버퍼 메모리(ConversationTokenBufferMemory)'], ['04. 대화 엔티티 메모리(ConversationEntityMemory)'], ['05. 대화 지식그래프 메모리(ConversationKGMemory)'], ['06. 대화 요약 메모리(ConversationSummaryMemory)'], ['07. 벡터저장소 검색 메모리(VectorStoreRetrieverMemory)'], ['08. LCEL Chain 에 메모리 추가', '09. SQLite 에 대화내용 저장'], ['10. RunnableWithMessageHistory에 ChatMessageHistory추가 CH06 문서 로더(Document Loader)'], ['01. 도큐먼트(Document) 의 구조'], ['02. PDF'], ['03. 한글(HWP)'], ['04. CSV'], ['05. Excel'], ['06. Word'], ['07. PowerPoint'], ['08. 웹 문서(WebBaseLoader)'], ['09. 텍스트(TextLoader)'], ['10. JSON'], ['11. Arxiv'], ['13. UpstageLayoutAnalysisLoader'], ['14. LlamaParser CH07 텍스트 분할(Text Splitter)'], ['01. 문자 텍스트 분할(CharacterTextSplitter)'], ['02. 재귀적 문자 텍스트 분할(RecursiveCharacterTextSplitter)'], ['03. 토큰 텍스트 분할(TokenTextSplitter)'], ['04. 시멘틱 청커(SemanticChunker)'], ['05. 코드 분할(Python, Markdown, JAVA, C++, C#, GO, JS, Latex 등)'], ['06. 마크다운 헤더 텍스트 분할(MarkdownHeaderTextSplitter)'], ['07. HTML 헤더 텍스트 분할(HTMLHeaderTextSplitter)'], ['08. 재귀적 JSON 분할(RecursiveJsonSplitter) CH08 임베딩(Embedding)'], ['01. OpenAIEmbeddings'], ['02. 캐시 임베딩(CacheBackedEmbeddings)'], ['03. 허깅페이스 임베딩(HuggingFace Embeddings)'], ['04. UpstageEmbeddings'], ['05. OllamaEmbeddings'], ['06. GPT4ALL 임베딩'], ['07. Llama CPP 임베딩 CH09 벡터저장소(VectorStore)'], ['01. Chroma'], ['02. FAISS'], ['03. Pinecone CH10 검색기(Retriever)'], ['01. 벡터저장소 지원 검색기(VectorStore-backed Retriever)'], ['02. 문맥 압축 검색기(ContextualCompressionRetriever)'], ['03. 앙상블 검색기(EnsembleRetriever)'], ['04. 긴 문맥 재정렬(LongContextReorder)'], ['05. 상위 문서 검색기(ParentDocumentRetriever)'], ['06. 다중 쿼리 검색기(MultiQueryRetriever)'], ['07. 다중 벡터저장소 검색기(MultiVectorRetriever)'], ['08. 셀프 쿼리 검색기(SelfQueryRetriever)'], ['09. 시간 가중 벡터저장소 검색기(TimeWeightedVectorStoreRetriever)'], ['10. 한글 형태소 분석기(Kiwi, Kkma, Okt) + BM25 검색기 CH11 리랭커(Reranker)'], ['01. Cross Encoder Reranker'], ['02. Cohere Reranker'], ['03. Jina Reranker'], ['04. FlashRank Reranker CH12 Retrieval Augmented Generation(RAG)'], ['01. PDF 문서 기반 QA(Question-Answer)'], ['02. 네이버 뉴스기사 QA(Question-Answer)'], ['03. RAG 의 기능별 다양한 모듈 활용기'], ['04. RAPTOR: 긴 문맥 요약(Long Context Summary)'], ['05. 대화내용을 기억하는 RAG 체인 CH13 LangChain Expression Language(LCEL)'], ['01. RunnablePassthrough: 데이터 전달'], ['02. Runnable 구조(그래프) 확인'], ['03. RunnableLambda: 사용자 정의 함수'], ['04. RunnableBranch: 라우팅(Routing)'], ['05. RunnableParallel: 병렬 처리'], ['06. configurable_fields, configurable_alternatives 07. @chain 데코레이터로 Runnable 생성', '08. RunnableWithMessageHistory'], ['09. 사용자 정의 제네레이터(generator)'], ['10. Runtime Arguments 바인딩'], ['11. 폴백(fallback) 모델 지정 CH14 체인(Chains)'], ['01. 문서 요약'], ['02. SQL CH15 에이전트(Agent)'], ['01. Agent 사용법 톺아보기'], ['02. 도구를 활용한 토론 에이전트(Two Agent Debates with Tools) CH16 파인튜닝(Fine Tuning)'], ['CH17 LangGraph'], ['01. Chain of Table for Multiple Tables'], ['Published with WikiDocs'], ['<랭체인LangChain 노트> - Lang…'], ['CH01 LangChain 시작하기'], ['04. LangChain Expression…'], ['위키독스'], ['04. LangChain Expression Language(LCEL)'], ['기본 예시: 프롬프트 + 모델 + 출력 파서'], ['가장 기본적이고 일반적인 사용 사례는 prompt 템플릿과 모델을 함께 연결하는 것입니다.'], ['이것이 어떻게 작동하는지 보기 위해, 각 나라별 수도를 물어보는 Chain을 생성해 보겠습니다.'], ['# API KEY를 환경변수로 관리하기 위한 설정 파일', 'from dotenv import load_dotenv'], ['# API KEY 정보로드', 'load_dotenv()'], ['True'], ['# LangSmith 추적을 설정합니다.', 'https://smith.langchain.com'], ['# !pip install -qU langchain-teddynote'], ['from langchain_teddynote import logging'], ['# 프로젝트 이름을 입력합니다.'], ['logging.langsmith(\"CH01-Basic\")'], ['LangSmith 추적을 시작합니다.'], ['[프로젝트명]'], ['CH01-Basic'], ['프롬프트 템플릿의 활용'], ['PromptTemplate'], ['사용자의 입력 변수를 사용하여 완전한 프롬프트 문자열을 만드는 데 사용되는 템플릿입니다', '사용법'], ['template: 템플릿 문자열입니다.'], ['이 문자열 내에서 중괄호 {}는 변수를 나타냅니다.'], ['input_variables: 중괄호 안에 들어갈 변수의 이름을 리스트로 정의합니다.'], ['input_variables'], ['input_variables는 PromptTemplate에서 사용되는 변수의 이름을 정의하는 리스트입니다.'], ['from langchain_teddynote.messages import stream_response # 스트리밍 출력'], ['from langchain_core.prompts import PromptTemplate'], ['from_template() 메소드를 사용하여 PromptTemplate 객체 생성'], ['# template 정의'], ['template = \"{country}의 수도는 어디인가요?\"'], ['# from_template 메소드를 이용하여 PromptTemplate 객체 생성'], ['prompt_template = PromptTemplate.from_template(template)'], ['prompt_template'], [\"PromptTemplate(input_variables=['country'], template='{country}의 수도는 어디인가요?')\"], ['# prompt 생성'], ['prompt = prompt_template.format(country=\"대한민국\")'], ['prompt'], [\"'대한민국의 수도는 어디인가요?'\"], ['# prompt 생성'], ['prompt = prompt_template.format(country=\"미국\")'], ['prompt'], [\"'미국의 수도는 어디인가요?'\"], ['from langchain_openai import ChatOpenAI'], ['model = ChatOpenAI('], ['model=\"gpt-3.5-turbo\",'], ['max_tokens=2048,'], ['temperature=0.1,'], [')'], ['Chain 생성'], ['LCEL(LangChain Expression Language)'], ['여기서 우리는 LCEL을 사용하여 다양한 구성 요소를 단일 체인으로 결합합니다'], ['chain = prompt | model | output_parser'], ['| 기호는 unix 파이프 연산자와 유사하며, 서로 다른 구성 요소를 연결하고 한 구성 요소의 출력을 다음 구성 요소의 입력으로 전달합니다.'], ['이 체인에서 사용자 입력은 프롬프트 템플릿으로 전달되고, 그런 다음 프롬프트 템플릿 출력은 모델로 전달됩니다.'], ['각 구성 요소를 개별적으로 살펴보면 무슨 일이 일어나고 있는지 이해할 수 있습니다.'], ['# prompt 를 PromptTemplate 객체로 생성합니다.', 'prompt = PromptTemplate.from_template(\"{topic} 에 대해 쉽게 설명해주세요.\")'], ['model = ChatOpenAI()'], ['chain = prompt | model'], ['invoke() 호출', 'python 딕셔너리 형태로 입력값을 전달합니다.(키: 값)', 'invoke() 함수 호출 시, 입력값을 전달합니다.'], [\"# input 딕셔너리에 주제를 '인공지능 모델의 학습 원리'으로 설정합니다.\"], ['input = {\"topic\": \"인공지능 모델의 학습 원리\"}'], ['# prompt 객체와 model 객체를 파이프(|) 연산자로 연결하고 invoke 메서드를 사용하여 input을 전달합니다.', '# 이를 통해 AI 모델이 생성한 메시지를 반환합니다.'], ['chain.invoke(input)'], [\"AIMessage(content='인공지능 모델의 학습 원리는 데이터를 이용하여 패턴을 학습하는 것입니다.\"], ['모델은 입력 데이터를 받아들이고 내부적으로 가중치를 조정하여 원하는 결과를 출력합니다.', '학습 과정에서 모델은 입력 데이터와 정답 데이터를 이용하여 오차를 계산하고 이 오차를 최소화하는 방향으로 가중치를 업데이트합니다.', '이렇게 반복적으로 학습을 진행하면 모델은 입력 데이터로부터 패턴을 학습하여 정확한 결과를 예측하게 됩니다.', \"이러한 학습 원리를 통해 인공지능 모델은 데이터를 이용하여 스스로 학습하고 문제를 해결할 수 있습니다.', response_metadata={'token_usage': {'completion_tokens': 214, 'prompt_tokens': 33, 'total_tokens': 247}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-7f8a08f4-51ba-4d14-b9d2-2e092be3e7aa-0', usage_metadata={'input_tokens': 33, 'output_tokens': 214, 'total_tokens': 247})\"], ['아래는 스트리밍을 출력하는 예시 입니다.'], ['# 스트리밍 출력을 위한 요청'], ['answer = chain.stream(input)'], ['# 스트리밍 출력'], ['stream_response(answer)'], ['인공지능 모델의 학습 원리는 데이터를 입력으로 받아서 패턴을 학습하고 이를 기반으로 예측이나 분류를 수행하는 과정입니다.', '학습 과정은 크게 입력층, 은닉층, 출력층으로 구성된 인공신경망을 사용합니다.', '입력층에서 데이터를 받아 은닉층을 거쳐 출력층으로 결과를 출력하는 구조입니다.'], ['이때, 모델은 주어진 데이터를 통해 가중치를 조정하고 오차를 최소화하는 방향으로 학습을 진행합니다.', '이를 위해 주어진 데이터에 대해 예측을 수행하고 실제 값과 비교하여 오차를 계산한 후, 이 오차를 줄이기 위해 가중치를 업데이트합니다.', '이러한 반복적인 과정을 통해 모델은 데이터 간의 패턴을 학습하고 새로운 데이터에 대해 정확한 예측을 수행할 수 있게 됩니다.', '이렇게 학습된 모델은 새로운 데이터에 대해 일반화된 예측을 할 수 있습니다.'], ['출력파서(Output Parser)'], ['from langchain_core.output_parsers import StrOutputParser'], ['output_parser = StrOutputParser()'], ['Chain 에 출력파서를 추가합니다.'], ['# 프롬프트, 모델, 출력 파서를 연결하여 처리 체인을 구성합니다.', 'chain = prompt | model | output_parser'], ['# chain 객체의 invoke 메서드를 사용하여 input을 전달합니다.'], ['input = {\"topic\": \"인공지능 모델의 학습 원리\"}'], ['chain.invoke(input)'], [\"'인공지능 모델의 학습 원리는 데이터를 입력으로 받아서 패턴을 학습하는 것입니다.\", '모델은 입력 데이터를 받아서 내부적으로 가중치를 조절하면서 원하는 결과를 출력하도록 학습됩니다.', '이때, 모델은 입력 데이터와 출력 데이터 간의 관계를 학습하여 새로운 입력 데이터에 대한 출력을 예측할 수 있게 됩니다.', '이 과정은 반복적으로 이루어지며, 모델은 학습을 통해 점차적으로 정확도를 향상시킵니다.', \"이러한 방식으로 인공지능 모델은 주어진 데이터를 기반으로 판단하고 예측하는 능력을 향상시킬 수 있습니다.'\"], ['# 스트리밍 출력을 위한 요청'], ['answer = chain.stream(input)'], ['# 스트리밍 출력'], ['stream_response(answer)'], ['인공지능 모델의 학습 원리는 데이터를 이용해서 패턴을 학습하는 과정입니다.', '먼저 모델은 입력 데이터를 받아서 처리하고, 이때 입력 데이터와 정답 데이터를 비교하여 오차를 계산합니다.', '이 오차를 최소화하기 위해 모델은 가중치와 편향을 조정하면서 점차적으로 정확한 패턴을 학습해나갑니다.', '이런 과정을 반복하여 모델이 데이터에 대해 정확한 예측을 할 수 있도록 학습시키는 것이 인공지능 모델의 핵심 원리입니다.'], ['템플릿을 변경하여 적용', '아래의 프롬프트 내용을 얼마든지 변경 하여 테스트 해볼 수 있습니다.', 'model_name 역시 변경하여 테스트가 가능합니다.'], ['template = \"\"\"'], ['당신은 영어를 가르치는 10년차 영어 선생님입니다.', '상황에 [FORMAT]에 영어 회화를 작성해 주세요.'], ['상황:'], ['{question}'], ['FORMAT:'], ['- 영어 회화:'], ['- 한글 해석:'], ['\"\"\"'], ['# 프롬프트 템플릿을 이용하여 프롬프트를 생성합니다.'], ['prompt = PromptTemplate.from_template(template)'], ['# ChatOpenAI 챗모델을 초기화합니다.', 'model = ChatOpenAI(model_name=\"gpt-4-turbo\")'], ['# 문자열 출력 파서를 초기화합니다.'], ['output_parser = StrOutputParser()'], ['# 체인을 구성합니다.'], ['chain = prompt | model | output_parser', '# 완성된 Chain을 실행하여 답변을 얻습니다.'], ['# 스트리밍 출력을 위한 요청', 'answer = chain.stream({\"question\": \"저는 식당에 가서 음식을 주문하고 싶어요\"})'], ['# 스트리밍 출력'], ['stream_response(answer)'], ['영어 회화:'], ['- Hello, could I see the menu, please?'], [\"- I'd like to order the grilled salmon and a side of mashed potatoes.\", '- Could I have a glass of water as well?', '- Thank you!'], ['한글 해석:'], ['- 안녕하세요, 메뉴판 좀 볼 수 있을까요?'], ['- 구운 연어와 매시드 포테이토를 주문하고 싶어요.'], ['- 물 한 잔도 주실 수 있나요?'], ['- 감사합니다!'], [\"# 이번에는 question 을 '미국에서 피자 주문'으로 설정하여 실행합니다.\"], ['# 스트리밍 출력을 위한 요청', 'answer = chain.stream({\"question\": \"미국에서 피자 주문\"})'], ['# 스트리밍 출력'], ['stream_response(answer)'], ['영어 회화:'], ['- Employee: \"Hello, Tony\\'s Pizza. How can I help you?\"'], ['- Customer: \"Hi, I\\'d like to place an order for delivery, please.\"'], ['- Employee: \"Sure thing! What would you like to order?\"', '- Customer: \"I\\'ll have a large pepperoni pizza with extra cheese and a side of garlic bread.\"'], ['- Employee: \"Anything to drink?\"'], ['- Customer: \"Yes, a 2-liter bottle of Coke, please.\"'], ['- Employee: \"Alright, your total comes to $22.50. Can I have your delivery address?\"'], ['- Customer: \"It\\'s 742 Evergreen Terrace.\"'], ['- Employee: \"Thank you.', 'Your order will be there in about 30-45 minutes.', 'Is there anything else I can help you with?\"', '- Customer: \"No, that\\'s everything. Thank you!\"'], ['- Employee: \"Thank you for choosing Tony\\'s Pizza. Have a great day!\"'], ['한글 해석:'], ['- 직원: \"안녕하세요, 토니의 피자입니다. 어떻게 도와드릴까요?\"', '- 고객: \"안녕하세요, 배달 주문하고 싶은데요.\"', '- 직원: \"네, 무엇을 주문하시겠어요?\"', '- 고객: \"큰 사이즈의 페퍼로니 피자에 치즈 추가하고, 마늘빵 하나 주세요.\"', '- 직원: \"음료는 드릴까요?\"', '- 고객: \"네, 콜라 2리터 한 병 주세요.\"', '- 직원: \"알겠습니다, 합계는 $22.50입니다. 배달 주소를 알려주시겠어요?\"', '- 고객: \"742 에버그린 테라스입니다.\"', '- 직원: \"감사합니다.', '주문하신 음식은 대략 30-45분 내에 도착할 예정입니다.', '다른 도움이 필요하신가요?\"', '- 고객: \"아니요, 이게 다예요. 감사합니다!\"'], ['- 직원: \"토니의 피자를 선택해주셔서 감사합니다. 좋은 하루 되세요!\"'], ['마지막 편집일시 : 2024년 6월 18일 1:20 오전'], ['댓글 0 피드백', '※ 댓글 작성은 로그인이 필요합니다.', '(또는 피드백을 이용해 주세요.)'], ['이전글 : 03.'], ['OpenAI API 사용(GPT-4o 멀티모달)'], ['다음글 : 05.'], ['LCEL 인터페이스'], ['책갈피'], ['이 페이지에 대한 피드백을 남겨주세요'], ['댓글을 신고합니다.']], 'span': [[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15], [16], [17], [18], [19], [20], [21], [22], [23], [24], [25], [26], [27], [28], [29], [30], [31], [32], [33], [34], [35], [36, 37], [38], [39], [40], [41], [42], [43], [44], [45], [46], [47], [48], [49], [50], [51], [52], [53], [54], [55], [56], [57], [58], [59], [60], [61], [62], [63], [64], [65], [66], [67], [68], [69], [70], [71], [72], [73], [74], [75], [76], [77], [78], [79], [80], [81], [82], [83], [84], [85], [86], [87], [88], [89], [90], [91], [92], [93], [94, 95], [96], [97], [98], [99], [100], [101], [102], [103], [104], [105], [106], [107], [108], [109], [110], [111], [112], [113], [114, 115], [116, 117], [118], [119, 120], [121], [122], [123], [124], [125], [126], [127], [128], [129], [130, 131], [132], [133], [134], [135], [136], [137], [138], [139], [140], [141], [142], [143], [144], [145], [146], [147], [148], [149], [150], [151], [152], [153], [154], [155], [156], [157], [158], [159], [160], [161], [162], [163], [164], [165], [166], [167, 168], [169], [170], [171, 172, 173], [174], [175], [176, 177], [178], [179], [180, 181, 182, 183], [184], [185], [186], [187], [188], [189, 190, 191], [192, 193, 194, 195], [196], [197], [198], [199], [200, 201], [202], [203], [204], [205, 206, 207, 208, 209], [210], [211], [212], [213], [214, 215, 216, 217], [218, 219, 220], [221], [222, 223], [224], [225], [226], [227], [228], [229], [230], [231], [232, 233], [234], [235], [236], [237, 238], [239, 240], [241], [242], [243], [244], [245, 246, 247], [248], [249], [250], [251], [252], [253], [254, 255], [256], [257], [258], [259], [260], [261, 262], [263], [264], [265], [266], [267, 268, 269, 270], [271], [272], [273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284], [285], [286], [287, 288, 289], [290], [291], [292], [293], [294], [295], [296]], 'inputTokens': 6882}}\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 4/7 [00:15<00:12,  4.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "{'status': {'code': '20000', 'message': 'OK'}, 'result': {'topicSeg': [['<랭체인LangChain 노트> - LangChain 한국어 튜토리얼🇰🇷 CH01 LangChain 시작하기'], ['01. OpenAI API 키 발급 및 테스트'], ['02. LangSmith 추적 설정'], ['03. OpenAI API 사용(GPT-4o 멀티모달)'], ['04. LangChain Expression Language(LCEL)'], ['05. LCEL 인터페이스'], ['06. Runnable CH02 프롬프트(Prompt)'], ['01. 프롬프트(Prompt)'], ['02. 퓨샷 프롬프트(FewShotPromptTemplate)'], ['03. LangChain Hub'], ['04. 개인화된 프롬프트(Hub에 업로드) CH03 출력 파서(Output Parsers)'], ['01. Pydantic 출력 파서(PydanticOutputParser)'], ['02. 콤마 구분자 출력 파서(CommaSeparatedListOutputParser)'], ['03. 구조화된 출력 파서(StructuredOuputParser)'], ['04. JSON 출력 파서(JsonOutputParser)'], ['05. 데이터프레임 출력 파서(PandasDataFrameOutputParser)'], ['06. 날짜 형식 출력 파서(DatetimeOutputParser)'], ['07. 열거형 출력 파서(EnumOutputParser)'], ['08. 출력 수정 파서(OutputFixingParser) CH04 모델(Model)'], ['01. 다양한 LLM 모델 활용'], ['02. 캐싱(Cache)'], ['03. 모델 직렬화(Serialization) - 저장 및 불러오기'], ['04. 토큰 사용량 확인'], ['05. 구글 생성 AI(Google Generative AI)'], ['06. 허깅페이스 엔드포인트(HuggingFace Endpoints)'], ['07. 허깅페이스 로컬(HuggingFace Local)'], ['08. 허깅페이스 파이프라인(HuggingFace Pipeline)'], ['09. 올라마(Ollama)'], ['10. GPT4ALL CH05 메모리(Memory)'], ['01. 대화 버퍼 메모리(ConversationBufferMemory)'], ['02. 대화 버퍼 윈도우 메모리(ConversationBufferWindowMemory)'], ['03. 대화 토큰 버퍼 메모리(ConversationTokenBufferMemory)'], ['04. 대화 엔티티 메모리(ConversationEntityMemory)'], ['05. 대화 지식그래프 메모리(ConversationKGMemory)'], ['06. 대화 요약 메모리(ConversationSummaryMemory)'], ['07. 벡터저장소 검색 메모리(VectorStoreRetrieverMemory)'], ['08. LCEL Chain 에 메모리 추가', '09. SQLite 에 대화내용 저장'], ['10. RunnableWithMessageHistory에 ChatMessageHistory추가 CH06 문서 로더(Document Loader)'], ['01. 도큐먼트(Document) 의 구조'], ['02. PDF'], ['03. 한글(HWP)'], ['04. CSV'], ['05. Excel'], ['06. Word'], ['07. PowerPoint'], ['08. 웹 문서(WebBaseLoader)'], ['09. 텍스트(TextLoader)'], ['10. JSON'], ['11. Arxiv'], ['13. UpstageLayoutAnalysisLoader'], ['14. LlamaParser CH07 텍스트 분할(Text Splitter)'], ['01. 문자 텍스트 분할(CharacterTextSplitter)'], ['02. 재귀적 문자 텍스트 분할(RecursiveCharacterTextSplitter)'], ['03. 토큰 텍스트 분할(TokenTextSplitter)'], ['04. 시멘틱 청커(SemanticChunker)'], ['05. 코드 분할(Python, Markdown, JAVA, C++, C#, GO, JS, Latex 등)'], ['06. 마크다운 헤더 텍스트 분할(MarkdownHeaderTextSplitter)'], ['07. HTML 헤더 텍스트 분할(HTMLHeaderTextSplitter)'], ['08. 재귀적 JSON 분할(RecursiveJsonSplitter) CH08 임베딩(Embedding)'], ['01. OpenAIEmbeddings'], ['02. 캐시 임베딩(CacheBackedEmbeddings)'], ['03. 허깅페이스 임베딩(HuggingFace Embeddings)'], ['04. UpstageEmbeddings'], ['05. OllamaEmbeddings'], ['06. GPT4ALL 임베딩'], ['07. Llama CPP 임베딩 CH09 벡터저장소(VectorStore)'], ['01. Chroma'], ['02. FAISS'], ['03. Pinecone CH10 검색기(Retriever)'], ['01. 벡터저장소 지원 검색기(VectorStore-backed Retriever)'], ['02. 문맥 압축 검색기(ContextualCompressionRetriever)'], ['03. 앙상블 검색기(EnsembleRetriever)'], ['04. 긴 문맥 재정렬(LongContextReorder)'], ['05. 상위 문서 검색기(ParentDocumentRetriever)'], ['06. 다중 쿼리 검색기(MultiQueryRetriever)'], ['07. 다중 벡터저장소 검색기(MultiVectorRetriever)'], ['08. 셀프 쿼리 검색기(SelfQueryRetriever)'], ['09. 시간 가중 벡터저장소 검색기(TimeWeightedVectorStoreRetriever)'], ['10. 한글 형태소 분석기(Kiwi, Kkma, Okt) + BM25 검색기 CH11 리랭커(Reranker)'], ['01. Cross Encoder Reranker'], ['02. Cohere Reranker'], ['03. Jina Reranker'], ['04. FlashRank Reranker CH12 Retrieval Augmented Generation(RAG)'], ['01. PDF 문서 기반 QA(Question-Answer)'], ['02. 네이버 뉴스기사 QA(Question-Answer)'], ['03. RAG 의 기능별 다양한 모듈 활용기'], ['04. RAPTOR: 긴 문맥 요약(Long Context Summary)'], ['05. 대화내용을 기억하는 RAG 체인 CH13 LangChain Expression Language(LCEL)'], ['01. RunnablePassthrough: 데이터 전달'], ['02. Runnable 구조(그래프) 확인'], ['03. RunnableLambda: 사용자 정의 함수'], ['04. RunnableBranch: 라우팅(Routing)'], ['05. RunnableParallel: 병렬 처리'], ['06. configurable_fields, configurable_alternatives 07. @chain 데코레이터로 Runnable 생성', '08. RunnableWithMessageHistory'], ['09. 사용자 정의 제네레이터(generator)'], ['10. Runtime Arguments 바인딩'], ['11. 폴백(fallback) 모델 지정 CH14 체인(Chains)'], ['01. 문서 요약'], ['02. SQL CH15 에이전트(Agent)'], ['01. Agent 사용법 톺아보기'], ['02. 도구를 활용한 토론 에이전트(Two Agent Debates with Tools) CH16 파인튜닝(Fine Tuning)'], ['CH17 LangGraph'], ['01. Chain of Table for Multiple Tables'], ['Published with WikiDocs'], ['<랭체인LangChain 노트> - Lang…'], ['CH01 LangChain 시작하기'], ['05. LCEL 인터페이스'], ['위키독스'], ['05. LCEL 인터페이스'], ['LCEL 인터페이스'], ['사용자 정의 체인을 가능한 쉽게 만들 수 있도록, Runnable 프로토콜을 구현했습니다.', 'Runnable 프로토콜은 대부분의 컴포넌트에 구현되어 있습니다.'], ['이는 표준 인터페이스로, 사용자 정의 체인을 정의하고 표준 방식으로 호출하는 것을 쉽게 만듭니다.', '표준 인터페이스에는 다음이 포함됩니다.'], ['stream: 응답의 청크를 스트리밍합니다.'], ['invoke: 입력에 대해 체인을 호출합니다.', 'batch: 입력 목록에 대해 체인을 호출합니다.'], ['비동기 메소드도 있습니다.'], ['astream: 비동기적으로 응답의 청크를 스트리밍합니다.'], ['ainvoke: 비동기적으로 입력에 대해 체인을 호출합니다.'], ['abatch: 비동기적으로 입력 목록에 대해 체인을 호출합니다.'], ['astream_log: 최종 응답뿐만 아니라 발생하는 중간 단계를 스트리밍합니다.'], ['# API KEY를 환경변수로 관리하기 위한 설정 파일'], ['from dotenv import load_dotenv', '# API KEY 정보로드', 'load_dotenv()'], ['True'], ['# LangSmith 추적을 설정합니다.'], ['https://smith.langchain.com'], ['from langchain_teddynote import logging'], ['# 프로젝트 이름을 입력합니다.'], ['logging.langsmith(\"CH01-Basic\")'], ['LCEL 문법을 사용하여 chain 을 생성합니다.'], ['from langchain_openai import ChatOpenAI', 'from langchain_core.prompts import PromptTemplate', 'from langchain_core.output_parsers import StrOutputParser'], ['# ChatOpenAI 모델을 인스턴스화합니다.'], ['model = ChatOpenAI()'], ['# 주어진 토픽에 대한 농담을 요청하는 프롬프트 템플릿을 생성합니다.'], ['prompt = PromptTemplate.from_template(\"{topic} 에 대하여 3문장으로 설명해줘.\")'], ['# 프롬프트와 모델을 연결하여 대화 체인을 생성합니다.'], ['chain = prompt | model | StrOutputParser()'], ['stream: 실시간 출력'], ['이 함수는 chain.stream 메서드를 사용하여 주어진 토픽에 대한 데이터 스트림을 생성하고, 이 스트림을 반복하여 각 데이터의 내용(content)을 즉시 출력합니다.'], ['end=\"\" 인자는 출력 후 줄바꿈을 하지 않도록 설정하며, flush=True 인자는 출력 버퍼를 즉시 비우도록 합니다.'], [\"# chain.stream 메서드를 사용하여 '멀티모달' 토픽에 대한 스트림을 생성하고 반복합니다.\", 'for token in chain.stream({\"topic\": \"멀티모달\"}):'], ['# 스트림에서 받은 데이터의 내용을 출력합니다.', '줄바꿈 없이 이어서 출력하고, 버퍼를 즉시 비웁니다.'], ['print(token, end=\"\", flush=True)'], ['멀티모달은 여러 가지 다른 형태의 커뮤니케이션 수단을 통해 정보를 전달하고 상호작용하는 기술을 의미합니다.', '예를 들어 음성, 텍스트, 이미지, 동영상 등 다양한 매체를 활용하여 사용자와 상호작용할 수 있습니다.'], ['멀티모달 기술은 사용자 경험을 향상시키고 정보 전달의 효율성을 높이는데 도움을 줄 수 있습니다.'], ['invoke: 호출'], ['chain 객체의 invoke 메서드는 주제를 인자로 받아 해당 주제에 대한 처리를 수행합니다.', \"# chain 객체의 invoke 메서드를 호출하고, 'ChatGPT'라는 주제로 딕셔너리를 전달합니다.\"], ['chain.invoke({\"topic\": \"ChatGPT\"})'], [\"'ChatGPT는 OpenAI에서 개발한 대화형 인공지능 모델로, 다양한 주제에 대한 대화를 자연스럽게 이어나갈 수 있습니다.\", '사용자들은 ChatGPT를 통해 질문에 답변을 받거나 대화를 이어가며 새로운 정보를 습득할 수 있습니다.', \"또한 ChatGPT는 사용자의 입력을 학습하여 점차적으로 더욱 유창하고 자연스러운 대화를 제공합니다.'\"], ['batch: 배치(단위 실행)'], ['함수 chain.batch는 여러 개의 딕셔너리를 포함하는 리스트를 인자로 받아, 각 딕셔너리에 있는 topic 키의 값을 사용하여 일괄 처리를 수행합니다.'], ['# 주어진 토픽 리스트를 batch 처리하는 함수 호출'], ['chain.batch([{\"topic\": \"ChatGPT\"}, {\"topic\": \"Instagram\"}])'], [\"['ChatGPT는 인공지능 챗봇으로 자연어 처리 기술을 사용하여 대화를 수행합니다.\"], ['사용자들과 자연스럽게 상호작용하며 다양한 주제에 대해 대화할 수 있습니다.', \"ChatGPT는 정보 제공, 질문 응답, 상담 및 엔터테인먼트 등 다양한 용도로 활용될 수 있습니다.', 'Instagram은 사진과 동영상을 공유하고 다른 사람들과 소통하는 소셜 미디어 플랫폼이다.\", '해시태그를 통해 관심사나 주제별로 사진을 검색하고 팔로워들과 소통할 수 있다.', \"인기 있는 인플루언서나 브랜드가 활발하게 활동하는 플랫폼으로 세계적으로 인기가 높다.']\"], ['max_concurrency 매개변수를 사용하여 동시 요청 수를 설정할 수 있습니다', 'config 딕셔너리는 max_concurrency 키를 통해 동시에 처리할 수 있는 최대 작업 수를 설정합니다.', '여기서는 최대 3개의 작업을 동시에 처리하도록 설정되어 있습니다.'], ['chain.batch('], ['['], ['{\"topic\": \"ChatGPT\"},'], ['{\"topic\": \"Instagram\"},'], ['{\"topic\": \"멀티모달\"},'], ['{\"topic\": \"프로그래밍\"},'], ['{\"topic\": \"머신러닝\"},'], ['],'], ['config={\"max_concurrency\": 3},'], [')'], [\"['ChatGPT는 인공지능 챗봇으로, 자연어 처리 기술을 사용하여 대화 상대와 상호작용합니다.\", '사용자의 질문에 응답하고 대화를 이어가며 다양한 주제에 대해 대화할 수 있습니다.', \"ChatGPT는 사용자와 자연스럽게 대화를 나누는 데 도움을 줄 뿐만 아니라 정보를 제공하고 문제 해결을 돕기도 합니다.', 'Instagram은 사진과 동영상을 공유하고 다른 사람들과 소통할 수 있는 소셜 미디어 플랫폼이다.\", '다양한 필터와 편집 기능을 제공하여 사용자가 쉽게 멋진 사진을 업로드할 수 있으며 해시태그를 통해 관심사에 맞는 콘텐츠를 찾을 수 있다.', \"인기 있는 인플루언서들의 활동과 광고가 많이 이루어지는 플랫폼이기도 하다.', '멀티모달은 여러 가지의 다른 형태의 정보를 함께 제공하거나 처리하는 기술이다.\", '이는 텍스트, 이미지, 음성, 비디오 등 여러 형태의 데이터를 통합하여 효과적으로 전달하고 상호작용할 수 있게 한다.', \"멀티모달은 사용자 경험을 향상시키고 정보를 보다 쉽게 이해하고 활용할 수 있도록 도와준다.', '프로그래밍은 컴퓨터에게 실행할 작업을 지시하는 일종의 커뮤니케이션 방법이다.\", '이를 위해 프로그래머가 사용하는 언어는 컴퓨터가 이해할 수 있는 형태여야 하며, 문법과 로직을 통해 원하는 결과를 얻을 수 있다.', \"프로그래밍을 통해 소프트웨어를 개발하고 문제를 해결하는 등 다양한 분야에서 활용할 수 있다.', '머신러닝은 컴퓨터 시스템이 데이터에서 학습하고 패턴을 발견하여 예측하거나 결정을 내리는 인공지능의 한 분야입니다.\", '이를 통해 컴퓨터는 사람의 개입 없이 스스로 학습하고 문제를 해결할 수 있습니다.', \"머신러닝은 이미지 및 음성 인식, 자율 주행 자동차, 헬스케어 등 다양한 분야에서 활용되고 있습니다.']\"], ['async stream: 비동기 스트림'], ['함수 chain.astream은 비동기 스트림을 생성하며, 주어진 토픽에 대한 메시지를 비동기적으로 처리합니다.', '비동기 for 루프(async for)를 사용하여 스트림에서 메시지를 순차적으로 받아오고, print 함수를 통해 메시지의 내용(s.content)을 즉시 출력합니다.'], ['end=\"\"는 출력 후 줄바꿈을 하지 않도록 설정하며, flush=True는 출력 버퍼를 강제로 비워 즉시 출력되도록 합니다.'], [\"# 비동기 스트림을 사용하여 'YouTube' 토픽의 메시지를 처리합니다.\"], ['async for token in chain.astream({\"topic\": \"YouTube\"}):'], ['# 메시지 내용을 출력합니다.'], ['줄바꿈 없이 바로 출력하고 버퍼를 비웁니다.'], ['print(token, end=\"\", flush=True)'], ['YouTube 는 동영상을 공유하고 시청할 수 있는 온라인 동영상 플랫폼이다.', '누구나 자신의 동영상을 업로드하여 다른 사람들과 공유할 수 있고, 영상 콘텐츠를 시청하며 다양한 정보나 즐길거리를 찾을 수 있다.', '또한 유명한 크리에이터들의 영상을 통해 엔터테인먼트와 정보를 얻을 수 있다.'], ['async invoke: 비동기 호출'], ['chain 객체의 ainvoke 메서드는 비동기적으로 주어진 인자를 사용하여 작업을 수행합니다.', '여기서는 topic이라는 키와 NVDA(엔비디아의 티커) 라는 값을 가진 딕셔너리를 인자로 전달하고 있습니다.', '이 메서드는 특정 토픽에 대한 처리를 비동기적으로 요청하는 데 사용될 수 있습니다.', \"# 비동기 체인 객체의 'ainvoke' 메서드를 호출하여 'NVDA' 토픽을 처리합니다.\"], ['my_process = chain.ainvoke({\"topic\": \"NVDA\"})'], ['# 비동기로 처리되는 프로세스가 완료될 때까지 기다립니다.'], ['await my_process'], [\"'NVDA는 엔비디아의 주식 코드로, 미국의 반도체 기업인 엔비디아(NVIDIA)의 주식을 말합니다.\", '엔비디아는 그래픽 처리 유닛(GPU)을 전문으로 하는 기업으로, 인공지능, 가상현실, 자율주행차 등 다양한 분야에서 기술을 제공하고 있습니다.'], [\"NVDA 주식은 기술 산업의 성장과 함께 높은 수익을 창출하고 있습니다.'\"], ['async batch: 비동기 배치'], ['함수 abatch는 비동기적으로 일련의 작업을 일괄 처리합니다.'], ['이 예시에서는 chain 객체의 abatch 메서드를 사용하여 topic 에 대한 작업을 비동기적으로 처리하고 있습니다.'], ['await 키워드는 해당 비동기 작업이 완료될 때까지 기다리는 데 사용됩니다.'], ['# 주어진 토픽에 대해 비동기적으로 일괄 처리를 수행합니다.'], ['my_abatch_process = chain.abatch('], ['[{\"topic\": \"YouTube\"}, {\"topic\": \"Instagram\"}, {\"topic\": \"Facebook\"}]'], [')'], ['# 비동기로 처리되는 일괄 처리 프로세스가 완료될 때까지 기다립니다.'], ['await my_abatch_process'], [\"['YouTube는 동영상 공유 플랫폼으로 사용자들이 영상을 업로드하고 시청할 수 있는 서비스입니다.\", '다양한 콘텐츠를 제공하며 사용자는 무료로 영상을 시청할 수 있습니다.'], [\"유명한 유튜버들이 활동하고 수익을 창출할 수 있는 플랫폼으로도 알려져 있습니다.', '인스타그램은 사진과 동영상을 공유하는 소셜 미디어 플랫폼으로, 사용자들은 다양한 필터와 효과를 이용해 자신의 콘텐츠를 멋지게 꾸밀 수 있습니다.\", '또한 팔로워들과 소통하고, 다른 사용자의 게시물을 좋아하거나 댓글을 남기며 커뮤니케이션을 할 수 있습니다.', \"인스타그램은 비즈니스나 개인 브랜딩에도 활용되며, 많은 사람들이 일상 속 소소한 순간부터 특별한 순간까지를 공유하고 있습니다.', 'Facebook은 미국의 소셜 네트워크 서비스로, 사용자들이 커뮤니케이션하고 정보를 공유할 수 있는 플랫폼이다.\", '현재 전 세계적으로 약 30억 명 이상의 사용자가 활동하고 있으며, 광고 및 비즈니스 활동에도 널리 활용되고 있다.'], [\"또한 개인정보 보호 문제와 가짜 뉴스 등 여러 논란을 빚어왔으나, 여전히 많은 사람들이 이용하고 있는 대표적인 SNS 서비스이다.']\"], ['Parallel: 병렬성'], ['LangChain Expression Language가 병렬 요청을 지원하는 방법을 살펴봅시다.', '예를 들어, RunnableParallel을 사용할 때(자주 사전 형태로 작성됨), 각 요소를 병렬로 실행합니다.', 'langchain_core.runnables 모듈의 RunnableParallel 클래스를 사용하여 두 가지 작업을 병렬로 실행하는 예시를 보여줍니다.', 'ChatPromptTemplate.from_template 메서드를 사용하여 주어진 country에 대한 수도 와 면적 을 구하는 두 개의 체인(chain1, chain2)을 만듭니다.', '이 체인들은 각각 model과 파이프(|) 연산자를 통해 연결됩니다.', '마지막으로, RunnableParallel 클래스를 사용하여 이 두 체인을 capital와 area이라는 키로 결합하여 동시에 실행할 수 있는 combined 객체를 생성합니다.'], ['from langchain_core.runnables import RunnableParallel'], ['# {country} 의 수도를 물어보는 체인을 생성합니다.', 'chain1 = ('], ['PromptTemplate.from_template(\"{country} 의 수도는 어디야?\")'], ['| model'], ['| StrOutputParser()'], [')'], ['# {country} 의 면적을 물어보는 체인을 생성합니다.'], ['chain2 = ('], ['PromptTemplate.from_template(\"{country} 의 면적은 얼마야?\")'], ['| model'], ['| StrOutputParser()'], [')'], ['# 위의 2개 체인을 동시에 생성하는 병렬 실행 체인을 생성합니다.'], ['combined = RunnableParallel(capital=chain1, area=chain2)'], ['chain1.invoke() 함수는 chain1 객체의 invoke 메서드를 호출합니다.', '이때, country이라는 키에 대한민국라는 값을 가진 딕셔너리를 인자로 전달합니다.'], ['# chain1 를 실행합니다.', 'chain1.invoke({\"country\": \"대한민국\"})'], [\"'대한민국의 수도는 서울이다.'\"], ['이번에는 chain2.invoke() 를 호출합니다.'], ['country 키에 다른 국가인 미국 을 전달합니다.'], ['# chain2 를 실행합니다.'], ['chain2.invoke({\"country\": \"미국\"})'], [\"'미국의 면적은 약 9,826,675 제곱 킬로미터입니다.'\"], ['combined 객체의 invoke 메서드는 주어진 country에 대한 처리를 수행합니다.'], ['이 예제에서는 대한민국라는 주제를 invoke 메서드에 전달하여 실행합니다.'], ['# 병렬 실행 체인을 실행합니다.'], ['combined.invoke({\"country\": \"대한민국\"})'], [\"{'capital': '대한민국의 수도는 서울입니다.', 'area': '대한민국의 면적은 약 100,363.4 제곱 킬로미터 입니다.'}\"], ['배치에서의 병렬 처리'], ['병렬 처리는 다른 실행 가능한 코드와 결합될 수 있습니다.'], ['배치와 병렬 처리를 사용해 보도록 합시다.'], ['chain1.batch 함수는 여러 개의 딕셔너리를 포함하는 리스트를 인자로 받아, 각 딕셔너리에 있는 \"topic\" 키에 해당하는 값을 처리합니다.'], ['이 예시에서는 \"대한민국\"와 \"미국\"라는 두 개의 토픽을 배치 처리하고 있습니다.'], ['# 배치 처리를 수행합니다.'], ['chain1.batch([{\"country\": \"대한민국\"}, {\"country\": \"미국\"}])'], [\"['대한민국의 수도는 서울이에요.', '미국의 수도는 워싱턴 D.C.입니다.']\"], ['chain2.batch 함수는 여러 개의 딕셔너리를 리스트 형태로 받아, 일괄 처리(batch)를 수행합니다.'], ['이 예시에서는 대한민국와 미국라는 두 가지 국가에 대한 처리를 요청합니다.'], ['# 배치 처리를 수행합니다.'], ['chain2.batch([{\"country\": \"대한민국\"}, {\"country\": \"미국\"}])'], [\"['대한민국의 총 면적은 약 100,363 제곱킬로미터 입니다.', '미국의 면적은 약 9,834,000km² 입니다.']\"], ['combined.batch 함수는 주어진 데이터를 배치로 처리하는 데 사용됩니다.'], ['이 예시에서는 두 개의 딕셔너리 객체를 포함하는 리스트를 인자로 받아 각각 대한민국와 미국 두 나라에 대한 데이터를 배치 처리합니다.'], ['# 주어진 데이터를 배치로 처리합니다.'], ['combined.batch([{\"country\": \"대한민국\"}, {\"country\": \"미국\"}])'], [\"[{'capital': '대한민국의 수도는 서울이다.', 'area': '대한민국의 면적은 약 100,363km² 입니다.'}, {'capital': '미국의 수도는 워싱턴 D.C.입니다.', 'area': '미국의 면적은 약 9,833,520 km² 입니다.'}]\"], ['마지막 편집일시 : 2024년 6월 17일 8:04 오후'], ['댓글 0 피드백'], ['※ 댓글 작성은 로그인이 필요합니다.'], ['(또는 피드백을 이용해 주세요.)'], ['이전글 : 04.'], ['LangChain Expression Language(LCEL)'], ['다음글 : 06.'], ['Runnable'], ['책갈피'], ['이 페이지에 대한 피드백을 남겨주세요'], ['댓글을 신고합니다.']], 'span': [[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15], [16], [17], [18], [19], [20], [21], [22], [23], [24], [25], [26], [27], [28], [29], [30], [31], [32], [33], [34], [35], [36, 37], [38], [39], [40], [41], [42], [43], [44], [45], [46], [47], [48], [49], [50], [51], [52], [53], [54], [55], [56], [57], [58], [59], [60], [61], [62], [63], [64], [65], [66], [67], [68], [69], [70], [71], [72], [73], [74], [75], [76], [77], [78], [79], [80], [81], [82], [83], [84], [85], [86], [87], [88], [89], [90], [91], [92], [93], [94, 95], [96], [97], [98], [99], [100], [101], [102], [103], [104], [105], [106], [107], [108], [109], [110], [111], [112, 113], [114, 115], [116], [117, 118], [119], [120], [121], [122], [123], [124], [125, 126, 127], [128], [129], [130], [131], [132], [133], [134], [135, 136, 137], [138], [139], [140], [141], [142], [143], [144], [145], [146], [147, 148], [149, 150], [151], [152, 153], [154], [155], [156, 157], [158], [159, 160, 161], [162], [163], [164], [165], [166], [167, 168, 169, 170], [171, 172, 173], [174], [175], [176], [177], [178], [179], [180], [181], [182], [183], [184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194], [195], [196, 197], [198], [199], [200], [201], [202], [203], [204, 205, 206], [207], [208, 209, 210, 211], [212], [213], [214], [215, 216], [217], [218], [219], [220], [221], [222], [223], [224], [225], [226], [227], [228, 229], [230, 231, 232, 233], [234], [235], [236, 237, 238, 239, 240, 241], [242], [243, 244], [245], [246], [247], [248], [249], [250], [251], [252], [253], [254], [255], [256], [257, 258], [259, 260], [261], [262], [263], [264], [265], [266], [267], [268], [269], [270], [271], [272], [273], [274], [275], [276], [277], [278], [279], [280], [281], [282], [283], [284], [285], [286], [287], [288], [289], [290], [291], [292], [293], [294], [295], [296], [297], [298], [299], [300]], 'inputTokens': 8040}}\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████▏  | 5/7 [00:18<00:07,  3.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "{'status': {'code': '20000', 'message': 'OK'}, 'result': {'topicSeg': [['<랭체인LangChain 노트> - LangChain 한국어 튜토리얼🇰🇷 CH01 LangChain 시작하기'], ['01. OpenAI API 키 발급 및 테스트'], ['02. LangSmith 추적 설정'], ['03. OpenAI API 사용(GPT-4o 멀티모달)'], ['04. LangChain Expression Language(LCEL)'], ['05. LCEL 인터페이스'], ['06. Runnable CH02 프롬프트(Prompt)'], ['01. 프롬프트(Prompt)'], ['02. 퓨샷 프롬프트(FewShotPromptTemplate)'], ['03. LangChain Hub'], ['04. 개인화된 프롬프트(Hub에 업로드) CH03 출력 파서(Output Parsers)'], ['01. Pydantic 출력 파서(PydanticOutputParser)'], ['02. 콤마 구분자 출력 파서(CommaSeparatedListOutputParser)'], ['03. 구조화된 출력 파서(StructuredOuputParser)'], ['04. JSON 출력 파서(JsonOutputParser)'], ['05. 데이터프레임 출력 파서(PandasDataFrameOutputParser)'], ['06. 날짜 형식 출력 파서(DatetimeOutputParser)'], ['07. 열거형 출력 파서(EnumOutputParser)'], ['08. 출력 수정 파서(OutputFixingParser) CH04 모델(Model)'], ['01. 다양한 LLM 모델 활용'], ['02. 캐싱(Cache)'], ['03. 모델 직렬화(Serialization) - 저장 및 불러오기'], ['04. 토큰 사용량 확인'], ['05. 구글 생성 AI(Google Generative AI)'], ['06. 허깅페이스 엔드포인트(HuggingFace Endpoints)'], ['07. 허깅페이스 로컬(HuggingFace Local)'], ['08. 허깅페이스 파이프라인(HuggingFace Pipeline)'], ['09. 올라마(Ollama)'], ['10. GPT4ALL CH05 메모리(Memory)'], ['01. 대화 버퍼 메모리(ConversationBufferMemory)'], ['02. 대화 버퍼 윈도우 메모리(ConversationBufferWindowMemory)'], ['03. 대화 토큰 버퍼 메모리(ConversationTokenBufferMemory)'], ['04. 대화 엔티티 메모리(ConversationEntityMemory)'], ['05. 대화 지식그래프 메모리(ConversationKGMemory)'], ['06. 대화 요약 메모리(ConversationSummaryMemory)'], ['07. 벡터저장소 검색 메모리(VectorStoreRetrieverMemory)'], ['08. LCEL Chain 에 메모리 추가', '09. SQLite 에 대화내용 저장'], ['10. RunnableWithMessageHistory에 ChatMessageHistory추가 CH06 문서 로더(Document Loader)'], ['01. 도큐먼트(Document) 의 구조'], ['02. PDF'], ['03. 한글(HWP)'], ['04. CSV'], ['05. Excel'], ['06. Word'], ['07. PowerPoint'], ['08. 웹 문서(WebBaseLoader)'], ['09. 텍스트(TextLoader)'], ['10. JSON'], ['11. Arxiv'], ['13. UpstageLayoutAnalysisLoader'], ['14. LlamaParser CH07 텍스트 분할(Text Splitter)'], ['01. 문자 텍스트 분할(CharacterTextSplitter)'], ['02. 재귀적 문자 텍스트 분할(RecursiveCharacterTextSplitter)'], ['03. 토큰 텍스트 분할(TokenTextSplitter)'], ['04. 시멘틱 청커(SemanticChunker)'], ['05. 코드 분할(Python, Markdown, JAVA, C++, C#, GO, JS, Latex 등)'], ['06. 마크다운 헤더 텍스트 분할(MarkdownHeaderTextSplitter)'], ['07. HTML 헤더 텍스트 분할(HTMLHeaderTextSplitter)'], ['08. 재귀적 JSON 분할(RecursiveJsonSplitter) CH08 임베딩(Embedding)'], ['01. OpenAIEmbeddings'], ['02. 캐시 임베딩(CacheBackedEmbeddings)'], ['03. 허깅페이스 임베딩(HuggingFace Embeddings)'], ['04. UpstageEmbeddings'], ['05. OllamaEmbeddings'], ['06. GPT4ALL 임베딩'], ['07. Llama CPP 임베딩 CH09 벡터저장소(VectorStore)'], ['01. Chroma'], ['02. FAISS'], ['03. Pinecone CH10 검색기(Retriever)'], ['01. 벡터저장소 지원 검색기(VectorStore-backed Retriever)'], ['02. 문맥 압축 검색기(ContextualCompressionRetriever)'], ['03. 앙상블 검색기(EnsembleRetriever)'], ['04. 긴 문맥 재정렬(LongContextReorder)'], ['05. 상위 문서 검색기(ParentDocumentRetriever)'], ['06. 다중 쿼리 검색기(MultiQueryRetriever)'], ['07. 다중 벡터저장소 검색기(MultiVectorRetriever)'], ['08. 셀프 쿼리 검색기(SelfQueryRetriever)'], ['09. 시간 가중 벡터저장소 검색기(TimeWeightedVectorStoreRetriever)'], ['10. 한글 형태소 분석기(Kiwi, Kkma, Okt) + BM25 검색기 CH11 리랭커(Reranker)'], ['01. Cross Encoder Reranker'], ['02. Cohere Reranker'], ['03. Jina Reranker'], ['04. FlashRank Reranker CH12 Retrieval Augmented Generation(RAG)'], ['01. PDF 문서 기반 QA(Question-Answer)'], ['02. 네이버 뉴스기사 QA(Question-Answer)'], ['03. RAG 의 기능별 다양한 모듈 활용기'], ['04. RAPTOR: 긴 문맥 요약(Long Context Summary)'], ['05. 대화내용을 기억하는 RAG 체인 CH13 LangChain Expression Language(LCEL)'], ['01. RunnablePassthrough: 데이터 전달'], ['02. Runnable 구조(그래프) 확인'], ['03. RunnableLambda: 사용자 정의 함수'], ['04. RunnableBranch: 라우팅(Routing)'], ['05. RunnableParallel: 병렬 처리'], ['06. configurable_fields, configurable_alternatives 07. @chain 데코레이터로 Runnable 생성', '08. RunnableWithMessageHistory'], ['09. 사용자 정의 제네레이터(generator)'], ['10. Runtime Arguments 바인딩'], ['11. 폴백(fallback) 모델 지정 CH14 체인(Chains)'], ['01. 문서 요약'], ['02. SQL CH15 에이전트(Agent)'], ['01. Agent 사용법 톺아보기'], ['02. 도구를 활용한 토론 에이전트(Two Agent Debates with Tools) CH16 파인튜닝(Fine Tuning)'], ['CH17 LangGraph'], ['01. Chain of Table for Multiple Tables'], ['Published with WikiDocs'], ['<랭체인LangChain 노트> - Lang…'], ['CH01 LangChain 시작하기'], ['02. LangSmith 추적 설정'], ['위키독스'], ['02. LangSmith 추적 설정'], ['LangSmith 추적 설정하기'], ['LangSmith는 LLM 애플리케이션 개발, 모니터링 및 테스트 를 위한 플랫폼입니다.'], ['프로젝트나 LangChain 학습을 시작하시는 분들이라면 LangSmith는 꼭 설정 후 진행하는 것을 추천 드립니다.'], ['LangSmith 의 추적기능'], ['추적은 LLM 애플리케이션의 동작을 이해하기 위한 강력한 도구입니다.', 'LangSmith는 LangChain 사용 여부와 관계없이 동급 최고의 추적 기능을 제공합니다.'], ['추적은 다음과 같은 문제를 추적하는 데 도움이 될 수 있습니다.'], ['예상치 못한 최종 결과'], ['에이전트가 루핑되는 이유', '체인이 예상보다 느린 이유'], ['에이전트가 각 단계에서 사용한 토큰 수'], ['프로젝트 단위 추적'], ['프로젝트 단위로 실행 카운트, Error 발생률, 토큰 사용량, 과금 정보등을 확인할 수 있습니다.', '프로젝트를 클릭하면 실행된 모든 Run 이 나타납니다.', '1개의 실행에 대한 세부 단계별 추척'], ['1개의 실행을 한 뒤 retrieve 된 문서의 검색 결과 뿐만 아니라, GPT 의 입출력 내용에 대해서 자세하게 기록합니다.', '따라서, 문서의 검색된 내용을 확인 후 검색 알고리즘을 변경해야할지 혹은 프롬프트를 변경해야할지 판단하는데 도움이 됩니다.', '뿐만 아니라, 상단에는 1개의 실행(Run) 이 걸린 시간(약 30초)와 사용된 토큰(5,104) 등이 표기가 되고, 토큰에 마우스 호버를 하게 되면 청구 금액까지 표기해 줍니다.'], ['LangSmith 추적 사용하기', '추적을 사용하는 방법은 매우 간단합니다.'], ['LangSmith API Key 발급', 'https://smith.langchain.com/ 으로 접속하여 회원가입을 진행합니다.', '가입후 이메일 인증하는 절차를 진행해야 합니다.', '왼쪽 톱니바퀴(Setting) - 가운데 \"Personal\" - \"Create API Key\" 를 눌러 API 키를 발급 받습니다.', 'Description 에 본인이 알 수 있는 설명을 넣고 Create API Key 버튼을 클릭하여 생성합니다.', '생성한 키를 복사한 뒤 다음 단계로 진행합니다.'], ['(주의!)', '생성한 키를 유출하지 않도록 안전한 곳에 복사해 두세요.'], ['.env 에 LangSmith 키 설정', '먼저, .env 파일에 LangSmith 에서 발급받은 키와 프로젝트 정보를 입력합니다.'], ['LANGCHAIN_TRACING_V2: \"true\" 로 설정하면 추적을 시작합니다.'], ['LANGCHAIN_ENDPOINT: https://api.smith.langchain.com 변경하지 않습니다.', 'LANGCHAIN_API_KEY: 이전 단계에서 발급받은 키 를 입력합니다.'], ['LANGCHAIN_PROJECT: 프로젝트 명 을 기입하면 해당 프로젝트 그룹으로 모든 실행(Run) 이 추적됩니다.'], ['Jupyter Notebook 혹은 코드에서 추적을 활성화 하기', '추적을 활성화 하는 방법은 매우 간단합니다.', '환경 변수만 설정하면 됩니다.'], ['.env 에 설정한 내용을 불러옵니다.', 'from dotenv import load_dotenv', 'load_dotenv()'], ['만약 설정한 추적이 활성화 되어 있고, API KEY 와 프로젝트 명이 제대로 설정되어 있다면, 이걸로도 충분합니다.', '하지만, 프로젝트 명을 변경하거나, 추적을 변경하고 싶을 때는 아래의 코드로 변경할 수 있습니다.'], ['import os'], ['os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"'], ['os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"'], ['os.environ[\"LANGCHAIN_PROJECT\"] = \"LangChain 프로젝트명\"'], ['os.environ[\"LANGCHAIN_API_KEY\"] = \"LangChain API KEY 입력\"'], ['langchain-teddynote', 'langchain 관련 기능을 보다 더 편리하게 사용하기 위한 목적으로 langchain-teddynote 패키지를 만들었습니다.', '설치방법', '설치코드 (터미널에서 실행 혹은 Jupyter Notebook 에서 실행)'], ['pip install langchain-teddynote'], ['LangSmith 추적 설정'], ['.env 파일에 LangSmith API 키가 설정 되어 있어야 합니다.(LANGCHAIN_API_KEY)'], ['from langchain_teddynote import logging', '# 프로젝트 이름을 입력합니다.', 'logging.langsmith(\"원하는 프로젝트명\")'], ['출력예시'], ['LangSmith 추적을 시작합니다.'], ['[프로젝트명]'], ['랭체인 튜토리얼 프로젝트'], ['추척을 원하지 않을 때는 다음과 같이 추적을 끌 수 있습니다.'], ['from langchain_teddynote import logging'], ['# set_enable=False 로 지정하면 추적을 하지 않습니다.', 'logging.langsmith(\"랭체인 튜토리얼 프로젝트\", set_enable=False)'], ['마지막 편집일시 : 2024년 6월 17일 10:13 오후'], ['댓글 0 피드백'], ['※ 댓글 작성은 로그인이 필요합니다.', '(또는 피드백을 이용해 주세요.)'], ['이전글 : 01.'], ['OpenAI API 키 발급 및 테스트'], ['다음글 : 03.'], ['OpenAI API 사용(GPT-4o 멀티모달)'], ['책갈피'], ['이 페이지에 대한 피드백을 남겨주세요'], ['댓글을 신고합니다.']], 'span': [[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15], [16], [17], [18], [19], [20], [21], [22], [23], [24], [25], [26], [27], [28], [29], [30], [31], [32], [33], [34], [35], [36, 37], [38], [39], [40], [41], [42], [43], [44], [45], [46], [47], [48], [49], [50], [51], [52], [53], [54], [55], [56], [57], [58], [59], [60], [61], [62], [63], [64], [65], [66], [67], [68], [69], [70], [71], [72], [73], [74], [75], [76], [77], [78], [79], [80], [81], [82], [83], [84], [85], [86], [87], [88], [89], [90], [91], [92], [93], [94, 95], [96], [97], [98], [99], [100], [101], [102], [103], [104], [105], [106], [107], [108], [109], [110], [111], [112], [113], [114], [115, 116], [117], [118], [119, 120], [121], [122], [123, 124, 125], [126, 127, 128], [129, 130], [131, 132, 133, 134, 135, 136], [137, 138], [139, 140], [141], [142, 143], [144], [145, 146, 147], [148, 149, 150], [151, 152], [153], [154], [155], [156], [157], [158, 159, 160, 161], [162], [163], [164], [165, 166, 167], [168], [169], [170], [171], [172], [173], [174, 175], [176], [177], [178, 179], [180], [181], [182], [183], [184], [185], [186]], 'inputTokens': 4365}}\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 6/7 [00:20<00:03,  3.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "{'status': {'code': '20000', 'message': 'OK'}, 'result': {'topicSeg': [['<랭체인LangChain 노트> - LangChain 한국어 튜토리얼🇰🇷 CH01 LangChain 시작하기'], ['01. OpenAI API 키 발급 및 테스트'], ['02. LangSmith 추적 설정'], ['03. OpenAI API 사용(GPT-4o 멀티모달)'], ['04. LangChain Expression Language(LCEL)'], ['05. LCEL 인터페이스'], ['06. Runnable CH02 프롬프트(Prompt)'], ['01. 프롬프트(Prompt)'], ['02. 퓨샷 프롬프트(FewShotPromptTemplate)'], ['03. LangChain Hub'], ['04. 개인화된 프롬프트(Hub에 업로드) CH03 출력 파서(Output Parsers)'], ['01. Pydantic 출력 파서(PydanticOutputParser)'], ['02. 콤마 구분자 출력 파서(CommaSeparatedListOutputParser)'], ['03. 구조화된 출력 파서(StructuredOuputParser)'], ['04. JSON 출력 파서(JsonOutputParser)'], ['05. 데이터프레임 출력 파서(PandasDataFrameOutputParser)'], ['06. 날짜 형식 출력 파서(DatetimeOutputParser)'], ['07. 열거형 출력 파서(EnumOutputParser)'], ['08. 출력 수정 파서(OutputFixingParser) CH04 모델(Model)'], ['01. 다양한 LLM 모델 활용'], ['02. 캐싱(Cache)'], ['03. 모델 직렬화(Serialization) - 저장 및 불러오기'], ['04. 토큰 사용량 확인'], ['05. 구글 생성 AI(Google Generative AI)'], ['06. 허깅페이스 엔드포인트(HuggingFace Endpoints)'], ['07. 허깅페이스 로컬(HuggingFace Local)'], ['08. 허깅페이스 파이프라인(HuggingFace Pipeline)'], ['09. 올라마(Ollama)'], ['10. GPT4ALL CH05 메모리(Memory)'], ['01. 대화 버퍼 메모리(ConversationBufferMemory)'], ['02. 대화 버퍼 윈도우 메모리(ConversationBufferWindowMemory)'], ['03. 대화 토큰 버퍼 메모리(ConversationTokenBufferMemory)'], ['04. 대화 엔티티 메모리(ConversationEntityMemory)'], ['05. 대화 지식그래프 메모리(ConversationKGMemory)'], ['06. 대화 요약 메모리(ConversationSummaryMemory)'], ['07. 벡터저장소 검색 메모리(VectorStoreRetrieverMemory)'], ['08. LCEL Chain 에 메모리 추가', '09. SQLite 에 대화내용 저장'], ['10. RunnableWithMessageHistory에 ChatMessageHistory추가 CH06 문서 로더(Document Loader)'], ['01. 도큐먼트(Document) 의 구조'], ['02. PDF'], ['03. 한글(HWP)'], ['04. CSV'], ['05. Excel'], ['06. Word'], ['07. PowerPoint'], ['08. 웹 문서(WebBaseLoader)'], ['09. 텍스트(TextLoader)'], ['10. JSON'], ['11. Arxiv'], ['13. UpstageLayoutAnalysisLoader'], ['14. LlamaParser CH07 텍스트 분할(Text Splitter)'], ['01. 문자 텍스트 분할(CharacterTextSplitter)'], ['02. 재귀적 문자 텍스트 분할(RecursiveCharacterTextSplitter)'], ['03. 토큰 텍스트 분할(TokenTextSplitter)'], ['04. 시멘틱 청커(SemanticChunker)'], ['05. 코드 분할(Python, Markdown, JAVA, C++, C#, GO, JS, Latex 등)'], ['06. 마크다운 헤더 텍스트 분할(MarkdownHeaderTextSplitter)'], ['07. HTML 헤더 텍스트 분할(HTMLHeaderTextSplitter)'], ['08. 재귀적 JSON 분할(RecursiveJsonSplitter) CH08 임베딩(Embedding)'], ['01. OpenAIEmbeddings'], ['02. 캐시 임베딩(CacheBackedEmbeddings)'], ['03. 허깅페이스 임베딩(HuggingFace Embeddings)'], ['04. UpstageEmbeddings'], ['05. OllamaEmbeddings'], ['06. GPT4ALL 임베딩'], ['07. Llama CPP 임베딩 CH09 벡터저장소(VectorStore)'], ['01. Chroma'], ['02. FAISS'], ['03. Pinecone CH10 검색기(Retriever)'], ['01. 벡터저장소 지원 검색기(VectorStore-backed Retriever)'], ['02. 문맥 압축 검색기(ContextualCompressionRetriever)'], ['03. 앙상블 검색기(EnsembleRetriever)'], ['04. 긴 문맥 재정렬(LongContextReorder)'], ['05. 상위 문서 검색기(ParentDocumentRetriever)'], ['06. 다중 쿼리 검색기(MultiQueryRetriever)'], ['07. 다중 벡터저장소 검색기(MultiVectorRetriever)'], ['08. 셀프 쿼리 검색기(SelfQueryRetriever)'], ['09. 시간 가중 벡터저장소 검색기(TimeWeightedVectorStoreRetriever)'], ['10. 한글 형태소 분석기(Kiwi, Kkma, Okt) + BM25 검색기 CH11 리랭커(Reranker)'], ['01. Cross Encoder Reranker'], ['02. Cohere Reranker'], ['03. Jina Reranker'], ['04. FlashRank Reranker CH12 Retrieval Augmented Generation(RAG)'], ['01. PDF 문서 기반 QA(Question-Answer)'], ['02. 네이버 뉴스기사 QA(Question-Answer)'], ['03. RAG 의 기능별 다양한 모듈 활용기'], ['04. RAPTOR: 긴 문맥 요약(Long Context Summary)'], ['05. 대화내용을 기억하는 RAG 체인 CH13 LangChain Expression Language(LCEL)'], ['01. RunnablePassthrough: 데이터 전달'], ['02. Runnable 구조(그래프) 확인'], ['03. RunnableLambda: 사용자 정의 함수'], ['04. RunnableBranch: 라우팅(Routing)'], ['05. RunnableParallel: 병렬 처리'], ['06. configurable_fields, configurable_alternatives 07. @chain 데코레이터로 Runnable 생성', '08. RunnableWithMessageHistory'], ['09. 사용자 정의 제네레이터(generator)'], ['10. Runtime Arguments 바인딩'], ['11. 폴백(fallback) 모델 지정 CH14 체인(Chains)'], ['01. 문서 요약'], ['02. SQL CH15 에이전트(Agent)'], ['01. Agent 사용법 톺아보기'], ['02. 도구를 활용한 토론 에이전트(Two Agent Debates with Tools) CH16 파인튜닝(Fine Tuning)'], ['CH17 LangGraph'], ['01. Chain of Table for Multiple Tables'], ['Published with WikiDocs'], ['<랭체인LangChain 노트> - Lang…'], ['CH01 LangChain 시작하기'], ['01. OpenAI API 키 발급 및 테스트'], ['위키독스'], ['01. OpenAI API 키 발급 및 테스트'], ['OpenAI API 키 발급 및 설정'], ['1)'], ['OpenAI API 키 발급'], ['OpenAI API 웹사이트에 접속합니다.'], ['링크: https://platform.openai.com/docs/overview', '우측 상단 \"Sign Up\" 을 눌러 회원가입을 진행합니다.', '(만약, 이미 가입되어 있는 상태라면 \"Log in\" 버튼을 눌러 로그인 합니다.', '우측 상단 톱니바퀴(Setting) 를 눌러 설정으로 이동합니다.'], ['왼쪽 \"Billing\" 메뉴에서 \"Payment methods\" 를 클릭하여 신용카드를 등록 합니다.', '신용카드를 등록했다면 아래와 같이 등록된 신용카드가 목록에 나타납니다.'], ['\"Add to credit balance\" 버튼을 눌러 사용할만큼의 미화(달러) 를 입력합니다.', '금액은 $5 부터 추가가 가능합니다.', '(즉, 최소결제금액인 $5 이상은 결제를 해야 합니다)', '금액을 입력한 후 \"Continue\" 를 눌러 결제를 진행합니다.'], ['왼쪽의 \"Limits\" 탭에서 월간 사용한도를 설정할 수 있습니다.'], ['\"Set a monthly budge\": 월간 사용한도를 지정합니다.', '이 금액에 도달하면 더이상 과금하지 않고 API 는 사용을 멈춥니다.'], ['\"Set an email notification threshold\": 이메일이 발송되는 요금을 지정할 수 있습니다.', '이 금액에 도달하면 이메일이 발송됩니다.'], ['우측 프로필 이미지 클릭 - \"Your profile\"'], ['API Key 관리 메뉴 로 접속합니다.'], ['https://platform.openai.com/api-keys'], ['\"Create new secret key\" 를 클릭합니다.', 'Name 과 프로젝트 를 입력합니다.', '(별도 생성한 프로젝트가 없다면 Default project 를 설정합니다)', '우측 \"Copy\" 버튼을 눌러 키를 복사합니다.'], ['주의!!!'], ['키가 유출되면 다른 사람이 내 API KEY 를 사용하여 GPT 를 사용할 수 있으며, 결제는 제 지갑에서 결제됩니다.', '절대 키는 타인에게 공유하지 마시고, 안전한 곳에 보관 하세요!'], ['(암호라고 생각하세요)'], ['2) .env 파일 설정', '프로젝트 루트 디렉토리에 .env 파일을 생성합니다.', '.env 파일에 OPENAI_API_KEY=방금복사한 키를 입력 한 뒤 Ctrl + S 를 눌러 저장하고 파일을 닫습니다.'], ['# LangChain 업데이트'], ['!pip install -r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt'], ['# API KEY를 환경변수로 관리하기 위한 설정 파일', '# 설치: pip install python-dotenv', 'from dotenv import load_dotenv', '# API KEY 정보로드'], ['load_dotenv()'], ['True'], ['API Key 가 잘 설정되었는지 확인합니다.'], ['import os', 'print(f\"[API KEY]'], ['{os.environ[\\'OPENAI_API_KEY\\']}\")'], ['마지막 편집일시 : 2024년 6월 17일 8:24 오후'], ['댓글 0 피드백'], ['※ 댓글 작성은 로그인이 필요합니다.'], ['(또는 피드백을 이용해 주세요.)'], ['이전글 : CH01 LangChain 시작하기'], ['다음글 : 02.'], ['LangSmith 추적 설정'], ['책갈피'], ['이 페이지에 대한 피드백을 남겨주세요'], ['댓글을 신고합니다.']], 'span': [[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15], [16], [17], [18], [19], [20], [21], [22], [23], [24], [25], [26], [27], [28], [29], [30], [31], [32], [33], [34], [35], [36, 37], [38], [39], [40], [41], [42], [43], [44], [45], [46], [47], [48], [49], [50], [51], [52], [53], [54], [55], [56], [57], [58], [59], [60], [61], [62], [63], [64], [65], [66], [67], [68], [69], [70], [71], [72], [73], [74], [75], [76], [77], [78], [79], [80], [81], [82], [83], [84], [85], [86], [87], [88], [89], [90], [91], [92], [93], [94, 95], [96], [97], [98], [99], [100], [101], [102], [103], [104], [105], [106], [107], [108], [109], [110], [111], [112], [113], [114], [115, 116, 117, 118], [119, 120], [121, 122, 123, 124], [125], [126, 127], [128, 129], [130], [131], [132], [133, 134, 135, 136], [137], [138, 139], [140], [141, 142, 143], [144], [145], [146, 147, 148, 149], [150], [151], [152], [153, 154], [155], [156], [157], [158], [159], [160], [161], [162], [163], [164], [165]], 'inputTokens': 3738}}\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:25<00:00,  3.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "{'status': {'code': '20000', 'message': 'OK'}, 'result': {'topicSeg': [['<랭체인LangChain 노트> - LangChain 한국어 튜토리얼🇰🇷 CH01 LangChain 시작하기'], ['01. OpenAI API 키 발급 및 테스트'], ['02. LangSmith 추적 설정'], ['03. OpenAI API 사용(GPT-4o 멀티모달)'], ['04. LangChain Expression Language(LCEL)'], ['05. LCEL 인터페이스'], ['06. Runnable CH02 프롬프트(Prompt)'], ['01. 프롬프트(Prompt)'], ['02. 퓨샷 프롬프트(FewShotPromptTemplate)'], ['03. LangChain Hub'], ['04. 개인화된 프롬프트(Hub에 업로드) CH03 출력 파서(Output Parsers)'], ['01. Pydantic 출력 파서(PydanticOutputParser)'], ['02. 콤마 구분자 출력 파서(CommaSeparatedListOutputParser)'], ['03. 구조화된 출력 파서(StructuredOuputParser)'], ['04. JSON 출력 파서(JsonOutputParser)'], ['05. 데이터프레임 출력 파서(PandasDataFrameOutputParser)'], ['06. 날짜 형식 출력 파서(DatetimeOutputParser)'], ['07. 열거형 출력 파서(EnumOutputParser)'], ['08. 출력 수정 파서(OutputFixingParser) CH04 모델(Model)'], ['01. 다양한 LLM 모델 활용'], ['02. 캐싱(Cache)'], ['03. 모델 직렬화(Serialization) - 저장 및 불러오기'], ['04. 토큰 사용량 확인'], ['05. 구글 생성 AI(Google Generative AI)'], ['06. 허깅페이스 엔드포인트(HuggingFace Endpoints)'], ['07. 허깅페이스 로컬(HuggingFace Local)'], ['08. 허깅페이스 파이프라인(HuggingFace Pipeline)'], ['09. 올라마(Ollama)'], ['10. GPT4ALL CH05 메모리(Memory)'], ['01. 대화 버퍼 메모리(ConversationBufferMemory)'], ['02. 대화 버퍼 윈도우 메모리(ConversationBufferWindowMemory)'], ['03. 대화 토큰 버퍼 메모리(ConversationTokenBufferMemory)'], ['04. 대화 엔티티 메모리(ConversationEntityMemory)'], ['05. 대화 지식그래프 메모리(ConversationKGMemory)'], ['06. 대화 요약 메모리(ConversationSummaryMemory)'], ['07. 벡터저장소 검색 메모리(VectorStoreRetrieverMemory)'], ['08. LCEL Chain 에 메모리 추가', '09. SQLite 에 대화내용 저장'], ['10. RunnableWithMessageHistory에 ChatMessageHistory추가 CH06 문서 로더(Document Loader)'], ['01. 도큐먼트(Document) 의 구조'], ['02. PDF'], ['03. 한글(HWP)'], ['04. CSV'], ['05. Excel'], ['06. Word'], ['07. PowerPoint'], ['08. 웹 문서(WebBaseLoader)'], ['09. 텍스트(TextLoader)'], ['10. JSON'], ['11. Arxiv'], ['13. UpstageLayoutAnalysisLoader'], ['14. LlamaParser CH07 텍스트 분할(Text Splitter)'], ['01. 문자 텍스트 분할(CharacterTextSplitter)'], ['02. 재귀적 문자 텍스트 분할(RecursiveCharacterTextSplitter)'], ['03. 토큰 텍스트 분할(TokenTextSplitter)'], ['04. 시멘틱 청커(SemanticChunker)'], ['05. 코드 분할(Python, Markdown, JAVA, C++, C#, GO, JS, Latex 등)'], ['06. 마크다운 헤더 텍스트 분할(MarkdownHeaderTextSplitter)'], ['07. HTML 헤더 텍스트 분할(HTMLHeaderTextSplitter)'], ['08. 재귀적 JSON 분할(RecursiveJsonSplitter) CH08 임베딩(Embedding)'], ['01. OpenAIEmbeddings'], ['02. 캐시 임베딩(CacheBackedEmbeddings)'], ['03. 허깅페이스 임베딩(HuggingFace Embeddings)'], ['04. UpstageEmbeddings'], ['05. OllamaEmbeddings'], ['06. GPT4ALL 임베딩'], ['07. Llama CPP 임베딩 CH09 벡터저장소(VectorStore)'], ['01. Chroma'], ['02. FAISS'], ['03. Pinecone CH10 검색기(Retriever)'], ['01. 벡터저장소 지원 검색기(VectorStore-backed Retriever)'], ['02. 문맥 압축 검색기(ContextualCompressionRetriever)'], ['03. 앙상블 검색기(EnsembleRetriever)'], ['04. 긴 문맥 재정렬(LongContextReorder)'], ['05. 상위 문서 검색기(ParentDocumentRetriever)'], ['06. 다중 쿼리 검색기(MultiQueryRetriever)'], ['07. 다중 벡터저장소 검색기(MultiVectorRetriever)'], ['08. 셀프 쿼리 검색기(SelfQueryRetriever)'], ['09. 시간 가중 벡터저장소 검색기(TimeWeightedVectorStoreRetriever)'], ['10. 한글 형태소 분석기(Kiwi, Kkma, Okt) + BM25 검색기 CH11 리랭커(Reranker)'], ['01. Cross Encoder Reranker'], ['02. Cohere Reranker'], ['03. Jina Reranker'], ['04. FlashRank Reranker CH12 Retrieval Augmented Generation(RAG)'], ['01. PDF 문서 기반 QA(Question-Answer)'], ['02. 네이버 뉴스기사 QA(Question-Answer)'], ['03. RAG 의 기능별 다양한 모듈 활용기'], ['04. RAPTOR: 긴 문맥 요약(Long Context Summary)'], ['05. 대화내용을 기억하는 RAG 체인 CH13 LangChain Expression Language(LCEL)'], ['01. RunnablePassthrough: 데이터 전달'], ['02. Runnable 구조(그래프) 확인'], ['03. RunnableLambda: 사용자 정의 함수'], ['04. RunnableBranch: 라우팅(Routing)'], ['05. RunnableParallel: 병렬 처리'], ['06. configurable_fields, configurable_alternatives 07. @chain 데코레이터로 Runnable 생성', '08. RunnableWithMessageHistory'], ['09. 사용자 정의 제네레이터(generator)'], ['10. Runtime Arguments 바인딩'], ['11. 폴백(fallback) 모델 지정 CH14 체인(Chains)'], ['01. 문서 요약'], ['02. SQL CH15 에이전트(Agent)'], ['01. Agent 사용법 톺아보기'], ['02. 도구를 활용한 토론 에이전트(Two Agent Debates with Tools) CH16 파인튜닝(Fine Tuning)'], ['CH17 LangGraph'], ['01. Chain of Table for Multiple Tables'], ['Published with WikiDocs'], ['<랭체인LangChain 노트> - Lang…'], ['CH01 LangChain 시작하기'], ['03. OpenAI API 사용(GPT-4o…'], ['위키독스'], ['03. OpenAI API 사용(GPT-4o 멀티모달)'], ['# API KEY를 환경변수로 관리하기 위한 설정 파일'], ['from dotenv import load_dotenv'], ['# API KEY 정보로드'], ['load_dotenv()'], ['True'], ['# LangSmith 추적을 설정합니다.', 'https://smith.langchain.com'], ['# .env 파일에 LANGCHAIN_API_KEY를 입력합니다.'], ['# !pip install -qU langchain-teddynote'], ['from langchain_teddynote import logging'], ['# 프로젝트 이름을 입력합니다.', 'logging.langsmith(\"CH01-Basic\")'], ['LangSmith 추적을 시작합니다.'], ['[프로젝트명]'], ['CH01-Basic'], ['ChatOpenAI', 'OpenAI 사의 채팅 전용 Large Language Model(llm) 입니다.'], ['객체를 생성할 때 다음을 옵션 값을 지정할 수 있습니다.', '옵션에 대한 상세 설명은 다음과 같습니다.'], ['temperature'], ['사용할 샘플링 온도는 0과 2 사이에서 선택합니다.', '0.8과 같은 높은 값은 출력을 더 무작위하게 만들고, 0.2와 같은 낮은 값은 출력을 더 집중되고 결정론적으로 만듭니다.'], ['max_tokens'], ['채팅 완성에서 생성할 토큰의 최대 개수입니다.'], ['model_name: 적용 가능한 모델 리스트 - gpt-3.5-turbo - gpt-4-turbo - gpt-4o'], ['링크: https://platform.openai.com/docs/models'], ['from langchain_openai import ChatOpenAI'], ['# 객체 생성', 'llm = ChatOpenAI('], ['temperature=0.1, # 창의성 (0.0 ~ 2.0)'], ['model_name=\"gpt-4o\", # 모델명'], [')'], ['# 질의내용', 'question = \"대한민국의 수도는 어디인가요?\"'], ['# 질의'], ['print(f\"[답변]: {llm.invoke(question)}\")'], [\"[답변]: content='대한민국의 수도는 서울입니다.\"], [\"서울은 대한민국의 정치, 경제, 문화의 중심지로서 많은 인구와 다양한 명소를 자랑하는 도시입니다.' response_metadata={'token_usage': {'completion_tokens': 36, 'prompt_tokens': 16, 'total_tokens': 52}, 'model_name': 'gpt-4o', 'system_fingerprint': 'fp_f4e629d0a5', 'finish_reason': 'stop', 'logprobs': None} id='run-dcda4cfa-3143-4982-b24c-4a25ce0a447e-0' usage_metadata={'input_tokens': 16, 'output_tokens': 36, 'total_tokens': 52}\"], ['답변의 형식(AI Message)'], ['# 질의내용'], ['question = \"대한민국의 수도는 어디인가요?\"'], ['# 질의'], ['response = llm.invoke(question)'], ['response'], [\"AIMessage(content='대한민국의 수도는 서울입니다.\"], [\"서울은 대한민국의 정치, 경제, 문화의 중심지로서 많은 인구와 다양한 명소를 자랑하는 도시입니다.', response_metadata={'token_usage': {'completion_tokens': 36, 'prompt_tokens': 16, 'total_tokens': 52}, 'model_name': 'gpt-4o', 'system_fingerprint': 'fp_aa87380ac5', 'finish_reason': 'stop', 'logprobs': None}, id='run-3296402a-f47b-4ace-88cd-b74efb7465fb-0', usage_metadata={'input_tokens': 16, 'output_tokens': 36, 'total_tokens': 52})\"], ['response.content'], [\"'대한민국의 수도는 서울입니다.\"], [\"서울은 대한민국의 정치, 경제, 문화의 중심지로서 많은 인구와 다양한 명소를 자랑하는 도시입니다.'\"], ['response.response_metadata'], [\"{'token_usage': {'completion_tokens': 36, 'prompt_tokens': 16, 'total_tokens': 52}, 'model_name': 'gpt-4o', 'system_fingerprint': 'fp_aa87380ac5', 'finish_reason': 'stop', 'logprobs': None}\"], ['LogProb 활성화'], ['주어진 텍스트에 대한 모델의 토큰 확률의 로그 값 을 의미합니다.', '토큰이란 문장을 구성하는 개별 단어나 문자 등의 요소를 의미하고, 확률은 모델이 그 토큰을 예측할 확률을 나타냅니다.'], ['# 객체 생성'], ['llm_with_logprob = ChatOpenAI('], ['temperature=0.1, # 창의성 (0.0 ~ 2.0)'], ['max_tokens=2048, # 최대 토큰수'], ['model_name=\"gpt-3.5-turbo\", # 모델명'], [').bind(logprobs=True)'], ['# 질의내용', 'question = \"대한민국의 수도는 어디인가요?\"'], ['# 질의'], ['response = llm_with_logprob.invoke(question)'], ['# 결과 출력', 'response.response_metadata'], [\"{'token_usage': {'completion_tokens': 15, 'prompt_tokens': 24, 'total_tokens': 39}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': {'content': [{'token': '대', 'bytes': [235, 140, 128], 'logprob': -0.03859115, 'top_logprobs': []}, {'token': '한', 'bytes': [237, 149, 156], 'logprob': -5.5122365e-07, 'top_logprobs': []}, {'token': '\\\\\\\\xeb\\\\\\\\xaf', 'bytes': [235, 175], 'logprob': -2.8160932e-06, 'top_logprobs': []}, {'token': '\\\\\\\\xbc', 'bytes': [188], 'logprob': 0.0, 'top_logprobs': []}, {'token': '\\\\\\\\xea\\\\\\\\xb5', 'bytes': [234, 181], 'logprob': -6.704273e-07, 'top_logprobs': []}, {'token': '\\\\\\\\xad', 'bytes': [173], 'logprob': 0.0, 'top_logprobs': []}, {'token': '의', 'bytes': [236, 157, 152], 'logprob': -6.2729996e-06, 'top_logprobs': []}, {'token': ' 수', 'bytes': [32, 236, 136, 152], 'logprob': -5.5122365e-07, 'top_logprobs': []}, {'token': '도', 'bytes': [235, 143, 132], 'logprob': -5.5122365e-07, 'top_logprobs': []}, {'token': '는', 'bytes': [235, 138, 148], 'logprob': -1.9361265e-07, 'top_logprobs': []}, {'token': ' 서', 'bytes': [32, 236, 132, 156], 'logprob': -5.080963e-06, 'top_logprobs': []}, {'token': '\\\\\\\\xec\\\\\\\\x9a', 'bytes': [236, 154], 'logprob': 0.0, 'top_logprobs': []}, {'token': '\\\\\\\\xb8', 'bytes': [184], 'logprob': 0.0, 'top_logprobs': []}, {'token': '입니다', 'bytes': [236, 158, 133, 235, 139, 136, 235, 139, 164], 'logprob': -0.13815464, 'top_logprobs': []}, {'token': '.', 'bytes': [46], 'logprob': -9.0883464e-07, 'top_logprobs': []}]}}\"], ['스트리밍 출력'], ['스트리밍 옵션은 질의에 대한 답변을 실시간으로 받을 때 유용합니다.'], ['# 스트림 방식으로 질의'], ['# answer 에 스트리밍 답변의 결과를 받습니다.'], ['answer = llm.stream(\"대한민국의 아름다운 관광지 10곳과 주소를 알려주세요!\")'], ['# 스트리밍 방식으로 각 토큰을 출력합니다.'], ['(실시간 출력)', 'for token in answer:', 'print(token.content, end=\"\", flush=True)'], ['물론입니다!'], ['대한민국에는 아름다운 관광지가 많이 있습니다.'], ['다음은 그 중 10곳과 그 주소입니다:'], ['1. **경복궁**'], ['- 주소: 서울특별시 종로구 사직로 161'], ['2. **부산 해운대 해수욕장**', '- 주소: 부산광역시 해운대구 우동'], ['3. **제주도 한라산 국립공원**', '- 주소: 제주특별자치도 제주시 1100로 2070-61'], ['4. **경주 불국사**'], ['- 주소: 경상북도 경주시 불국로 385'], ['5. **설악산 국립공원**'], ['- 주소: 강원도 속초시 설악산로 833'], ['6. **남이섬**'], ['- 주소: 강원도 춘천시 남산면 남이섬길 1'], ['7. **안동 하회마을**'], ['- 주소: 경상북도 안동시 풍천면 하회종가길 40'], ['8. **전주 한옥마을**'], ['- 주소: 전라북도 전주시 완산구 기린대로 99'], ['9. **서울 남산타워 (N서울타워)**'], ['- 주소: 서울특별시 용산구 남산공원길 105'], ['10. **보성 녹차밭 대한다원**', '- 주소: 전라남도 보성군 보성읍 녹차로 763-67'], ['이 관광지들은 각기 다른 매력을 가지고 있어 다양한 경험을 할 수 있습니다.'], ['즐거운 여행 되세요!'], ['from langchain_teddynote.messages import stream_response'], ['# 스트림 방식으로 질의', '# answer 에 스트리밍 답변의 결과를 받습니다.', 'answer = llm.stream(\"대한민국의 아름다운 관광지 10곳과 주소를 알려주세요!\")'], ['stream_response(answer)', '물론입니다!'], ['대한민국에는 아름다운 관광지가 많이 있습니다.', '다음은 그 중 10곳과 그 주소입니다:'], ['1. **경복궁**'], ['- 주소: 서울특별시 종로구 사직로 161'], ['2. **부산 해운대 해수욕장**', '- 주소: 부산광역시 해운대구 우동'], ['3. **제주도 한라산 국립공원**', '- 주소: 제주특별자치도 제주시 1100로 2070-61'], ['4. **경주 불국사**'], ['- 주소: 경상북도 경주시 불국로 385'], ['5. **설악산 국립공원**'], ['- 주소: 강원도 속초시 설악산로 833'], ['6. **남이섬**'], ['- 주소: 강원도 춘천시 남산면 남이섬길 1'], ['7. **전주 한옥마을**'], ['- 주소: 전라북도 전주시 완산구 기린대로 99'], ['8. **안동 하회마을**'], ['- 주소: 경상북도 안동시 풍천면 하회종가길 40'], ['9. **서울 남산타워 (N서울타워)**'], ['- 주소: 서울특별시 용산구 남산공원길 105'], ['10. **순천만 국가정원**'], ['- 주소: 전라남도 순천시 국가정원1호길 47'], ['이 관광지들은 각기 다른 매력을 가지고 있어 다양한 경험을 할 수 있습니다.'], ['즐거운 여행 되세요!'], ['멀티모달 모델(이미지 인식)'], ['멀티모달은 여러 가지 형태의 정보(모달)를 통합하여 처리하는 기술이나 접근 방식을 의미합니다.'], ['이는 다음과 같은 다양한 데이터 유형을 포함할 수 있습니다.'], ['텍스트: 문서, 책, 웹 페이지 등의 글자로 된 정보'], ['이미지: 사진, 그래픽, 그림 등 시각적 정보'], ['오디오: 음성, 음악, 소리 효과 등의 청각적 정보'], ['비디오: 동영상 클립, 실시간 스트리밍 등 시각적 및 청각적 정보의 결합'], ['gpt-4o 나 gpt-4-turbo 모델은 이미지 인식 기능(Vision) 이 추가되어 있는 모델입니다.'], ['from langchain_teddynote.models import MultiModal'], ['from langchain_teddynote.messages import stream_response'], ['# 객체 생성'], ['llm = ChatOpenAI('], ['temperature=0.1, # 창의성 (0.0 ~ 2.0)'], ['max_tokens=2048, # 최대 토큰수'], ['model_name=\"gpt-4o\", # 모델명'], [')'], ['# 멀티모달 객체 생성'], ['multimodal_llm = MultiModal(llm)'], ['# 샘플 이미지 주소(웹사이트로 부터 바로 인식)'], ['IMAGE_URL = \"https://t3.ftcdn.net/jpg/03/77/33/96/360_F_377339633_Rtv9I77sSmSNcev8bEcnVxTHrXB4nRJ5.jpg\"'], ['# 이미지 파일로 부터 질의'], ['answer = multimodal_llm.stream(IMAGE_URL)'], ['# 스트리밍 방식으로 각 토큰을 출력합니다.', '(실시간 출력)', 'stream_response(answer)'], ['이 이미지는 표 형식의 데이터 테이블을 보여줍니다.', '테이블의 제목은 \"TABLE 001: LOREM IPSUM DOLOR AMIS ENIMA ACCUMER TUNA\"입니다.', '테이블은 다섯 개의 열과 여덟 개의 행으로 구성되어 있습니다.', '열 제목은 다음과 같습니다:'], ['1. Loremis'], ['2. Amis terim'], ['3. Gato lepis'], ['4. Tortores'], ['각 행의 데이터는 다음과 같습니다:'], ['1. Lorem dolor siamet: 8,288, 123%, YES, $89'], ['2. Consecter odio: 123, 87%, NO, $129'], ['3. Gatoque accums: 1,005, 12%, NO, $199'], ['4. Sed hac enim rem: 56, 69%, N/A, $199', '5. Rempus tortor just: 5,554, 18%, NO, $999', '6. Klimas nsecter: 455, 56%, NO, $245'], ['7. Babiask atque accu: 1,222, 2%, YES, $977'], ['8. Enim rem kos: 5,002, 91%, N/A, $522'], ['표 하단에는 작은 글씨로 Lorem ipsum 텍스트가 포함되어 있습니다.'], ['# 로컬 PC 에 저장되어 있는 이미지의 경로 입력'], ['IMAGE_PATH_FROM_FILE = \"./images/sample-image.png\"'], ['# 이미지 파일로 부터 질의(스트림 방식)', 'answer = multimodal_llm.stream(IMAGE_PATH_FROM_FILE)'], ['# 스트리밍 방식으로 각 토큰을 출력합니다.', '(실시간 출력)', 'stream_response(answer)'], ['이미지 설명 대체 텍스트:'], ['이미지에는 \"FIRST OPENAI DEVDAY EVENT\"라는 제목이 상단에 크게 표시되어 있습니다.'], ['이벤트 날짜는 2023년 11월 6일입니다.'], ['주요 업데이트 항목으로는 GPT 4 Turbo, 128k Tokens, Custom GPTs, Assistant API, Price Reduction이 나열되어 있습니다.', '이미지 왼쪽 상단에는 \"ASTRA TECHZ\" 로고가 있습니다.', '이미지 중앙에는 \"MAIN UPDATES SUMMARISED\"라는 제목 아래 주요 업데이트 내용이 요약되어 있습니다.', '각 항목 옆에는 체크 표시가 있으며, 세부 내용은 다음과 같습니다:'], ['- Token Length: 128K'], ['- Custom GPTs: Private or Public'], ['- Multi Modal: Img, Video, Voice'], ['- JSON Mode: Guaranteed'], ['- Assistant API: Developers'], ['- Text 2 Speech: Beta Release'], ['- Natural Voice Options: 6 Voices'], ['- GPT Store: Revenue Shared'], ['- Conversation Threading: Per Conversation'], ['- File Uploading: Multiple'], ['- API Price Reduction: 2.5x - 3.5x'], ['- Code Interpreter: Built In'], ['- Function Calling: Built In'], ['이미지 하단에는 \"visit www.astratechz.com to build AI solutions\"라는 문구가 있습니다.'], ['System, User 프롬프트 수정'], ['system_prompt = \"\"\"당신은 표(재무제표) 를 해석하는 금융 AI 어시스턴트 입니다.', '당신의 임무는 주어진 테이블 형식의 재무제표를 바탕으로 흥미로운 사실을 정리하여 친절하게 답변하는 것입니다.\"\"\"'], ['user_prompt = \"\"\"당신에게 주어진 표는 회사의 재무제표 입니다.'], ['흥미로운 사실을 정리하여 답변하세요.\"\"\"'], ['# 멀티모달 객체 생성'], ['multimodal_llm_with_prompt = MultiModal(', 'llm, system_prompt=system_prompt, user_prompt=user_prompt'], [')'], ['# 로컬 PC 에 저장되어 있는 이미지의 경로 입력'], ['IMAGE_PATH_FROM_FILE = \"https://storage.googleapis.com/static.fastcampus.co.kr/prod/uploads/202212/080345-661/kwon-01.png\"'], ['# 이미지 파일로 부터 질의(스트림 방식)'], ['answer = multimodal_llm_with_prompt.stream(IMAGE_PATH_FROM_FILE)'], ['# 스트리밍 방식으로 각 토큰을 출력합니다.', '(실시간 출력)', 'stream_response(answer)'], ['주어진 재무제표를 바탕으로 몇 가지 흥미로운 사실을 정리해 보았습니다:'], ['1. **유동자산의 변화**:'], ['- 제 19기(2019년) 유동자산은 8,349,633백만원으로, 제 18기(2018년) 8,602,837백만원에 비해 감소하였습니다.', '- 특히 현금 및 현금성 자산이 제 18기 1,690,862백만원에서 제 19기 1,002,263백만원으로 크게 감소하였습니다.'], ['2. **매출채권**:', '- 매출채권은 제 18기 4,004,920백만원에서 제 19기 3,981,935백만원으로 소폭 감소하였습니다.'], ['3. **기타수취채권**:', '- 기타수취채권은 제 18기 321,866백만원에서 제 19기 366,141백만원으로 증가하였습니다.'], ['4. **비유동자산의 증가**:', '- 비유동자산은 제 18기 15,127,741백만원에서 제 19기 18,677,453백만원으로 크게 증가하였습니다.', '- 특히, 재고자산이 제 18기 2,426,364백만원에서 제 19기 2,670,294백만원으로 증가하였습니다.'], ['5. **기타유동자산**:', '- 기타유동자산은 제 18기 156,538백만원에서 제 19기 207,596백만원으로 증가하였습니다.'], ['6. **기타장기수취채권**:', '- 기타장기수취채권은 제 18기 118,086백만원에서 제 19기 505,489백만원으로 크게 증가하였습니다.', '이러한 변화들은 회사의 자산 구조와 재무 상태에 중요한 영향을 미칠 수 있으며, 특히 현금성 자산의 감소와 비유동자산의 증가가 눈에 띕니다.'], ['이는 회사의 유동성 관리와 장기 투자 전략에 대한 추가적인 분석이 필요함을 시사합니다.'], ['마지막 편집일시 : 2024년 6월 18일 1:19 오전'], ['댓글 0 피드백', '※ 댓글 작성은 로그인이 필요합니다.', '(또는 피드백을 이용해 주세요.)'], ['이전글 : 02.'], ['LangSmith 추적 설정'], ['다음글 : 04.'], ['LangChain Expression Language(LCEL)'], ['책갈피'], ['이 페이지에 대한 피드백을 남겨주세요'], ['댓글을 신고합니다.']], 'span': [[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15], [16], [17], [18], [19], [20], [21], [22], [23], [24], [25], [26], [27], [28], [29], [30], [31], [32], [33], [34], [35], [36, 37], [38], [39], [40], [41], [42], [43], [44], [45], [46], [47], [48], [49], [50], [51], [52], [53], [54], [55], [56], [57], [58], [59], [60], [61], [62], [63], [64], [65], [66], [67], [68], [69], [70], [71], [72], [73], [74], [75], [76], [77], [78], [79], [80], [81], [82], [83], [84], [85], [86], [87], [88], [89], [90], [91], [92], [93], [94, 95], [96], [97], [98], [99], [100], [101], [102], [103], [104], [105], [106], [107], [108], [109], [110], [111], [112], [113], [114], [115], [116, 117], [118], [119], [120], [121, 122], [123], [124], [125], [126, 127], [128, 129], [130], [131, 132], [133], [134], [135], [136], [137], [138, 139], [140], [141], [142], [143, 144], [145], [146], [147], [148], [149], [150], [151], [152], [153], [154], [155], [156], [157], [158], [159], [160], [161], [162], [163, 164], [165], [166], [167], [168], [169], [170], [171, 172], [173], [174], [175, 176], [177], [178], [179], [180], [181], [182], [183], [184, 185, 186], [187], [188], [189], [190], [191], [192, 193], [194, 195], [196], [197], [198], [199], [200], [201], [202], [203], [204], [205], [206], [207], [208, 209], [210], [211], [212], [213, 214, 215], [216, 217], [218, 219], [220], [221], [222, 223], [224, 225], [226], [227], [228], [229], [230], [231], [232], [233], [234], [235], [236], [237], [238], [239], [240], [241], [242], [243], [244], [245], [246], [247], [248], [249], [250], [251], [252], [253], [254], [255], [256], [257], [258], [259], [260], [261], [262], [263], [264, 265, 266], [267, 268, 269, 270], [271], [272], [273], [274], [275], [276], [277], [278], [279, 280, 281], [282], [283], [284], [285], [286], [287, 288], [289, 290, 291], [292], [293], [294], [295, 296, 297, 298], [299], [300], [301], [302], [303], [304], [305], [306], [307], [308], [309], [310], [311], [312], [313], [314, 315], [316], [317], [318], [319, 320], [321], [322], [323], [324], [325], [326, 327, 328], [329], [330], [331, 332], [333, 334], [335, 336], [337, 338, 339], [340, 341], [342, 343, 344], [345], [346], [347, 348, 349], [350], [351], [352], [353], [354], [355], [356]], 'inputTokens': 9545}}\n",
      "1486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "class SegmentationExecutor:\n",
    "    def __init__(self, host, api_key, api_key_primary_val, request_id):\n",
    "        self._host = host\n",
    "        self._api_key = api_key\n",
    "        self._api_key_primary_val = api_key_primary_val\n",
    "        self._request_id = request_id\n",
    " \n",
    "    def _send_request(self, completion_request):\n",
    "        headers = {\n",
    "            \"Content-Type\": \"application/json; charset=utf-8\",\n",
    "            \"X-NCP-CLOVASTUDIO-API-KEY\": self._api_key,\n",
    "            \"X-NCP-APIGW-API-KEY\": self._api_key_primary_val,\n",
    "            \"X-NCP-CLOVASTUDIO-REQUEST-ID\": self._request_id\n",
    "        }\n",
    " \n",
    "        conn = http.client.HTTPSConnection(self._host)\n",
    "        conn.request(\n",
    "            \"POST\",\n",
    "            \"/testapp/v1/api-tools/segmentation/90972c6f0a784c9886f4bc6ae8a66c01\", # If using Service App, change 'testapp' to 'serviceapp', and corresponding app id.\n",
    "            json.dumps(completion_request),\n",
    "            headers\n",
    "        )\n",
    "        response = conn.getresponse()\n",
    "        print(response.length)\n",
    "        result = json.loads(response.read().decode(encoding=\"utf-8\"))\n",
    "        print(result)\n",
    "        conn.close()\n",
    "        return result\n",
    " \n",
    "    def execute(self, completion_request):\n",
    "        res = self._send_request(completion_request)\n",
    "        if res[\"status\"][\"code\"] == \"20000\":\n",
    "            return res[\"result\"][\"topicSeg\"]\n",
    "        else:\n",
    "            raise ValueError(f\"{res}\")\n",
    " \n",
    " \n",
    "if __name__ == \"__main__\":\n",
    "    segmentation_executor = SegmentationExecutor(\n",
    "        host=\"clovastudio.apigw.ntruss.com\",\n",
    "        api_key=\"NTA0MjU2MWZlZTcxNDJiY9olvu8DfBGDWQ20qeVZrRupbxCgWcs/59xl7cuRCJQ/\",\n",
    "        api_key_primary_val=\"J97Kg6j6Nrc14yhuSv1JfvgWlJ2qbcOKUsAS88BB\",\n",
    "        request_id=\"\"\n",
    "    )\n",
    " \n",
    "    chunked_html = []\n",
    " \n",
    "    for htmldata in tqdm(langchainwiki_flattened ):\n",
    "        try:\n",
    "            request_data = {\n",
    "                \"postProcessMaxSize\": 100,\n",
    "                \"alpha\": 1.5,\n",
    "                \"segCnt\": -1,\n",
    "                \"postProcessMinSize\": 0,\n",
    "                \"text\": htmldata.page_content,\n",
    "                \"postProcess\": False\n",
    "            }\n",
    "\n",
    "            request_json_string = json.dumps(request_data)\n",
    "            request_data = json.loads(request_json_string, strict=False)\n",
    "            print(1)\n",
    "            response_data = segmentation_executor.execute(request_data)\n",
    "        except Exception as e:\n",
    "            print(f\"Error occurred. Message: {e}\")\n",
    "        \n",
    "        for paragraph in response_data:\n",
    "            chunked_document = {\n",
    "                \"source\": htmldata.metadata[\"source\"],\n",
    "                \"text\": paragraph\n",
    "            }\n",
    "            chunked_html.append(chunked_document)\n",
    " \n",
    "print(len(chunked_html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1486"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chunked_html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'source': 'https://wikidocs.net/233341',\n",
       "  'text': ['<랭체인LangChain 노트> - LangChain 한국어 튜토리얼🇰🇷 CH01 LangChain 시작하기']},\n",
       " {'source': 'https://wikidocs.net/233341',\n",
       "  'text': ['01. OpenAI API 키 발급 및 테스트']},\n",
       " {'source': 'https://wikidocs.net/233341', 'text': ['02. LangSmith 추적 설정']},\n",
       " {'source': 'https://wikidocs.net/233341',\n",
       "  'text': ['03. OpenAI API 사용(GPT-4o 멀티모달)']},\n",
       " {'source': 'https://wikidocs.net/233341',\n",
       "  'text': ['04. LangChain Expression Language(LCEL)']},\n",
       " {'source': 'https://wikidocs.net/233341', 'text': ['05. LCEL 인터페이스']},\n",
       " {'source': 'https://wikidocs.net/233341',\n",
       "  'text': ['06. Runnable CH02 프롬프트(Prompt)']},\n",
       " {'source': 'https://wikidocs.net/233341', 'text': ['01. 프롬프트(Prompt)']},\n",
       " {'source': 'https://wikidocs.net/233341',\n",
       "  'text': ['02. 퓨샷 프롬프트(FewShotPromptTemplate)']},\n",
       " {'source': 'https://wikidocs.net/233341', 'text': ['03. LangChain Hub']},\n",
       " {'source': 'https://wikidocs.net/233341',\n",
       "  'text': ['04. 개인화된 프롬프트(Hub에 업로드) CH03 출력 파서(Output Parsers)']},\n",
       " {'source': 'https://wikidocs.net/233341',\n",
       "  'text': ['01. Pydantic 출력 파서(PydanticOutputParser)']},\n",
       " {'source': 'https://wikidocs.net/233341',\n",
       "  'text': ['02. 콤마 구분자 출력 파서(CommaSeparatedListOutputParser)']},\n",
       " {'source': 'https://wikidocs.net/233341',\n",
       "  'text': ['03. 구조화된 출력 파서(StructuredOuputParser)']},\n",
       " {'source': 'https://wikidocs.net/233341',\n",
       "  'text': ['04. JSON 출력 파서(JsonOutputParser)']},\n",
       " {'source': 'https://wikidocs.net/233341',\n",
       "  'text': ['05. 데이터프레임 출력 파서(PandasDataFrameOutputParser)']},\n",
       " {'source': 'https://wikidocs.net/233341',\n",
       "  'text': ['06. 날짜 형식 출력 파서(DatetimeOutputParser)']},\n",
       " {'source': 'https://wikidocs.net/233341',\n",
       "  'text': ['07. 열거형 출력 파서(EnumOutputParser)']},\n",
       " {'source': 'https://wikidocs.net/233341',\n",
       "  'text': ['08. 출력 수정 파서(OutputFixingParser) CH04 모델(Model)']},\n",
       " {'source': 'https://wikidocs.net/233341', 'text': ['01. 다양한 LLM 모델 활용']},\n",
       " {'source': 'https://wikidocs.net/233341', 'text': ['02. 캐싱(Cache)']},\n",
       " {'source': 'https://wikidocs.net/233341',\n",
       "  'text': ['03. 모델 직렬화(Serialization) - 저장 및 불러오기']},\n",
       " {'source': 'https://wikidocs.net/233341', 'text': ['04. 토큰 사용량 확인']},\n",
       " {'source': 'https://wikidocs.net/233341',\n",
       "  'text': ['05. 구글 생성 AI(Google Generative AI)']},\n",
       " {'source': 'https://wikidocs.net/233341',\n",
       "  'text': ['06. 허깅페이스 엔드포인트(HuggingFace Endpoints)']},\n",
       " {'source': 'https://wikidocs.net/233341',\n",
       "  'text': ['07. 허깅페이스 로컬(HuggingFace Local)']},\n",
       " {'source': 'https://wikidocs.net/233341',\n",
       "  'text': ['08. 허깅페이스 파이프라인(HuggingFace Pipeline)']},\n",
       " {'source': 'https://wikidocs.net/233341', 'text': ['09. 올라마(Ollama)']},\n",
       " {'source': 'https://wikidocs.net/233341',\n",
       "  'text': ['10. GPT4ALL CH05 메모리(Memory)']},\n",
       " {'source': 'https://wikidocs.net/233341',\n",
       "  'text': ['01. 대화 버퍼 메모리(ConversationBufferMemory)']},\n",
       " {'source': 'https://wikidocs.net/233341',\n",
       "  'text': ['02. 대화 버퍼 윈도우 메모리(ConversationBufferWindowMemory)']},\n",
       " {'source': 'https://wikidocs.net/233341',\n",
       "  'text': ['03. 대화 토큰 버퍼 메모리(ConversationTokenBufferMemory)']},\n",
       " {'source': 'https://wikidocs.net/233341',\n",
       "  'text': ['04. 대화 엔티티 메모리(ConversationEntityMemory)']},\n",
       " {'source': 'https://wikidocs.net/233341',\n",
       "  'text': ['05. 대화 지식그래프 메모리(ConversationKGMemory)']},\n",
       " {'source': 'https://wikidocs.net/233341',\n",
       "  'text': ['06. 대화 요약 메모리(ConversationSummaryMemory)']},\n",
       " {'source': 'https://wikidocs.net/233341',\n",
       "  'text': ['07. 벡터저장소 검색 메모리(VectorStoreRetrieverMemory)']},\n",
       " {'source': 'https://wikidocs.net/233341',\n",
       "  'text': ['08. LCEL Chain 에 메모리 추가', '09. SQLite 에 대화내용 저장']},\n",
       " {'source': 'https://wikidocs.net/233341',\n",
       "  'text': ['10. RunnableWithMessageHistory에 ChatMessageHistory추가 CH06 문서 로더(Document Loader)']},\n",
       " {'source': 'https://wikidocs.net/233341',\n",
       "  'text': ['01. 도큐먼트(Document) 의 구조']},\n",
       " {'source': 'https://wikidocs.net/233341', 'text': ['02. PDF']},\n",
       " {'source': 'https://wikidocs.net/233341', 'text': ['03. 한글(HWP)']},\n",
       " {'source': 'https://wikidocs.net/233341', 'text': ['04. CSV']},\n",
       " {'source': 'https://wikidocs.net/233341', 'text': ['05. Excel']},\n",
       " {'source': 'https://wikidocs.net/233341', 'text': ['06. Word']},\n",
       " {'source': 'https://wikidocs.net/233341', 'text': ['07. PowerPoint']},\n",
       " {'source': 'https://wikidocs.net/233341',\n",
       "  'text': ['08. 웹 문서(WebBaseLoader)']},\n",
       " {'source': 'https://wikidocs.net/233341', 'text': ['09. 텍스트(TextLoader)']},\n",
       " {'source': 'https://wikidocs.net/233341', 'text': ['10. JSON']},\n",
       " {'source': 'https://wikidocs.net/233341', 'text': ['11. Arxiv']},\n",
       " {'source': 'https://wikidocs.net/233341',\n",
       "  'text': ['13. UpstageLayoutAnalysisLoader']},\n",
       " {'source': 'https://wikidocs.net/233341',\n",
       "  'text': ['14. LlamaParser CH07 텍스트 분할(Text Splitter)']},\n",
       " {'source': 'https://wikidocs.net/233341',\n",
       "  'text': ['01. 문자 텍스트 분할(CharacterTextSplitter)']},\n",
       " {'source': 'https://wikidocs.net/233341',\n",
       "  'text': ['02. 재귀적 문자 텍스트 분할(RecursiveCharacterTextSplitter)']},\n",
       " {'source': 'https://wikidocs.net/233341',\n",
       "  'text': ['03. 토큰 텍스트 분할(TokenTextSplitter)']},\n",
       " {'source': 'https://wikidocs.net/233341',\n",
       "  'text': ['04. 시멘틱 청커(SemanticChunker)']},\n",
       " {'source': 'https://wikidocs.net/233341',\n",
       "  'text': ['05. 코드 분할(Python, Markdown, JAVA, C++, C#, GO, JS, Latex 등)']},\n",
       " {'source': 'https://wikidocs.net/233341',\n",
       "  'text': ['06. 마크다운 헤더 텍스트 분할(MarkdownHeaderTextSplitter)']},\n",
       " {'source': 'https://wikidocs.net/233341',\n",
       "  'text': ['07. HTML 헤더 텍스트 분할(HTMLHeaderTextSplitter)']},\n",
       " {'source': 'https://wikidocs.net/233341',\n",
       "  'text': ['08. 재귀적 JSON 분할(RecursiveJsonSplitter) CH08 임베딩(Embedding)']},\n",
       " {'source': 'https://wikidocs.net/233341', 'text': ['01. OpenAIEmbeddings']},\n",
       " {'source': 'https://wikidocs.net/233341',\n",
       "  'text': ['02. 캐시 임베딩(CacheBackedEmbeddings)']},\n",
       " {'source': 'https://wikidocs.net/233341',\n",
       "  'text': ['03. 허깅페이스 임베딩(HuggingFace Embeddings)']},\n",
       " {'source': 'https://wikidocs.net/233341', 'text': ['04. UpstageEmbeddings']},\n",
       " {'source': 'https://wikidocs.net/233341', 'text': ['05. OllamaEmbeddings']},\n",
       " {'source': 'https://wikidocs.net/233341', 'text': ['06. GPT4ALL 임베딩']},\n",
       " {'source': 'https://wikidocs.net/233341',\n",
       "  'text': ['07. Llama CPP 임베딩 CH09 벡터저장소(VectorStore)']},\n",
       " {'source': 'https://wikidocs.net/233341', 'text': ['01. Chroma']},\n",
       " {'source': 'https://wikidocs.net/233341', 'text': ['02. FAISS']},\n",
       " {'source': 'https://wikidocs.net/233341',\n",
       "  'text': ['03. Pinecone CH10 검색기(Retriever)']},\n",
       " {'source': 'https://wikidocs.net/233341',\n",
       "  'text': ['01. 벡터저장소 지원 검색기(VectorStore-backed Retriever)']},\n",
       " {'source': 'https://wikidocs.net/233341',\n",
       "  'text': ['02. 문맥 압축 검색기(ContextualCompressionRetriever)']},\n",
       " {'source': 'https://wikidocs.net/233341',\n",
       "  'text': ['03. 앙상블 검색기(EnsembleRetriever)']},\n",
       " {'source': 'https://wikidocs.net/233341',\n",
       "  'text': ['04. 긴 문맥 재정렬(LongContextReorder)']},\n",
       " {'source': 'https://wikidocs.net/233341',\n",
       "  'text': ['05. 상위 문서 검색기(ParentDocumentRetriever)']},\n",
       " {'source': 'https://wikidocs.net/233341',\n",
       "  'text': ['06. 다중 쿼리 검색기(MultiQueryRetriever)']},\n",
       " {'source': 'https://wikidocs.net/233341',\n",
       "  'text': ['07. 다중 벡터저장소 검색기(MultiVectorRetriever)']},\n",
       " {'source': 'https://wikidocs.net/233341',\n",
       "  'text': ['08. 셀프 쿼리 검색기(SelfQueryRetriever)']},\n",
       " {'source': 'https://wikidocs.net/233341',\n",
       "  'text': ['09. 시간 가중 벡터저장소 검색기(TimeWeightedVectorStoreRetriever)']},\n",
       " {'source': 'https://wikidocs.net/233341',\n",
       "  'text': ['10. 한글 형태소 분석기(Kiwi, Kkma, Okt) + BM25 검색기 CH11 리랭커(Reranker)']},\n",
       " {'source': 'https://wikidocs.net/233341',\n",
       "  'text': ['01. Cross Encoder Reranker']},\n",
       " {'source': 'https://wikidocs.net/233341', 'text': ['02. Cohere Reranker']},\n",
       " {'source': 'https://wikidocs.net/233341', 'text': ['03. Jina Reranker']},\n",
       " {'source': 'https://wikidocs.net/233341',\n",
       "  'text': ['04. FlashRank Reranker CH12 Retrieval Augmented Generation(RAG)']},\n",
       " {'source': 'https://wikidocs.net/233341',\n",
       "  'text': ['01. PDF 문서 기반 QA(Question-Answer)']},\n",
       " {'source': 'https://wikidocs.net/233341',\n",
       "  'text': ['02. 네이버 뉴스기사 QA(Question-Answer)']},\n",
       " {'source': 'https://wikidocs.net/233341',\n",
       "  'text': ['03. RAG 의 기능별 다양한 모듈 활용기']},\n",
       " {'source': 'https://wikidocs.net/233341',\n",
       "  'text': ['04. RAPTOR: 긴 문맥 요약(Long Context Summary)']},\n",
       " {'source': 'https://wikidocs.net/233341',\n",
       "  'text': ['05. 대화내용을 기억하는 RAG 체인 CH13 LangChain Expression Language(LCEL)']},\n",
       " {'source': 'https://wikidocs.net/233341',\n",
       "  'text': ['01. RunnablePassthrough: 데이터 전달']},\n",
       " {'source': 'https://wikidocs.net/233341',\n",
       "  'text': ['02. Runnable 구조(그래프) 확인']},\n",
       " {'source': 'https://wikidocs.net/233341',\n",
       "  'text': ['03. RunnableLambda: 사용자 정의 함수']},\n",
       " {'source': 'https://wikidocs.net/233341',\n",
       "  'text': ['04. RunnableBranch: 라우팅(Routing)']},\n",
       " {'source': 'https://wikidocs.net/233341',\n",
       "  'text': ['05. RunnableParallel: 병렬 처리']},\n",
       " {'source': 'https://wikidocs.net/233341',\n",
       "  'text': ['06. configurable_fields, configurable_alternatives 07. @chain 데코레이터로 Runnable 생성',\n",
       "   '08. RunnableWithMessageHistory']},\n",
       " {'source': 'https://wikidocs.net/233341',\n",
       "  'text': ['09. 사용자 정의 제네레이터(generator)']},\n",
       " {'source': 'https://wikidocs.net/233341',\n",
       "  'text': ['10. Runtime Arguments 바인딩']},\n",
       " {'source': 'https://wikidocs.net/233341',\n",
       "  'text': ['11. 폴백(fallback) 모델 지정 CH14 체인(Chains)']},\n",
       " {'source': 'https://wikidocs.net/233341', 'text': ['01. 문서 요약']},\n",
       " {'source': 'https://wikidocs.net/233341',\n",
       "  'text': ['02. SQL CH15 에이전트(Agent)']},\n",
       " {'source': 'https://wikidocs.net/233341', 'text': ['01. Agent 사용법 톺아보기']},\n",
       " {'source': 'https://wikidocs.net/233341',\n",
       "  'text': ['02. 도구를 활용한 토론 에이전트(Two Agent Debates with Tools) CH16 파인튜닝(Fine Tuning)']},\n",
       " {'source': 'https://wikidocs.net/233341', 'text': ['CH17 LangGraph']},\n",
       " {'source': 'https://wikidocs.net/233341',\n",
       "  'text': ['01. Chain of Table for Multiple Tables']},\n",
       " {'source': 'https://wikidocs.net/233341',\n",
       "  'text': ['Published with WikiDocs']},\n",
       " {'source': 'https://wikidocs.net/233341',\n",
       "  'text': ['<랭체인LangChain 노트> - Lang…']},\n",
       " {'source': 'https://wikidocs.net/233341',\n",
       "  'text': ['CH01 LangChain 시작하기', '위키독스']},\n",
       " {'source': 'https://wikidocs.net/233341', 'text': ['CH01 LangChain 시작하기']},\n",
       " {'source': 'https://wikidocs.net/233341', 'text': ['🦜️🔗 랭체인 LangChain']},\n",
       " {'source': 'https://wikidocs.net/233341',\n",
       "  'text': ['LangChain 은 언어 모델을 활용해 다양한 애플리케이션을 개발할 수 있는 프레임워크를 말합니다.',\n",
       "   '이 프레임워크를 통해 언어 모델은 다음과 같은 기능을 수행할 수 있게 됩니다.']},\n",
       " {'source': 'https://wikidocs.net/233341',\n",
       "  'text': ['문맥을 인식하는 기능: LangChain은 언어 모델을 다양한 문맥 소스와 연결합니다.',\n",
       "   '여기에는 프롬프트 지시사항, 소수의 예시, 응답에 근거한 내용 등이 포함됩니다.',\n",
       "   '이를 통해 언어 모델은 제공된 정보를 기반으로 더 정확하고 관련성 높은 답변을 생성할 수 있습니다.',\n",
       "   '추론하는 기능: 또한, 언어 모델은 주어진 문맥을 바탕으로 어떠한 답변을 제공하거나, 어떤 조치를 취해야 할지를 스스로 추론할 수 있습니다.',\n",
       "   '이는 언어 모델이 단순히 정보를 재생산하는 것을 넘어서, 주어진 상황을 분석하고 적절한 해결책을 제시할 수 있음을 의미합니다.',\n",
       "   'LangChain 을 활용하면 이전에 언급한 기능을 바탕으로 검색 증강 생성(RAG) 어플리케이션 제작, 구조화된 데이터 분석, 챗봇 등을 만들 수 있습니다.']},\n",
       " {'source': 'https://wikidocs.net/233341',\n",
       "  'text': ['더 많은 예제는 유튜브 채널 테디노트 에서 확인하실 수 있습니다.']},\n",
       " {'source': 'https://wikidocs.net/233341', 'text': ['설치']},\n",
       " {'source': 'https://wikidocs.net/233341',\n",
       "  'text': ['권장하는 파이썬 버전은 3.11 버전입니다.']},\n",
       " {'source': 'https://wikidocs.net/233341',\n",
       "  'text': ['pip 를 이용한 설치',\n",
       "   'pip install -r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt']},\n",
       " {'source': 'https://wikidocs.net/233341',\n",
       "  'text': ['최소한의 기능만 설치하기 위한 mini 버전 (일부 패키지만 설치하는 경우)']},\n",
       " {'source': 'https://wikidocs.net/233341',\n",
       "  'text': ['pip install -r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements-mini.txt']},\n",
       " {'source': 'https://wikidocs.net/233341', 'text': ['구성']},\n",
       " {'source': 'https://wikidocs.net/233341',\n",
       "  'text': ['이 프레임워크는 여러 부분으로 구성되어 있습니다.']},\n",
       " {'source': 'https://wikidocs.net/233341',\n",
       "  'text': ['LangChain 라이브러리: Python 및 JavaScript 라이브러리.']},\n",
       " {'source': 'https://wikidocs.net/233341',\n",
       "  'text': ['다양한 컴포넌트의 인터페이스와 통합, 이러한 컴포넌트를 체인과 에이전트로 결합하는 기본 런타임, 그리고 즉시 사용 가능한 체인과 에이전트의 구현을 포함합니다.']},\n",
       " {'source': 'https://wikidocs.net/233341',\n",
       "  'text': ['LangChain 템플릿: 다양한 작업을 위한 쉽게 배포할 수 있는 참조 아키텍처 모음입니다.']},\n",
       " {'source': 'https://wikidocs.net/233341',\n",
       "  'text': ['LangServe: LangChain 체인을 REST API로 배포하기 위한 라이브러리입니다.']},\n",
       " {'source': 'https://wikidocs.net/233341',\n",
       "  'text': ['LangSmith: 어떤 LLM 프레임워크에도 구축된 체인을 디버그, 테스트, 평가, 모니터링할 수 있게 해주며 LangChain과 원활하게 통합되는 개발자 플랫폼입니다.']},\n",
       " {'source': 'https://wikidocs.net/233341',\n",
       "  'text': ['LangGraph: LLM을 사용한 상태유지가 가능한 다중 액터 애플리케이션을 구축하기 위한 라이브러리로, LangChain 위에 구축되었으며 LangChain과 함께 사용하도록 설계되었습니다.',\n",
       "   '여러 계산 단계에서 다중 체인(또는 액터)을 순환 방식으로 조정할 수 있는 능력을 LangChain 표현 언어에 추가합니다.']},\n",
       " {'source': 'https://wikidocs.net/233341', 'text': ['개발 용이성✨']},\n",
       " {'source': 'https://wikidocs.net/233341',\n",
       "  'text': ['컴포넌트의 조립 및 통합 🔧',\n",
       "   'LangChain은 언어 모델과의 작업을 위한 조립 가능한 도구 및 통합을 제공합니다.',\n",
       "   '컴포넌트는 모듈식으로 설계되어, 사용하기 쉽습니다.',\n",
       "   '이는 개발자가 LangChain 프레임워크를 자유롭게 활용할 수 있게 해줍니다.',\n",
       "   '즉시 사용 가능한 체인 🚀',\n",
       "   '고수준 작업을 수행하기 위한 컴포넌트의 내장 조합을 제공합니다.',\n",
       "   '이러한 체인은 개발 과정을 간소화하고 속도를 높여줍니다.']},\n",
       " {'source': 'https://wikidocs.net/233341',\n",
       "  'text': ['주요 모듈 📌',\n",
       "   '모델 I/O 📃',\n",
       "   '프롬프트 관리, 최적화 및 LLM과의 일반적인 인터페이스와 작업을 위한 유틸리티를 포함합니다.']},\n",
       " {'source': 'https://wikidocs.net/233341', 'text': ['검색 📚']},\n",
       " {'source': 'https://wikidocs.net/233341',\n",
       "  'text': [\"'데이터 강화 생성'에 초점을 맞춘 이 모듈은 생성 단계에서 필요한 데이터를 외부 데이터 소스에서 가져오는 작업을 담당합니다.\"]},\n",
       " {'source': 'https://wikidocs.net/233341', 'text': ['에이전트 🤖']},\n",
       " {'source': 'https://wikidocs.net/233341',\n",
       "  'text': ['언어 모델이 어떤 조치를 취할지 결정하고, 해당 조치를 실행하며, 관찰하고, 필요한 경우 반복하는 과정을 포함합니다.']},\n",
       " {'source': 'https://wikidocs.net/233341',\n",
       "  'text': ['LangChain을 활용하면, 언어 모델 기반 애플리케이션의 개발을 보다 쉽게 시작할 수 있으며, 필요에 맞게 기능을 맞춤 설정하고, 다양한 데이터 소스와 통합하여 복잡한 작업을 처리할 수 있게 됩니다.']},\n",
       " {'source': 'https://wikidocs.net/233341',\n",
       "  'text': ['마지막 편집일시 : 2024년 7월 16일 2:40 오전']},\n",
       " {'source': 'https://wikidocs.net/233341',\n",
       "  'text': ['댓글 0 피드백', '※ 댓글 작성은 로그인이 필요합니다.', '(또는 피드백을 이용해 주세요.)']},\n",
       " {'source': 'https://wikidocs.net/233341',\n",
       "  'text': ['이전글 : <랭체인LangChain 노트> - LangChain 한국어 튜토리얼🇰🇷']},\n",
       " {'source': 'https://wikidocs.net/233341', 'text': ['다음글 : 01.']},\n",
       " {'source': 'https://wikidocs.net/233341', 'text': ['OpenAI API 키 발급 및 테스트']},\n",
       " {'source': 'https://wikidocs.net/233341', 'text': ['책갈피']},\n",
       " {'source': 'https://wikidocs.net/233341', 'text': ['이 페이지에 대한 피드백을 남겨주세요']},\n",
       " {'source': 'https://wikidocs.net/233341', 'text': ['댓글을 신고합니다.']},\n",
       " {'source': 'https://wikidocs.net/233346',\n",
       "  'text': ['<랭체인LangChain 노트> - LangChain 한국어 튜토리얼🇰🇷 CH01 LangChain 시작하기']},\n",
       " {'source': 'https://wikidocs.net/233346',\n",
       "  'text': ['01. OpenAI API 키 발급 및 테스트']},\n",
       " {'source': 'https://wikidocs.net/233346', 'text': ['02. LangSmith 추적 설정']},\n",
       " {'source': 'https://wikidocs.net/233346',\n",
       "  'text': ['03. OpenAI API 사용(GPT-4o 멀티모달)']},\n",
       " {'source': 'https://wikidocs.net/233346',\n",
       "  'text': ['04. LangChain Expression Language(LCEL)']},\n",
       " {'source': 'https://wikidocs.net/233346', 'text': ['05. LCEL 인터페이스']},\n",
       " {'source': 'https://wikidocs.net/233346',\n",
       "  'text': ['06. Runnable CH02 프롬프트(Prompt)']},\n",
       " {'source': 'https://wikidocs.net/233346', 'text': ['01. 프롬프트(Prompt)']},\n",
       " {'source': 'https://wikidocs.net/233346',\n",
       "  'text': ['02. 퓨샷 프롬프트(FewShotPromptTemplate)']},\n",
       " {'source': 'https://wikidocs.net/233346', 'text': ['03. LangChain Hub']},\n",
       " {'source': 'https://wikidocs.net/233346',\n",
       "  'text': ['04. 개인화된 프롬프트(Hub에 업로드) CH03 출력 파서(Output Parsers)']},\n",
       " {'source': 'https://wikidocs.net/233346',\n",
       "  'text': ['01. Pydantic 출력 파서(PydanticOutputParser)']},\n",
       " {'source': 'https://wikidocs.net/233346',\n",
       "  'text': ['02. 콤마 구분자 출력 파서(CommaSeparatedListOutputParser)']},\n",
       " {'source': 'https://wikidocs.net/233346',\n",
       "  'text': ['03. 구조화된 출력 파서(StructuredOuputParser)']},\n",
       " {'source': 'https://wikidocs.net/233346',\n",
       "  'text': ['04. JSON 출력 파서(JsonOutputParser)']},\n",
       " {'source': 'https://wikidocs.net/233346',\n",
       "  'text': ['05. 데이터프레임 출력 파서(PandasDataFrameOutputParser)']},\n",
       " {'source': 'https://wikidocs.net/233346',\n",
       "  'text': ['06. 날짜 형식 출력 파서(DatetimeOutputParser)']},\n",
       " {'source': 'https://wikidocs.net/233346',\n",
       "  'text': ['07. 열거형 출력 파서(EnumOutputParser)']},\n",
       " {'source': 'https://wikidocs.net/233346',\n",
       "  'text': ['08. 출력 수정 파서(OutputFixingParser) CH04 모델(Model)']},\n",
       " {'source': 'https://wikidocs.net/233346', 'text': ['01. 다양한 LLM 모델 활용']},\n",
       " {'source': 'https://wikidocs.net/233346', 'text': ['02. 캐싱(Cache)']},\n",
       " {'source': 'https://wikidocs.net/233346',\n",
       "  'text': ['03. 모델 직렬화(Serialization) - 저장 및 불러오기']},\n",
       " {'source': 'https://wikidocs.net/233346', 'text': ['04. 토큰 사용량 확인']},\n",
       " {'source': 'https://wikidocs.net/233346',\n",
       "  'text': ['05. 구글 생성 AI(Google Generative AI)']},\n",
       " {'source': 'https://wikidocs.net/233346',\n",
       "  'text': ['06. 허깅페이스 엔드포인트(HuggingFace Endpoints)']},\n",
       " {'source': 'https://wikidocs.net/233346',\n",
       "  'text': ['07. 허깅페이스 로컬(HuggingFace Local)']},\n",
       " {'source': 'https://wikidocs.net/233346',\n",
       "  'text': ['08. 허깅페이스 파이프라인(HuggingFace Pipeline)']},\n",
       " {'source': 'https://wikidocs.net/233346', 'text': ['09. 올라마(Ollama)']},\n",
       " {'source': 'https://wikidocs.net/233346',\n",
       "  'text': ['10. GPT4ALL CH05 메모리(Memory)']},\n",
       " {'source': 'https://wikidocs.net/233346',\n",
       "  'text': ['01. 대화 버퍼 메모리(ConversationBufferMemory)']},\n",
       " {'source': 'https://wikidocs.net/233346',\n",
       "  'text': ['02. 대화 버퍼 윈도우 메모리(ConversationBufferWindowMemory)']},\n",
       " {'source': 'https://wikidocs.net/233346',\n",
       "  'text': ['03. 대화 토큰 버퍼 메모리(ConversationTokenBufferMemory)']},\n",
       " {'source': 'https://wikidocs.net/233346',\n",
       "  'text': ['04. 대화 엔티티 메모리(ConversationEntityMemory)']},\n",
       " {'source': 'https://wikidocs.net/233346',\n",
       "  'text': ['05. 대화 지식그래프 메모리(ConversationKGMemory)']},\n",
       " {'source': 'https://wikidocs.net/233346',\n",
       "  'text': ['06. 대화 요약 메모리(ConversationSummaryMemory)']},\n",
       " {'source': 'https://wikidocs.net/233346',\n",
       "  'text': ['07. 벡터저장소 검색 메모리(VectorStoreRetrieverMemory)']},\n",
       " {'source': 'https://wikidocs.net/233346',\n",
       "  'text': ['08. LCEL Chain 에 메모리 추가', '09. SQLite 에 대화내용 저장']},\n",
       " {'source': 'https://wikidocs.net/233346',\n",
       "  'text': ['10. RunnableWithMessageHistory에 ChatMessageHistory추가 CH06 문서 로더(Document Loader)']},\n",
       " {'source': 'https://wikidocs.net/233346',\n",
       "  'text': ['01. 도큐먼트(Document) 의 구조']},\n",
       " {'source': 'https://wikidocs.net/233346', 'text': ['02. PDF']},\n",
       " {'source': 'https://wikidocs.net/233346', 'text': ['03. 한글(HWP)']},\n",
       " {'source': 'https://wikidocs.net/233346', 'text': ['04. CSV']},\n",
       " {'source': 'https://wikidocs.net/233346', 'text': ['05. Excel']},\n",
       " {'source': 'https://wikidocs.net/233346', 'text': ['06. Word']},\n",
       " {'source': 'https://wikidocs.net/233346', 'text': ['07. PowerPoint']},\n",
       " {'source': 'https://wikidocs.net/233346',\n",
       "  'text': ['08. 웹 문서(WebBaseLoader)']},\n",
       " {'source': 'https://wikidocs.net/233346', 'text': ['09. 텍스트(TextLoader)']},\n",
       " {'source': 'https://wikidocs.net/233346', 'text': ['10. JSON']},\n",
       " {'source': 'https://wikidocs.net/233346', 'text': ['11. Arxiv']},\n",
       " {'source': 'https://wikidocs.net/233346',\n",
       "  'text': ['13. UpstageLayoutAnalysisLoader']},\n",
       " {'source': 'https://wikidocs.net/233346',\n",
       "  'text': ['14. LlamaParser CH07 텍스트 분할(Text Splitter)']},\n",
       " {'source': 'https://wikidocs.net/233346',\n",
       "  'text': ['01. 문자 텍스트 분할(CharacterTextSplitter)']},\n",
       " {'source': 'https://wikidocs.net/233346',\n",
       "  'text': ['02. 재귀적 문자 텍스트 분할(RecursiveCharacterTextSplitter)']},\n",
       " {'source': 'https://wikidocs.net/233346',\n",
       "  'text': ['03. 토큰 텍스트 분할(TokenTextSplitter)']},\n",
       " {'source': 'https://wikidocs.net/233346',\n",
       "  'text': ['04. 시멘틱 청커(SemanticChunker)']},\n",
       " {'source': 'https://wikidocs.net/233346',\n",
       "  'text': ['05. 코드 분할(Python, Markdown, JAVA, C++, C#, GO, JS, Latex 등)']},\n",
       " {'source': 'https://wikidocs.net/233346',\n",
       "  'text': ['06. 마크다운 헤더 텍스트 분할(MarkdownHeaderTextSplitter)']},\n",
       " {'source': 'https://wikidocs.net/233346',\n",
       "  'text': ['07. HTML 헤더 텍스트 분할(HTMLHeaderTextSplitter)']},\n",
       " {'source': 'https://wikidocs.net/233346',\n",
       "  'text': ['08. 재귀적 JSON 분할(RecursiveJsonSplitter) CH08 임베딩(Embedding)']},\n",
       " {'source': 'https://wikidocs.net/233346', 'text': ['01. OpenAIEmbeddings']},\n",
       " {'source': 'https://wikidocs.net/233346',\n",
       "  'text': ['02. 캐시 임베딩(CacheBackedEmbeddings)']},\n",
       " {'source': 'https://wikidocs.net/233346',\n",
       "  'text': ['03. 허깅페이스 임베딩(HuggingFace Embeddings)']},\n",
       " {'source': 'https://wikidocs.net/233346', 'text': ['04. UpstageEmbeddings']},\n",
       " {'source': 'https://wikidocs.net/233346', 'text': ['05. OllamaEmbeddings']},\n",
       " {'source': 'https://wikidocs.net/233346', 'text': ['06. GPT4ALL 임베딩']},\n",
       " {'source': 'https://wikidocs.net/233346',\n",
       "  'text': ['07. Llama CPP 임베딩 CH09 벡터저장소(VectorStore)']},\n",
       " {'source': 'https://wikidocs.net/233346', 'text': ['01. Chroma']},\n",
       " {'source': 'https://wikidocs.net/233346', 'text': ['02. FAISS']},\n",
       " {'source': 'https://wikidocs.net/233346',\n",
       "  'text': ['03. Pinecone CH10 검색기(Retriever)']},\n",
       " {'source': 'https://wikidocs.net/233346',\n",
       "  'text': ['01. 벡터저장소 지원 검색기(VectorStore-backed Retriever)']},\n",
       " {'source': 'https://wikidocs.net/233346',\n",
       "  'text': ['02. 문맥 압축 검색기(ContextualCompressionRetriever)']},\n",
       " {'source': 'https://wikidocs.net/233346',\n",
       "  'text': ['03. 앙상블 검색기(EnsembleRetriever)']},\n",
       " {'source': 'https://wikidocs.net/233346',\n",
       "  'text': ['04. 긴 문맥 재정렬(LongContextReorder)']},\n",
       " {'source': 'https://wikidocs.net/233346',\n",
       "  'text': ['05. 상위 문서 검색기(ParentDocumentRetriever)']},\n",
       " {'source': 'https://wikidocs.net/233346',\n",
       "  'text': ['06. 다중 쿼리 검색기(MultiQueryRetriever)']},\n",
       " {'source': 'https://wikidocs.net/233346',\n",
       "  'text': ['07. 다중 벡터저장소 검색기(MultiVectorRetriever)']},\n",
       " {'source': 'https://wikidocs.net/233346',\n",
       "  'text': ['08. 셀프 쿼리 검색기(SelfQueryRetriever)']},\n",
       " {'source': 'https://wikidocs.net/233346',\n",
       "  'text': ['09. 시간 가중 벡터저장소 검색기(TimeWeightedVectorStoreRetriever)']},\n",
       " {'source': 'https://wikidocs.net/233346',\n",
       "  'text': ['10. 한글 형태소 분석기(Kiwi, Kkma, Okt) + BM25 검색기 CH11 리랭커(Reranker)']},\n",
       " {'source': 'https://wikidocs.net/233346',\n",
       "  'text': ['01. Cross Encoder Reranker']},\n",
       " {'source': 'https://wikidocs.net/233346', 'text': ['02. Cohere Reranker']},\n",
       " {'source': 'https://wikidocs.net/233346', 'text': ['03. Jina Reranker']},\n",
       " {'source': 'https://wikidocs.net/233346',\n",
       "  'text': ['04. FlashRank Reranker CH12 Retrieval Augmented Generation(RAG)']},\n",
       " {'source': 'https://wikidocs.net/233346',\n",
       "  'text': ['01. PDF 문서 기반 QA(Question-Answer)']},\n",
       " {'source': 'https://wikidocs.net/233346',\n",
       "  'text': ['02. 네이버 뉴스기사 QA(Question-Answer)']},\n",
       " {'source': 'https://wikidocs.net/233346',\n",
       "  'text': ['03. RAG 의 기능별 다양한 모듈 활용기']},\n",
       " {'source': 'https://wikidocs.net/233346',\n",
       "  'text': ['04. RAPTOR: 긴 문맥 요약(Long Context Summary)']},\n",
       " {'source': 'https://wikidocs.net/233346',\n",
       "  'text': ['05. 대화내용을 기억하는 RAG 체인 CH13 LangChain Expression Language(LCEL)']},\n",
       " {'source': 'https://wikidocs.net/233346',\n",
       "  'text': ['01. RunnablePassthrough: 데이터 전달']},\n",
       " {'source': 'https://wikidocs.net/233346',\n",
       "  'text': ['02. Runnable 구조(그래프) 확인']},\n",
       " {'source': 'https://wikidocs.net/233346',\n",
       "  'text': ['03. RunnableLambda: 사용자 정의 함수']},\n",
       " {'source': 'https://wikidocs.net/233346',\n",
       "  'text': ['04. RunnableBranch: 라우팅(Routing)']},\n",
       " {'source': 'https://wikidocs.net/233346',\n",
       "  'text': ['05. RunnableParallel: 병렬 처리']},\n",
       " {'source': 'https://wikidocs.net/233346',\n",
       "  'text': ['06. configurable_fields, configurable_alternatives 07. @chain 데코레이터로 Runnable 생성',\n",
       "   '08. RunnableWithMessageHistory']},\n",
       " {'source': 'https://wikidocs.net/233346',\n",
       "  'text': ['09. 사용자 정의 제네레이터(generator)']},\n",
       " {'source': 'https://wikidocs.net/233346',\n",
       "  'text': ['10. Runtime Arguments 바인딩']},\n",
       " {'source': 'https://wikidocs.net/233346',\n",
       "  'text': ['11. 폴백(fallback) 모델 지정 CH14 체인(Chains)']},\n",
       " {'source': 'https://wikidocs.net/233346', 'text': ['01. 문서 요약']},\n",
       " {'source': 'https://wikidocs.net/233346',\n",
       "  'text': ['02. SQL CH15 에이전트(Agent)']},\n",
       " {'source': 'https://wikidocs.net/233346', 'text': ['01. Agent 사용법 톺아보기']},\n",
       " {'source': 'https://wikidocs.net/233346',\n",
       "  'text': ['02. 도구를 활용한 토론 에이전트(Two Agent Debates with Tools) CH16 파인튜닝(Fine Tuning)']},\n",
       " {'source': 'https://wikidocs.net/233346', 'text': ['CH17 LangGraph']},\n",
       " {'source': 'https://wikidocs.net/233346',\n",
       "  'text': ['01. Chain of Table for Multiple Tables']},\n",
       " {'source': 'https://wikidocs.net/233346',\n",
       "  'text': ['Published with WikiDocs']},\n",
       " {'source': 'https://wikidocs.net/233346',\n",
       "  'text': ['<랭체인LangChain 노트> - Lang…']},\n",
       " {'source': 'https://wikidocs.net/233346', 'text': ['CH01 LangChain 시작하기']},\n",
       " {'source': 'https://wikidocs.net/233346', 'text': ['06. Runnable']},\n",
       " {'source': 'https://wikidocs.net/233346', 'text': ['위키독스']},\n",
       " {'source': 'https://wikidocs.net/233346', 'text': ['06. Runnable']},\n",
       " {'source': 'https://wikidocs.net/233346',\n",
       "  'text': ['# .env 파일을 읽어서 환경변수로 설정', 'from dotenv import load_dotenv']},\n",
       " {'source': 'https://wikidocs.net/233346', 'text': ['# 토큰 정보로드']},\n",
       " {'source': 'https://wikidocs.net/233346', 'text': ['load_dotenv()']},\n",
       " {'source': 'https://wikidocs.net/233346', 'text': ['True']},\n",
       " {'source': 'https://wikidocs.net/233346',\n",
       "  'text': ['# LangSmith 추적을 설정합니다.', 'https://smith.langchain.com']},\n",
       " {'source': 'https://wikidocs.net/233346',\n",
       "  'text': ['# !pip install -qU langchain-teddynote']},\n",
       " {'source': 'https://wikidocs.net/233346',\n",
       "  'text': ['from langchain_teddynote import logging',\n",
       "   '# 프로젝트 이름을 입력합니다.',\n",
       "   'logging.langsmith(\"CH01-Basic\")']},\n",
       " {'source': 'https://wikidocs.net/233346', 'text': ['LangSmith 추적을 시작합니다.']},\n",
       " {'source': 'https://wikidocs.net/233346', 'text': ['[프로젝트명]']},\n",
       " {'source': 'https://wikidocs.net/233346', 'text': ['CH01-Basic']},\n",
       " {'source': 'https://wikidocs.net/233346', 'text': ['데이터를 효과적으로 전달하는 방법']},\n",
       " {'source': 'https://wikidocs.net/233346',\n",
       "  'text': ['RunnablePassthrough 는 입력을 변경하지 않거나 추가 키를 더하여 전달할 수 있습니다.',\n",
       "   'RunnablePassthrough() 가 단독으로 호출되면, 단순히 입력을 받아 그대로 전달합니다.',\n",
       "   'RunnablePassthrough.assign(...)']},\n",
       " {'source': 'https://wikidocs.net/233346',\n",
       "  'text': ['방식으로 호출되면, 입력을 받아 assign 함수에 전달된 추가 인수를 추가합니다.']},\n",
       " {'source': 'https://wikidocs.net/233346', 'text': ['RunnablePassthrough']},\n",
       " {'source': 'https://wikidocs.net/233346',\n",
       "  'text': ['from langchain_core.prompts import PromptTemplate']},\n",
       " {'source': 'https://wikidocs.net/233346',\n",
       "  'text': ['from langchain_openai import ChatOpenAI']},\n",
       " {'source': 'https://wikidocs.net/233346',\n",
       "  'text': ['# prompt 와 llm 을 생성합니다.',\n",
       "   'prompt = PromptTemplate.from_template(\"{num} 의 10배는?\")',\n",
       "   'llm = ChatOpenAI(temperature=0)']},\n",
       " {'source': 'https://wikidocs.net/233346',\n",
       "  'text': ['# chain 을 생성합니다.',\n",
       "   'chain = prompt | llm',\n",
       "   'chain 을 invoke() 하여 실행할 때는 입력 데이터의 타입이 딕셔너리여야 합니다.']},\n",
       " {'source': 'https://wikidocs.net/233346',\n",
       "  'text': ['# chain 을 실행합니다.', 'chain.invoke({\"num\": 5})']},\n",
       " {'source': 'https://wikidocs.net/233346',\n",
       "  'text': [\"AIMessage(content='50입니다.', response_metadata={'token_usage': {'completion_tokens': 3, 'prompt_tokens': 16, 'total_tokens': 19}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-29242a8b-01c0-41ad-8f5b-7613e6876dc5-0', usage_metadata={'input_tokens': 16, 'output_tokens': 3, 'total_tokens': 19})\"]},\n",
       " {'source': 'https://wikidocs.net/233346',\n",
       "  'text': ['하지만, langchain 라이브러리가 업데이트 되면서 1개의 변수만 템플릿에 포함하고 있다면, 값만 전달하는 것도 가능합니다.']},\n",
       " {'source': 'https://wikidocs.net/233346', 'text': ['# chain 을 실행합니다.']},\n",
       " {'source': 'https://wikidocs.net/233346', 'text': ['chain.invoke(5)']},\n",
       " {'source': 'https://wikidocs.net/233346',\n",
       "  'text': [\"AIMessage(content='50', response_metadata={'token_usage': {'completion_tokens': 1, 'prompt_tokens': 16, 'total_tokens': 17}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-44f606db-2437-4d1f-9cee-ddfc69428745-0', usage_metadata={'input_tokens': 16, 'output_tokens': 1, 'total_tokens': 17})\"]},\n",
       " {'source': 'https://wikidocs.net/233346',\n",
       "  'text': ['아래는 RunnablePassthrough 를 사용한 예제입니다.']},\n",
       " {'source': 'https://wikidocs.net/233346',\n",
       "  'text': ['RunnablePassthrough 는 runnable 객체이며, runnable 객체는 invoke() 메소드를 사용하여 별도 실행이 가능합니다.']},\n",
       " {'source': 'https://wikidocs.net/233346',\n",
       "  'text': ['from langchain_core.runnables import RunnablePassthrough']},\n",
       " {'source': 'https://wikidocs.net/233346', 'text': ['# runnable']},\n",
       " {'source': 'https://wikidocs.net/233346',\n",
       "  'text': ['RunnablePassthrough().invoke({\"num\": 10})']},\n",
       " {'source': 'https://wikidocs.net/233346', 'text': [\"{'num': 10}\"]},\n",
       " {'source': 'https://wikidocs.net/233346',\n",
       "  'text': ['아래는 RunnablePassthrough 로 체인을 구성하는 예제입니다.',\n",
       "   'runnable_chain = {\"num\": RunnablePassthrough()} | prompt | ChatOpenAI()']},\n",
       " {'source': 'https://wikidocs.net/233346',\n",
       "  'text': ['# dict 값이 RunnablePassthrough() 로 변경되었습니다.']},\n",
       " {'source': 'https://wikidocs.net/233346',\n",
       "  'text': ['runnable_chain.invoke(10)']},\n",
       " {'source': 'https://wikidocs.net/233346',\n",
       "  'text': [\"AIMessage(content='100입니다.', response_metadata={'token_usage': {'completion_tokens': 3, 'prompt_tokens': 16, 'total_tokens': 19}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-66270ca2-4d62-4c71-859b-de6318f29909-0', usage_metadata={'input_tokens': 16, 'output_tokens': 3, 'total_tokens': 19})\"]},\n",
       " {'source': 'https://wikidocs.net/233346',\n",
       "  'text': ['다음은 RunnablePassthrough.assign() 을 사용하는 경우와 비교한 결과입니다.']},\n",
       " {'source': 'https://wikidocs.net/233346',\n",
       "  'text': ['RunnablePassthrough().invoke({\"num\": 1})']},\n",
       " {'source': 'https://wikidocs.net/233346', 'text': [\"{'num': 1}\"]},\n",
       " {'source': 'https://wikidocs.net/233346',\n",
       "  'text': ['RunnablePassthrough.assign()']},\n",
       " {'source': 'https://wikidocs.net/233346',\n",
       "  'text': ['입력 값으로 들어온 값의 key/value 쌍과 새롭게 할당된 key/value 쌍을 합칩니다.']},\n",
       " {'source': 'https://wikidocs.net/233346',\n",
       "  'text': ['# 입력 키: num, 할당(assign) 키: new_num']},\n",
       " {'source': 'https://wikidocs.net/233346',\n",
       "  'text': ['(RunnablePassthrough.assign(new_num=lambda x: x[\"num\"] * 3)).invoke({\"num\": 1})']},\n",
       " {'source': 'https://wikidocs.net/233346',\n",
       "  'text': [\"{'num': 1, 'new_num': 3}\"]},\n",
       " {'source': 'https://wikidocs.net/233346', 'text': ['RunnableParallel']},\n",
       " {'source': 'https://wikidocs.net/233346',\n",
       "  'text': ['from langchain_core.runnables import RunnableParallel']},\n",
       " {'source': 'https://wikidocs.net/233346',\n",
       "  'text': ['# RunnableParallel 인스턴스를 생성합니다.',\n",
       "   '이 인스턴스는 여러 Runnable 인스턴스를 병렬로 실행할 수 있습니다.',\n",
       "   'runnable = RunnableParallel(']},\n",
       " {'source': 'https://wikidocs.net/233346',\n",
       "  'text': [\"# RunnablePassthrough 인스턴스를 'passed' 키워드 인자로 전달합니다.\",\n",
       "   '이는 입력된 데이터를 그대로 통과시키는 역할을 합니다.',\n",
       "   'passed=RunnablePassthrough(),']},\n",
       " {'source': 'https://wikidocs.net/233346',\n",
       "  'text': [\"# 'extra' 키워드 인자로 RunnablePassthrough.assign을 사용하여, 'mult' 람다 함수를 할당합니다.\",\n",
       "   \"이 함수는 입력된 딕셔너리의 'num' 키에 해당하는 값을 3배로 증가시킵니다.\"]},\n",
       " {'source': 'https://wikidocs.net/233346',\n",
       "  'text': ['extra=RunnablePassthrough.assign(mult=lambda x: x[\"num\"] * 3),']},\n",
       " {'source': 'https://wikidocs.net/233346',\n",
       "  'text': [\"# 'modified' 키워드 인자로 람다 함수를 전달합니다.\",\n",
       "   \"이 함수는 입력된 딕셔너리의 'num' 키에 해당하는 값에 1을 더합니다.\",\n",
       "   'modified=lambda x: x[\"num\"] + 1,']},\n",
       " {'source': 'https://wikidocs.net/233346', 'text': [')']},\n",
       " {'source': 'https://wikidocs.net/233346',\n",
       "  'text': [\"# runnable 인스턴스에 {'num': 1} 딕셔너리를 입력으로 전달하여 invoke 메소드를 호출합니다.\",\n",
       "   'runnable.invoke({\"num\": 1})']},\n",
       " {'source': 'https://wikidocs.net/233346',\n",
       "  'text': [\"{'passed': {'num': 1}, 'extra': {'num': 1, 'mult': 3}, 'modified': 2}\"]},\n",
       " {'source': 'https://wikidocs.net/233346',\n",
       "  'text': ['Chain 도 RunnableParallel 적용할 수 있습니다.']},\n",
       " {'source': 'https://wikidocs.net/233346', 'text': ['chain1 = (']},\n",
       " {'source': 'https://wikidocs.net/233346',\n",
       "  'text': ['{\"country\": RunnablePassthrough()}']},\n",
       " {'source': 'https://wikidocs.net/233346',\n",
       "  'text': ['| PromptTemplate.from_template(\"{country} 의 수도는?\")']},\n",
       " {'source': 'https://wikidocs.net/233346', 'text': ['| ChatOpenAI()']},\n",
       " {'source': 'https://wikidocs.net/233346', 'text': [')']},\n",
       " {'source': 'https://wikidocs.net/233346', 'text': ['chain2 = (']},\n",
       " {'source': 'https://wikidocs.net/233346',\n",
       "  'text': ['{\"country\": RunnablePassthrough()}']},\n",
       " {'source': 'https://wikidocs.net/233346',\n",
       "  'text': ['| PromptTemplate.from_template(\"{country} 의 면적은?\")']},\n",
       " {'source': 'https://wikidocs.net/233346', 'text': ['| ChatOpenAI()']},\n",
       " {'source': 'https://wikidocs.net/233346', 'text': [')']},\n",
       " {'source': 'https://wikidocs.net/233346',\n",
       "  'text': ['combined_chain = RunnableParallel(capital=chain1, area=chain2)']},\n",
       " {'source': 'https://wikidocs.net/233346',\n",
       "  'text': ['combined_chain.invoke(\"대한민국\")']},\n",
       " {'source': 'https://wikidocs.net/233346',\n",
       "  'text': [\"{'capital': AIMessage(content='서울입니다.', response_metadata={'token_usage': {'completion_tokens': 5, 'prompt_tokens': 19, 'total_tokens': 24}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-d9324c24-9670-4430-97d6-1272f5dbe0f2-0', usage_metadata={'input_tokens': 19, 'output_tokens': 5, 'total_tokens': 24}), 'area': AIMessage(content='대한민국의 총 면적은 약 100,363 km²입니다.', response_metadata={'token_usage': {'completion_tokens': 24, 'prompt_tokens': 20, 'total_tokens': 44}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-f27442a3-fc9c-4d08-9fdf-189c1b4585c8-0', usage_metadata={'input_tokens': 20, 'output_tokens': 24, 'total_tokens': 44})}\"]},\n",
       " {'source': 'https://wikidocs.net/233346', 'text': ['RunnableLambda']},\n",
       " {'source': 'https://wikidocs.net/233346',\n",
       "  'text': ['RunnableLambda 를 사용하여 사용자 정의 함수를 맵핑할 수 있습니다.']},\n",
       " {'source': 'https://wikidocs.net/233346',\n",
       "  'text': ['from langchain_core.output_parsers import StrOutputParser']},\n",
       " {'source': 'https://wikidocs.net/233346',\n",
       "  'text': ['from langchain_core.prompts import PromptTemplate']},\n",
       " {'source': 'https://wikidocs.net/233346',\n",
       "  'text': ['from langchain_openai import ChatOpenAI']},\n",
       " {'source': 'https://wikidocs.net/233346',\n",
       "  'text': ['from datetime import datetime']},\n",
       " {'source': 'https://wikidocs.net/233346', 'text': ['def get_today(a):']},\n",
       " {'source': 'https://wikidocs.net/233346',\n",
       "  'text': ['# 오늘 날짜를 가져오기', 'return datetime.today().strftime(\"%b-%d\")']},\n",
       " {'source': 'https://wikidocs.net/233346', 'text': ['# 오늘 날짜를 출력']},\n",
       " {'source': 'https://wikidocs.net/233346', 'text': ['get_today(None)']},\n",
       " {'source': 'https://wikidocs.net/233346', 'text': [\"'Jun-19'\"]},\n",
       " {'source': 'https://wikidocs.net/233346',\n",
       "  'text': ['from langchain_core.runnables import RunnableLambda, RunnablePassthrough']},\n",
       " {'source': 'https://wikidocs.net/233346',\n",
       "  'text': ['# prompt 와 llm 을 생성합니다.',\n",
       "   'prompt = PromptTemplate.from_template(']},\n",
       " {'source': 'https://wikidocs.net/233346',\n",
       "  'text': ['\"{today} 가 생일인 유명인 {n} 명을 나열하세요.', '생년월일을 표기해 주세요.\"']},\n",
       " {'source': 'https://wikidocs.net/233346', 'text': [')']},\n",
       " {'source': 'https://wikidocs.net/233346',\n",
       "  'text': ['llm = ChatOpenAI(temperature=0, model_name=\"gpt-4o\")']},\n",
       " {'source': 'https://wikidocs.net/233346',\n",
       "  'text': ['# chain 을 생성합니다.', 'chain = (']},\n",
       " {'source': 'https://wikidocs.net/233346',\n",
       "  'text': ['{\"today\": RunnableLambda(get_today), \"n\": RunnablePassthrough()}']},\n",
       " {'source': 'https://wikidocs.net/233346', 'text': ['| prompt']},\n",
       " {'source': 'https://wikidocs.net/233346', 'text': ['| llm']},\n",
       " {'source': 'https://wikidocs.net/233346', 'text': ['| StrOutputParser()']},\n",
       " {'source': 'https://wikidocs.net/233346', 'text': [')']},\n",
       " {'source': 'https://wikidocs.net/233346', 'text': ['# 출력']},\n",
       " {'source': 'https://wikidocs.net/233346', 'text': ['print(chain.invoke(3))']},\n",
       " {'source': 'https://wikidocs.net/233346',\n",
       "  'text': ['다음은 6월 19일이 생일인 몇몇 유명인들입니다:']},\n",
       " {'source': 'https://wikidocs.net/233346',\n",
       "  'text': ['1. 폴 도노반 (Paul Dano) - 1984년 6월 19일']},\n",
       " {'source': 'https://wikidocs.net/233346',\n",
       "  'text': ['2. 디렉 노박 조코비치 (Novak Djokovic) - 1987년 6월 19일']},\n",
       " {'source': 'https://wikidocs.net/233346',\n",
       "  'text': ['3. 필리페 쿠티뉴 (Philippe Coutinho) - 1992년 6월 19일']},\n",
       " {'source': 'https://wikidocs.net/233346',\n",
       "  'text': ['이들은 각각 배우, 테니스 선수, 축구 선수로서 다양한 분야에서 활동하고 있습니다.']},\n",
       " {'source': 'https://wikidocs.net/233346',\n",
       "  'text': ['itemgetter 를 사용하여 특정 키를 추출합니다.']},\n",
       " {'source': 'https://wikidocs.net/233346',\n",
       "  'text': ['from operator import itemgetter']},\n",
       " {'source': 'https://wikidocs.net/233346',\n",
       "  'text': ['from langchain_core.prompts import ChatPromptTemplate']},\n",
       " {'source': 'https://wikidocs.net/233346',\n",
       "  'text': ['from langchain_core.runnables import RunnableLambda']},\n",
       " {'source': 'https://wikidocs.net/233346',\n",
       "  'text': ['from langchain_openai import ChatOpenAI']},\n",
       " {'source': 'https://wikidocs.net/233346', 'text': ['# 문장의 길이를 반환하는 함수입니다.']},\n",
       " {'source': 'https://wikidocs.net/233346',\n",
       "  'text': ['def length_function(text):', 'return len(text)']},\n",
       " {'source': 'https://wikidocs.net/233346',\n",
       "  'text': ['# 두 문장의 길이를 곱한 값을 반환하는 함수입니다.']},\n",
       " {'source': 'https://wikidocs.net/233346',\n",
       "  'text': ['def _multiple_length_function(text1, text2):']},\n",
       " {'source': 'https://wikidocs.net/233346',\n",
       "  'text': ['return len(text1) * len(text2)']},\n",
       " {'source': 'https://wikidocs.net/233346',\n",
       "  'text': ['# _multiple_length_function 함수를 사용하여 두 문장의 길이를 곱한 값을 반환하는 함수입니다.']},\n",
       " {'source': 'https://wikidocs.net/233346',\n",
       "  'text': ['def multiple_length_function(_dict):']},\n",
       " {'source': 'https://wikidocs.net/233346',\n",
       "  'text': ['return _multiple_length_function(_dict[\"text1\"], _dict[\"text2\"])']},\n",
       " {'source': 'https://wikidocs.net/233346',\n",
       "  'text': ['prompt = ChatPromptTemplate.from_template(\"{a} + {b} 는 무엇인가요?\")',\n",
       "   'model = ChatOpenAI()']},\n",
       " {'source': 'https://wikidocs.net/233346',\n",
       "  'text': ['chain1 = prompt | model']},\n",
       " {'source': 'https://wikidocs.net/233346', 'text': ['chain = (']},\n",
       " {'source': 'https://wikidocs.net/233346', 'text': ['{']},\n",
       " {'source': 'https://wikidocs.net/233346',\n",
       "  'text': ['\"a\": itemgetter(\"word1\") | RunnableLambda(length_function),']},\n",
       " {'source': 'https://wikidocs.net/233346',\n",
       "  'text': ['\"b\": {\"text1\": itemgetter(\"word1\"), \"text2\": itemgetter(\"word2\")}']},\n",
       " {'source': 'https://wikidocs.net/233346',\n",
       "  'text': ['| RunnableLambda(multiple_length_function),']},\n",
       " {'source': 'https://wikidocs.net/233346', 'text': ['}']},\n",
       " {'source': 'https://wikidocs.net/233346', 'text': ['| prompt']},\n",
       " {'source': 'https://wikidocs.net/233346', 'text': ['| model']},\n",
       " {'source': 'https://wikidocs.net/233346', 'text': [')']},\n",
       " {'source': 'https://wikidocs.net/233346',\n",
       "  'text': ['chain.invoke({\"word1\": \"hello\", \"word2\": \"world\"})']},\n",
       " {'source': 'https://wikidocs.net/233346',\n",
       "  'text': [\"AIMessage(content='5 + 25 = 30입니다.', response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 22, 'total_tokens': 31}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-5db9b475-09ee-4edb-af9d-b37b320bee1e-0', usage_metadata={'input_tokens': 22, 'output_tokens': 9, 'total_tokens': 31})\"]},\n",
       " {'source': 'https://wikidocs.net/233346',\n",
       "  'text': ['마지막 편집일시 : 2024년 6월 19일 10:59 오후']},\n",
       " {'source': 'https://wikidocs.net/233346', 'text': ['댓글 0 피드백']},\n",
       " {'source': 'https://wikidocs.net/233346',\n",
       "  'text': ['※ 댓글 작성은 로그인이 필요합니다.', '(또는 피드백을 이용해 주세요.)']},\n",
       " {'source': 'https://wikidocs.net/233346', 'text': ['이전글 : 05.']},\n",
       " {'source': 'https://wikidocs.net/233346', 'text': ['LCEL 인터페이스']},\n",
       " {'source': 'https://wikidocs.net/233346',\n",
       "  'text': ['다음글 : CH02 프롬프트(Prompt)']},\n",
       " {'source': 'https://wikidocs.net/233346', 'text': ['책갈피']},\n",
       " {'source': 'https://wikidocs.net/233346', 'text': ['이 페이지에 대한 피드백을 남겨주세요']},\n",
       " {'source': 'https://wikidocs.net/233346', 'text': ['댓글을 신고합니다.']},\n",
       " {'source': 'https://wikidocs.net/233344',\n",
       "  'text': ['<랭체인LangChain 노트> - LangChain 한국어 튜토리얼🇰🇷 CH01 LangChain 시작하기']},\n",
       " {'source': 'https://wikidocs.net/233344',\n",
       "  'text': ['01. OpenAI API 키 발급 및 테스트']},\n",
       " {'source': 'https://wikidocs.net/233344', 'text': ['02. LangSmith 추적 설정']},\n",
       " {'source': 'https://wikidocs.net/233344',\n",
       "  'text': ['03. OpenAI API 사용(GPT-4o 멀티모달)']},\n",
       " {'source': 'https://wikidocs.net/233344',\n",
       "  'text': ['04. LangChain Expression Language(LCEL)']},\n",
       " {'source': 'https://wikidocs.net/233344', 'text': ['05. LCEL 인터페이스']},\n",
       " {'source': 'https://wikidocs.net/233344',\n",
       "  'text': ['06. Runnable CH02 프롬프트(Prompt)']},\n",
       " {'source': 'https://wikidocs.net/233344', 'text': ['01. 프롬프트(Prompt)']},\n",
       " {'source': 'https://wikidocs.net/233344',\n",
       "  'text': ['02. 퓨샷 프롬프트(FewShotPromptTemplate)']},\n",
       " {'source': 'https://wikidocs.net/233344', 'text': ['03. LangChain Hub']},\n",
       " {'source': 'https://wikidocs.net/233344',\n",
       "  'text': ['04. 개인화된 프롬프트(Hub에 업로드) CH03 출력 파서(Output Parsers)']},\n",
       " {'source': 'https://wikidocs.net/233344',\n",
       "  'text': ['01. Pydantic 출력 파서(PydanticOutputParser)']},\n",
       " {'source': 'https://wikidocs.net/233344',\n",
       "  'text': ['02. 콤마 구분자 출력 파서(CommaSeparatedListOutputParser)']},\n",
       " {'source': 'https://wikidocs.net/233344',\n",
       "  'text': ['03. 구조화된 출력 파서(StructuredOuputParser)']},\n",
       " {'source': 'https://wikidocs.net/233344',\n",
       "  'text': ['04. JSON 출력 파서(JsonOutputParser)']},\n",
       " {'source': 'https://wikidocs.net/233344',\n",
       "  'text': ['05. 데이터프레임 출력 파서(PandasDataFrameOutputParser)']},\n",
       " {'source': 'https://wikidocs.net/233344',\n",
       "  'text': ['06. 날짜 형식 출력 파서(DatetimeOutputParser)']},\n",
       " {'source': 'https://wikidocs.net/233344',\n",
       "  'text': ['07. 열거형 출력 파서(EnumOutputParser)']},\n",
       " {'source': 'https://wikidocs.net/233344',\n",
       "  'text': ['08. 출력 수정 파서(OutputFixingParser) CH04 모델(Model)']},\n",
       " {'source': 'https://wikidocs.net/233344', 'text': ['01. 다양한 LLM 모델 활용']},\n",
       " {'source': 'https://wikidocs.net/233344', 'text': ['02. 캐싱(Cache)']},\n",
       " {'source': 'https://wikidocs.net/233344',\n",
       "  'text': ['03. 모델 직렬화(Serialization) - 저장 및 불러오기']},\n",
       " {'source': 'https://wikidocs.net/233344', 'text': ['04. 토큰 사용량 확인']},\n",
       " {'source': 'https://wikidocs.net/233344',\n",
       "  'text': ['05. 구글 생성 AI(Google Generative AI)']},\n",
       " {'source': 'https://wikidocs.net/233344',\n",
       "  'text': ['06. 허깅페이스 엔드포인트(HuggingFace Endpoints)']},\n",
       " {'source': 'https://wikidocs.net/233344',\n",
       "  'text': ['07. 허깅페이스 로컬(HuggingFace Local)']},\n",
       " {'source': 'https://wikidocs.net/233344',\n",
       "  'text': ['08. 허깅페이스 파이프라인(HuggingFace Pipeline)']},\n",
       " {'source': 'https://wikidocs.net/233344', 'text': ['09. 올라마(Ollama)']},\n",
       " {'source': 'https://wikidocs.net/233344',\n",
       "  'text': ['10. GPT4ALL CH05 메모리(Memory)']},\n",
       " {'source': 'https://wikidocs.net/233344',\n",
       "  'text': ['01. 대화 버퍼 메모리(ConversationBufferMemory)']},\n",
       " {'source': 'https://wikidocs.net/233344',\n",
       "  'text': ['02. 대화 버퍼 윈도우 메모리(ConversationBufferWindowMemory)']},\n",
       " {'source': 'https://wikidocs.net/233344',\n",
       "  'text': ['03. 대화 토큰 버퍼 메모리(ConversationTokenBufferMemory)']},\n",
       " {'source': 'https://wikidocs.net/233344',\n",
       "  'text': ['04. 대화 엔티티 메모리(ConversationEntityMemory)']},\n",
       " {'source': 'https://wikidocs.net/233344',\n",
       "  'text': ['05. 대화 지식그래프 메모리(ConversationKGMemory)']},\n",
       " {'source': 'https://wikidocs.net/233344',\n",
       "  'text': ['06. 대화 요약 메모리(ConversationSummaryMemory)']},\n",
       " {'source': 'https://wikidocs.net/233344',\n",
       "  'text': ['07. 벡터저장소 검색 메모리(VectorStoreRetrieverMemory)']},\n",
       " {'source': 'https://wikidocs.net/233344',\n",
       "  'text': ['08. LCEL Chain 에 메모리 추가', '09. SQLite 에 대화내용 저장']},\n",
       " {'source': 'https://wikidocs.net/233344',\n",
       "  'text': ['10. RunnableWithMessageHistory에 ChatMessageHistory추가 CH06 문서 로더(Document Loader)']},\n",
       " {'source': 'https://wikidocs.net/233344',\n",
       "  'text': ['01. 도큐먼트(Document) 의 구조']},\n",
       " {'source': 'https://wikidocs.net/233344', 'text': ['02. PDF']},\n",
       " {'source': 'https://wikidocs.net/233344', 'text': ['03. 한글(HWP)']},\n",
       " {'source': 'https://wikidocs.net/233344', 'text': ['04. CSV']},\n",
       " {'source': 'https://wikidocs.net/233344', 'text': ['05. Excel']},\n",
       " {'source': 'https://wikidocs.net/233344', 'text': ['06. Word']},\n",
       " {'source': 'https://wikidocs.net/233344', 'text': ['07. PowerPoint']},\n",
       " {'source': 'https://wikidocs.net/233344',\n",
       "  'text': ['08. 웹 문서(WebBaseLoader)']},\n",
       " {'source': 'https://wikidocs.net/233344', 'text': ['09. 텍스트(TextLoader)']},\n",
       " {'source': 'https://wikidocs.net/233344', 'text': ['10. JSON']},\n",
       " {'source': 'https://wikidocs.net/233344', 'text': ['11. Arxiv']},\n",
       " {'source': 'https://wikidocs.net/233344',\n",
       "  'text': ['13. UpstageLayoutAnalysisLoader']},\n",
       " {'source': 'https://wikidocs.net/233344',\n",
       "  'text': ['14. LlamaParser CH07 텍스트 분할(Text Splitter)']},\n",
       " {'source': 'https://wikidocs.net/233344',\n",
       "  'text': ['01. 문자 텍스트 분할(CharacterTextSplitter)']},\n",
       " {'source': 'https://wikidocs.net/233344',\n",
       "  'text': ['02. 재귀적 문자 텍스트 분할(RecursiveCharacterTextSplitter)']},\n",
       " {'source': 'https://wikidocs.net/233344',\n",
       "  'text': ['03. 토큰 텍스트 분할(TokenTextSplitter)']},\n",
       " {'source': 'https://wikidocs.net/233344',\n",
       "  'text': ['04. 시멘틱 청커(SemanticChunker)']},\n",
       " {'source': 'https://wikidocs.net/233344',\n",
       "  'text': ['05. 코드 분할(Python, Markdown, JAVA, C++, C#, GO, JS, Latex 등)']},\n",
       " {'source': 'https://wikidocs.net/233344',\n",
       "  'text': ['06. 마크다운 헤더 텍스트 분할(MarkdownHeaderTextSplitter)']},\n",
       " {'source': 'https://wikidocs.net/233344',\n",
       "  'text': ['07. HTML 헤더 텍스트 분할(HTMLHeaderTextSplitter)']},\n",
       " {'source': 'https://wikidocs.net/233344',\n",
       "  'text': ['08. 재귀적 JSON 분할(RecursiveJsonSplitter) CH08 임베딩(Embedding)']},\n",
       " {'source': 'https://wikidocs.net/233344', 'text': ['01. OpenAIEmbeddings']},\n",
       " {'source': 'https://wikidocs.net/233344',\n",
       "  'text': ['02. 캐시 임베딩(CacheBackedEmbeddings)']},\n",
       " {'source': 'https://wikidocs.net/233344',\n",
       "  'text': ['03. 허깅페이스 임베딩(HuggingFace Embeddings)']},\n",
       " {'source': 'https://wikidocs.net/233344', 'text': ['04. UpstageEmbeddings']},\n",
       " {'source': 'https://wikidocs.net/233344', 'text': ['05. OllamaEmbeddings']},\n",
       " {'source': 'https://wikidocs.net/233344', 'text': ['06. GPT4ALL 임베딩']},\n",
       " {'source': 'https://wikidocs.net/233344',\n",
       "  'text': ['07. Llama CPP 임베딩 CH09 벡터저장소(VectorStore)']},\n",
       " {'source': 'https://wikidocs.net/233344', 'text': ['01. Chroma']},\n",
       " {'source': 'https://wikidocs.net/233344', 'text': ['02. FAISS']},\n",
       " {'source': 'https://wikidocs.net/233344',\n",
       "  'text': ['03. Pinecone CH10 검색기(Retriever)']},\n",
       " {'source': 'https://wikidocs.net/233344',\n",
       "  'text': ['01. 벡터저장소 지원 검색기(VectorStore-backed Retriever)']},\n",
       " {'source': 'https://wikidocs.net/233344',\n",
       "  'text': ['02. 문맥 압축 검색기(ContextualCompressionRetriever)']},\n",
       " {'source': 'https://wikidocs.net/233344',\n",
       "  'text': ['03. 앙상블 검색기(EnsembleRetriever)']},\n",
       " {'source': 'https://wikidocs.net/233344',\n",
       "  'text': ['04. 긴 문맥 재정렬(LongContextReorder)']},\n",
       " {'source': 'https://wikidocs.net/233344',\n",
       "  'text': ['05. 상위 문서 검색기(ParentDocumentRetriever)']},\n",
       " {'source': 'https://wikidocs.net/233344',\n",
       "  'text': ['06. 다중 쿼리 검색기(MultiQueryRetriever)']},\n",
       " {'source': 'https://wikidocs.net/233344',\n",
       "  'text': ['07. 다중 벡터저장소 검색기(MultiVectorRetriever)']},\n",
       " {'source': 'https://wikidocs.net/233344',\n",
       "  'text': ['08. 셀프 쿼리 검색기(SelfQueryRetriever)']},\n",
       " {'source': 'https://wikidocs.net/233344',\n",
       "  'text': ['09. 시간 가중 벡터저장소 검색기(TimeWeightedVectorStoreRetriever)']},\n",
       " {'source': 'https://wikidocs.net/233344',\n",
       "  'text': ['10. 한글 형태소 분석기(Kiwi, Kkma, Okt) + BM25 검색기 CH11 리랭커(Reranker)']},\n",
       " {'source': 'https://wikidocs.net/233344',\n",
       "  'text': ['01. Cross Encoder Reranker']},\n",
       " {'source': 'https://wikidocs.net/233344', 'text': ['02. Cohere Reranker']},\n",
       " {'source': 'https://wikidocs.net/233344', 'text': ['03. Jina Reranker']},\n",
       " {'source': 'https://wikidocs.net/233344',\n",
       "  'text': ['04. FlashRank Reranker CH12 Retrieval Augmented Generation(RAG)']},\n",
       " {'source': 'https://wikidocs.net/233344',\n",
       "  'text': ['01. PDF 문서 기반 QA(Question-Answer)']},\n",
       " {'source': 'https://wikidocs.net/233344',\n",
       "  'text': ['02. 네이버 뉴스기사 QA(Question-Answer)']},\n",
       " {'source': 'https://wikidocs.net/233344',\n",
       "  'text': ['03. RAG 의 기능별 다양한 모듈 활용기']},\n",
       " {'source': 'https://wikidocs.net/233344',\n",
       "  'text': ['04. RAPTOR: 긴 문맥 요약(Long Context Summary)']},\n",
       " {'source': 'https://wikidocs.net/233344',\n",
       "  'text': ['05. 대화내용을 기억하는 RAG 체인 CH13 LangChain Expression Language(LCEL)']},\n",
       " {'source': 'https://wikidocs.net/233344',\n",
       "  'text': ['01. RunnablePassthrough: 데이터 전달']},\n",
       " {'source': 'https://wikidocs.net/233344',\n",
       "  'text': ['02. Runnable 구조(그래프) 확인']},\n",
       " {'source': 'https://wikidocs.net/233344',\n",
       "  'text': ['03. RunnableLambda: 사용자 정의 함수']},\n",
       " {'source': 'https://wikidocs.net/233344',\n",
       "  'text': ['04. RunnableBranch: 라우팅(Routing)']},\n",
       " {'source': 'https://wikidocs.net/233344',\n",
       "  'text': ['05. RunnableParallel: 병렬 처리']},\n",
       " {'source': 'https://wikidocs.net/233344',\n",
       "  'text': ['06. configurable_fields, configurable_alternatives 07. @chain 데코레이터로 Runnable 생성',\n",
       "   '08. RunnableWithMessageHistory']},\n",
       " {'source': 'https://wikidocs.net/233344',\n",
       "  'text': ['09. 사용자 정의 제네레이터(generator)']},\n",
       " {'source': 'https://wikidocs.net/233344',\n",
       "  'text': ['10. Runtime Arguments 바인딩']},\n",
       " {'source': 'https://wikidocs.net/233344',\n",
       "  'text': ['11. 폴백(fallback) 모델 지정 CH14 체인(Chains)']},\n",
       " {'source': 'https://wikidocs.net/233344', 'text': ['01. 문서 요약']},\n",
       " {'source': 'https://wikidocs.net/233344',\n",
       "  'text': ['02. SQL CH15 에이전트(Agent)']},\n",
       " {'source': 'https://wikidocs.net/233344', 'text': ['01. Agent 사용법 톺아보기']},\n",
       " {'source': 'https://wikidocs.net/233344',\n",
       "  'text': ['02. 도구를 활용한 토론 에이전트(Two Agent Debates with Tools) CH16 파인튜닝(Fine Tuning)']},\n",
       " {'source': 'https://wikidocs.net/233344', 'text': ['CH17 LangGraph']},\n",
       " {'source': 'https://wikidocs.net/233344',\n",
       "  'text': ['01. Chain of Table for Multiple Tables']},\n",
       " {'source': 'https://wikidocs.net/233344',\n",
       "  'text': ['Published with WikiDocs']},\n",
       " {'source': 'https://wikidocs.net/233344',\n",
       "  'text': ['<랭체인LangChain 노트> - Lang…']},\n",
       " {'source': 'https://wikidocs.net/233344', 'text': ['CH01 LangChain 시작하기']},\n",
       " {'source': 'https://wikidocs.net/233344',\n",
       "  'text': ['04. LangChain Expression…']},\n",
       " {'source': 'https://wikidocs.net/233344', 'text': ['위키독스']},\n",
       " {'source': 'https://wikidocs.net/233344',\n",
       "  'text': ['04. LangChain Expression Language(LCEL)']},\n",
       " {'source': 'https://wikidocs.net/233344',\n",
       "  'text': ['기본 예시: 프롬프트 + 모델 + 출력 파서']},\n",
       " {'source': 'https://wikidocs.net/233344',\n",
       "  'text': ['가장 기본적이고 일반적인 사용 사례는 prompt 템플릿과 모델을 함께 연결하는 것입니다.']},\n",
       " {'source': 'https://wikidocs.net/233344',\n",
       "  'text': ['이것이 어떻게 작동하는지 보기 위해, 각 나라별 수도를 물어보는 Chain을 생성해 보겠습니다.']},\n",
       " {'source': 'https://wikidocs.net/233344',\n",
       "  'text': ['# API KEY를 환경변수로 관리하기 위한 설정 파일',\n",
       "   'from dotenv import load_dotenv']},\n",
       " {'source': 'https://wikidocs.net/233344',\n",
       "  'text': ['# API KEY 정보로드', 'load_dotenv()']},\n",
       " {'source': 'https://wikidocs.net/233344', 'text': ['True']},\n",
       " {'source': 'https://wikidocs.net/233344',\n",
       "  'text': ['# LangSmith 추적을 설정합니다.', 'https://smith.langchain.com']},\n",
       " {'source': 'https://wikidocs.net/233344',\n",
       "  'text': ['# !pip install -qU langchain-teddynote']},\n",
       " {'source': 'https://wikidocs.net/233344',\n",
       "  'text': ['from langchain_teddynote import logging']},\n",
       " {'source': 'https://wikidocs.net/233344', 'text': ['# 프로젝트 이름을 입력합니다.']},\n",
       " {'source': 'https://wikidocs.net/233344',\n",
       "  'text': ['logging.langsmith(\"CH01-Basic\")']},\n",
       " {'source': 'https://wikidocs.net/233344', 'text': ['LangSmith 추적을 시작합니다.']},\n",
       " {'source': 'https://wikidocs.net/233344', 'text': ['[프로젝트명]']},\n",
       " {'source': 'https://wikidocs.net/233344', 'text': ['CH01-Basic']},\n",
       " {'source': 'https://wikidocs.net/233344', 'text': ['프롬프트 템플릿의 활용']},\n",
       " {'source': 'https://wikidocs.net/233344', 'text': ['PromptTemplate']},\n",
       " {'source': 'https://wikidocs.net/233344',\n",
       "  'text': ['사용자의 입력 변수를 사용하여 완전한 프롬프트 문자열을 만드는 데 사용되는 템플릿입니다', '사용법']},\n",
       " {'source': 'https://wikidocs.net/233344', 'text': ['template: 템플릿 문자열입니다.']},\n",
       " {'source': 'https://wikidocs.net/233344',\n",
       "  'text': ['이 문자열 내에서 중괄호 {}는 변수를 나타냅니다.']},\n",
       " {'source': 'https://wikidocs.net/233344',\n",
       "  'text': ['input_variables: 중괄호 안에 들어갈 변수의 이름을 리스트로 정의합니다.']},\n",
       " {'source': 'https://wikidocs.net/233344', 'text': ['input_variables']},\n",
       " {'source': 'https://wikidocs.net/233344',\n",
       "  'text': ['input_variables는 PromptTemplate에서 사용되는 변수의 이름을 정의하는 리스트입니다.']},\n",
       " {'source': 'https://wikidocs.net/233344',\n",
       "  'text': ['from langchain_teddynote.messages import stream_response # 스트리밍 출력']},\n",
       " {'source': 'https://wikidocs.net/233344',\n",
       "  'text': ['from langchain_core.prompts import PromptTemplate']},\n",
       " {'source': 'https://wikidocs.net/233344',\n",
       "  'text': ['from_template() 메소드를 사용하여 PromptTemplate 객체 생성']},\n",
       " {'source': 'https://wikidocs.net/233344', 'text': ['# template 정의']},\n",
       " {'source': 'https://wikidocs.net/233344',\n",
       "  'text': ['template = \"{country}의 수도는 어디인가요?\"']},\n",
       " {'source': 'https://wikidocs.net/233344',\n",
       "  'text': ['# from_template 메소드를 이용하여 PromptTemplate 객체 생성']},\n",
       " {'source': 'https://wikidocs.net/233344',\n",
       "  'text': ['prompt_template = PromptTemplate.from_template(template)']},\n",
       " {'source': 'https://wikidocs.net/233344', 'text': ['prompt_template']},\n",
       " {'source': 'https://wikidocs.net/233344',\n",
       "  'text': [\"PromptTemplate(input_variables=['country'], template='{country}의 수도는 어디인가요?')\"]},\n",
       " {'source': 'https://wikidocs.net/233344', 'text': ['# prompt 생성']},\n",
       " {'source': 'https://wikidocs.net/233344',\n",
       "  'text': ['prompt = prompt_template.format(country=\"대한민국\")']},\n",
       " {'source': 'https://wikidocs.net/233344', 'text': ['prompt']},\n",
       " {'source': 'https://wikidocs.net/233344', 'text': [\"'대한민국의 수도는 어디인가요?'\"]},\n",
       " {'source': 'https://wikidocs.net/233344', 'text': ['# prompt 생성']},\n",
       " {'source': 'https://wikidocs.net/233344',\n",
       "  'text': ['prompt = prompt_template.format(country=\"미국\")']},\n",
       " {'source': 'https://wikidocs.net/233344', 'text': ['prompt']},\n",
       " {'source': 'https://wikidocs.net/233344', 'text': [\"'미국의 수도는 어디인가요?'\"]},\n",
       " {'source': 'https://wikidocs.net/233344',\n",
       "  'text': ['from langchain_openai import ChatOpenAI']},\n",
       " {'source': 'https://wikidocs.net/233344', 'text': ['model = ChatOpenAI(']},\n",
       " {'source': 'https://wikidocs.net/233344', 'text': ['model=\"gpt-3.5-turbo\",']},\n",
       " {'source': 'https://wikidocs.net/233344', 'text': ['max_tokens=2048,']},\n",
       " {'source': 'https://wikidocs.net/233344', 'text': ['temperature=0.1,']},\n",
       " {'source': 'https://wikidocs.net/233344', 'text': [')']},\n",
       " {'source': 'https://wikidocs.net/233344', 'text': ['Chain 생성']},\n",
       " {'source': 'https://wikidocs.net/233344',\n",
       "  'text': ['LCEL(LangChain Expression Language)']},\n",
       " {'source': 'https://wikidocs.net/233344',\n",
       "  'text': ['여기서 우리는 LCEL을 사용하여 다양한 구성 요소를 단일 체인으로 결합합니다']},\n",
       " {'source': 'https://wikidocs.net/233344',\n",
       "  'text': ['chain = prompt | model | output_parser']},\n",
       " {'source': 'https://wikidocs.net/233344',\n",
       "  'text': ['| 기호는 unix 파이프 연산자와 유사하며, 서로 다른 구성 요소를 연결하고 한 구성 요소의 출력을 다음 구성 요소의 입력으로 전달합니다.']},\n",
       " {'source': 'https://wikidocs.net/233344',\n",
       "  'text': ['이 체인에서 사용자 입력은 프롬프트 템플릿으로 전달되고, 그런 다음 프롬프트 템플릿 출력은 모델로 전달됩니다.']},\n",
       " {'source': 'https://wikidocs.net/233344',\n",
       "  'text': ['각 구성 요소를 개별적으로 살펴보면 무슨 일이 일어나고 있는지 이해할 수 있습니다.']},\n",
       " {'source': 'https://wikidocs.net/233344',\n",
       "  'text': ['# prompt 를 PromptTemplate 객체로 생성합니다.',\n",
       "   'prompt = PromptTemplate.from_template(\"{topic} 에 대해 쉽게 설명해주세요.\")']},\n",
       " {'source': 'https://wikidocs.net/233344', 'text': ['model = ChatOpenAI()']},\n",
       " {'source': 'https://wikidocs.net/233344', 'text': ['chain = prompt | model']},\n",
       " {'source': 'https://wikidocs.net/233344',\n",
       "  'text': ['invoke() 호출',\n",
       "   'python 딕셔너리 형태로 입력값을 전달합니다.(키: 값)',\n",
       "   'invoke() 함수 호출 시, 입력값을 전달합니다.']},\n",
       " {'source': 'https://wikidocs.net/233344',\n",
       "  'text': [\"# input 딕셔너리에 주제를 '인공지능 모델의 학습 원리'으로 설정합니다.\"]},\n",
       " {'source': 'https://wikidocs.net/233344',\n",
       "  'text': ['input = {\"topic\": \"인공지능 모델의 학습 원리\"}']},\n",
       " {'source': 'https://wikidocs.net/233344',\n",
       "  'text': ['# prompt 객체와 model 객체를 파이프(|) 연산자로 연결하고 invoke 메서드를 사용하여 input을 전달합니다.',\n",
       "   '# 이를 통해 AI 모델이 생성한 메시지를 반환합니다.']},\n",
       " {'source': 'https://wikidocs.net/233344', 'text': ['chain.invoke(input)']},\n",
       " {'source': 'https://wikidocs.net/233344',\n",
       "  'text': [\"AIMessage(content='인공지능 모델의 학습 원리는 데이터를 이용하여 패턴을 학습하는 것입니다.\"]},\n",
       " {'source': 'https://wikidocs.net/233344',\n",
       "  'text': ['모델은 입력 데이터를 받아들이고 내부적으로 가중치를 조정하여 원하는 결과를 출력합니다.',\n",
       "   '학습 과정에서 모델은 입력 데이터와 정답 데이터를 이용하여 오차를 계산하고 이 오차를 최소화하는 방향으로 가중치를 업데이트합니다.',\n",
       "   '이렇게 반복적으로 학습을 진행하면 모델은 입력 데이터로부터 패턴을 학습하여 정확한 결과를 예측하게 됩니다.',\n",
       "   \"이러한 학습 원리를 통해 인공지능 모델은 데이터를 이용하여 스스로 학습하고 문제를 해결할 수 있습니다.', response_metadata={'token_usage': {'completion_tokens': 214, 'prompt_tokens': 33, 'total_tokens': 247}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-7f8a08f4-51ba-4d14-b9d2-2e092be3e7aa-0', usage_metadata={'input_tokens': 33, 'output_tokens': 214, 'total_tokens': 247})\"]},\n",
       " {'source': 'https://wikidocs.net/233344', 'text': ['아래는 스트리밍을 출력하는 예시 입니다.']},\n",
       " {'source': 'https://wikidocs.net/233344', 'text': ['# 스트리밍 출력을 위한 요청']},\n",
       " {'source': 'https://wikidocs.net/233344',\n",
       "  'text': ['answer = chain.stream(input)']},\n",
       " {'source': 'https://wikidocs.net/233344', 'text': ['# 스트리밍 출력']},\n",
       " {'source': 'https://wikidocs.net/233344',\n",
       "  'text': ['stream_response(answer)']},\n",
       " {'source': 'https://wikidocs.net/233344',\n",
       "  'text': ['인공지능 모델의 학습 원리는 데이터를 입력으로 받아서 패턴을 학습하고 이를 기반으로 예측이나 분류를 수행하는 과정입니다.',\n",
       "   '학습 과정은 크게 입력층, 은닉층, 출력층으로 구성된 인공신경망을 사용합니다.',\n",
       "   '입력층에서 데이터를 받아 은닉층을 거쳐 출력층으로 결과를 출력하는 구조입니다.']},\n",
       " {'source': 'https://wikidocs.net/233344',\n",
       "  'text': ['이때, 모델은 주어진 데이터를 통해 가중치를 조정하고 오차를 최소화하는 방향으로 학습을 진행합니다.',\n",
       "   '이를 위해 주어진 데이터에 대해 예측을 수행하고 실제 값과 비교하여 오차를 계산한 후, 이 오차를 줄이기 위해 가중치를 업데이트합니다.',\n",
       "   '이러한 반복적인 과정을 통해 모델은 데이터 간의 패턴을 학습하고 새로운 데이터에 대해 정확한 예측을 수행할 수 있게 됩니다.',\n",
       "   '이렇게 학습된 모델은 새로운 데이터에 대해 일반화된 예측을 할 수 있습니다.']},\n",
       " {'source': 'https://wikidocs.net/233344', 'text': ['출력파서(Output Parser)']},\n",
       " {'source': 'https://wikidocs.net/233344',\n",
       "  'text': ['from langchain_core.output_parsers import StrOutputParser']},\n",
       " {'source': 'https://wikidocs.net/233344',\n",
       "  'text': ['output_parser = StrOutputParser()']},\n",
       " {'source': 'https://wikidocs.net/233344', 'text': ['Chain 에 출력파서를 추가합니다.']},\n",
       " {'source': 'https://wikidocs.net/233344',\n",
       "  'text': ['# 프롬프트, 모델, 출력 파서를 연결하여 처리 체인을 구성합니다.',\n",
       "   'chain = prompt | model | output_parser']},\n",
       " {'source': 'https://wikidocs.net/233344',\n",
       "  'text': ['# chain 객체의 invoke 메서드를 사용하여 input을 전달합니다.']},\n",
       " {'source': 'https://wikidocs.net/233344',\n",
       "  'text': ['input = {\"topic\": \"인공지능 모델의 학습 원리\"}']},\n",
       " {'source': 'https://wikidocs.net/233344', 'text': ['chain.invoke(input)']},\n",
       " {'source': 'https://wikidocs.net/233344',\n",
       "  'text': [\"'인공지능 모델의 학습 원리는 데이터를 입력으로 받아서 패턴을 학습하는 것입니다.\",\n",
       "   '모델은 입력 데이터를 받아서 내부적으로 가중치를 조절하면서 원하는 결과를 출력하도록 학습됩니다.',\n",
       "   '이때, 모델은 입력 데이터와 출력 데이터 간의 관계를 학습하여 새로운 입력 데이터에 대한 출력을 예측할 수 있게 됩니다.',\n",
       "   '이 과정은 반복적으로 이루어지며, 모델은 학습을 통해 점차적으로 정확도를 향상시킵니다.',\n",
       "   \"이러한 방식으로 인공지능 모델은 주어진 데이터를 기반으로 판단하고 예측하는 능력을 향상시킬 수 있습니다.'\"]},\n",
       " {'source': 'https://wikidocs.net/233344', 'text': ['# 스트리밍 출력을 위한 요청']},\n",
       " {'source': 'https://wikidocs.net/233344',\n",
       "  'text': ['answer = chain.stream(input)']},\n",
       " {'source': 'https://wikidocs.net/233344', 'text': ['# 스트리밍 출력']},\n",
       " {'source': 'https://wikidocs.net/233344',\n",
       "  'text': ['stream_response(answer)']},\n",
       " {'source': 'https://wikidocs.net/233344',\n",
       "  'text': ['인공지능 모델의 학습 원리는 데이터를 이용해서 패턴을 학습하는 과정입니다.',\n",
       "   '먼저 모델은 입력 데이터를 받아서 처리하고, 이때 입력 데이터와 정답 데이터를 비교하여 오차를 계산합니다.',\n",
       "   '이 오차를 최소화하기 위해 모델은 가중치와 편향을 조정하면서 점차적으로 정확한 패턴을 학습해나갑니다.',\n",
       "   '이런 과정을 반복하여 모델이 데이터에 대해 정확한 예측을 할 수 있도록 학습시키는 것이 인공지능 모델의 핵심 원리입니다.']},\n",
       " {'source': 'https://wikidocs.net/233344',\n",
       "  'text': ['템플릿을 변경하여 적용',\n",
       "   '아래의 프롬프트 내용을 얼마든지 변경 하여 테스트 해볼 수 있습니다.',\n",
       "   'model_name 역시 변경하여 테스트가 가능합니다.']},\n",
       " {'source': 'https://wikidocs.net/233344', 'text': ['template = \"\"\"']},\n",
       " {'source': 'https://wikidocs.net/233344',\n",
       "  'text': ['당신은 영어를 가르치는 10년차 영어 선생님입니다.', '상황에 [FORMAT]에 영어 회화를 작성해 주세요.']},\n",
       " {'source': 'https://wikidocs.net/233344', 'text': ['상황:']},\n",
       " {'source': 'https://wikidocs.net/233344', 'text': ['{question}']},\n",
       " {'source': 'https://wikidocs.net/233344', 'text': ['FORMAT:']},\n",
       " {'source': 'https://wikidocs.net/233344', 'text': ['- 영어 회화:']},\n",
       " {'source': 'https://wikidocs.net/233344', 'text': ['- 한글 해석:']},\n",
       " {'source': 'https://wikidocs.net/233344', 'text': ['\"\"\"']},\n",
       " {'source': 'https://wikidocs.net/233344',\n",
       "  'text': ['# 프롬프트 템플릿을 이용하여 프롬프트를 생성합니다.']},\n",
       " {'source': 'https://wikidocs.net/233344',\n",
       "  'text': ['prompt = PromptTemplate.from_template(template)']},\n",
       " {'source': 'https://wikidocs.net/233344',\n",
       "  'text': ['# ChatOpenAI 챗모델을 초기화합니다.',\n",
       "   'model = ChatOpenAI(model_name=\"gpt-4-turbo\")']},\n",
       " {'source': 'https://wikidocs.net/233344', 'text': ['# 문자열 출력 파서를 초기화합니다.']},\n",
       " {'source': 'https://wikidocs.net/233344',\n",
       "  'text': ['output_parser = StrOutputParser()']},\n",
       " {'source': 'https://wikidocs.net/233344', 'text': ['# 체인을 구성합니다.']},\n",
       " {'source': 'https://wikidocs.net/233344',\n",
       "  'text': ['chain = prompt | model | output_parser',\n",
       "   '# 완성된 Chain을 실행하여 답변을 얻습니다.']},\n",
       " {'source': 'https://wikidocs.net/233344',\n",
       "  'text': ['# 스트리밍 출력을 위한 요청',\n",
       "   'answer = chain.stream({\"question\": \"저는 식당에 가서 음식을 주문하고 싶어요\"})']},\n",
       " {'source': 'https://wikidocs.net/233344', 'text': ['# 스트리밍 출력']},\n",
       " {'source': 'https://wikidocs.net/233344',\n",
       "  'text': ['stream_response(answer)']},\n",
       " {'source': 'https://wikidocs.net/233344', 'text': ['영어 회화:']},\n",
       " {'source': 'https://wikidocs.net/233344',\n",
       "  'text': ['- Hello, could I see the menu, please?']},\n",
       " {'source': 'https://wikidocs.net/233344',\n",
       "  'text': [\"- I'd like to order the grilled salmon and a side of mashed potatoes.\",\n",
       "   '- Could I have a glass of water as well?',\n",
       "   '- Thank you!']},\n",
       " {'source': 'https://wikidocs.net/233344', 'text': ['한글 해석:']},\n",
       " {'source': 'https://wikidocs.net/233344',\n",
       "  'text': ['- 안녕하세요, 메뉴판 좀 볼 수 있을까요?']},\n",
       " {'source': 'https://wikidocs.net/233344',\n",
       "  'text': ['- 구운 연어와 매시드 포테이토를 주문하고 싶어요.']},\n",
       " {'source': 'https://wikidocs.net/233344', 'text': ['- 물 한 잔도 주실 수 있나요?']},\n",
       " {'source': 'https://wikidocs.net/233344', 'text': ['- 감사합니다!']},\n",
       " {'source': 'https://wikidocs.net/233344',\n",
       "  'text': [\"# 이번에는 question 을 '미국에서 피자 주문'으로 설정하여 실행합니다.\"]},\n",
       " {'source': 'https://wikidocs.net/233344',\n",
       "  'text': ['# 스트리밍 출력을 위한 요청',\n",
       "   'answer = chain.stream({\"question\": \"미국에서 피자 주문\"})']},\n",
       " {'source': 'https://wikidocs.net/233344', 'text': ['# 스트리밍 출력']},\n",
       " {'source': 'https://wikidocs.net/233344',\n",
       "  'text': ['stream_response(answer)']},\n",
       " {'source': 'https://wikidocs.net/233344', 'text': ['영어 회화:']},\n",
       " {'source': 'https://wikidocs.net/233344',\n",
       "  'text': ['- Employee: \"Hello, Tony\\'s Pizza. How can I help you?\"']},\n",
       " {'source': 'https://wikidocs.net/233344',\n",
       "  'text': ['- Customer: \"Hi, I\\'d like to place an order for delivery, please.\"']},\n",
       " {'source': 'https://wikidocs.net/233344',\n",
       "  'text': ['- Employee: \"Sure thing! What would you like to order?\"',\n",
       "   '- Customer: \"I\\'ll have a large pepperoni pizza with extra cheese and a side of garlic bread.\"']},\n",
       " {'source': 'https://wikidocs.net/233344',\n",
       "  'text': ['- Employee: \"Anything to drink?\"']},\n",
       " {'source': 'https://wikidocs.net/233344',\n",
       "  'text': ['- Customer: \"Yes, a 2-liter bottle of Coke, please.\"']},\n",
       " {'source': 'https://wikidocs.net/233344',\n",
       "  'text': ['- Employee: \"Alright, your total comes to $22.50. Can I have your delivery address?\"']},\n",
       " {'source': 'https://wikidocs.net/233344',\n",
       "  'text': ['- Customer: \"It\\'s 742 Evergreen Terrace.\"']},\n",
       " {'source': 'https://wikidocs.net/233344',\n",
       "  'text': ['- Employee: \"Thank you.',\n",
       "   'Your order will be there in about 30-45 minutes.',\n",
       "   'Is there anything else I can help you with?\"',\n",
       "   '- Customer: \"No, that\\'s everything. Thank you!\"']},\n",
       " {'source': 'https://wikidocs.net/233344',\n",
       "  'text': ['- Employee: \"Thank you for choosing Tony\\'s Pizza. Have a great day!\"']},\n",
       " {'source': 'https://wikidocs.net/233344', 'text': ['한글 해석:']},\n",
       " {'source': 'https://wikidocs.net/233344',\n",
       "  'text': ['- 직원: \"안녕하세요, 토니의 피자입니다. 어떻게 도와드릴까요?\"',\n",
       "   '- 고객: \"안녕하세요, 배달 주문하고 싶은데요.\"',\n",
       "   '- 직원: \"네, 무엇을 주문하시겠어요?\"',\n",
       "   '- 고객: \"큰 사이즈의 페퍼로니 피자에 치즈 추가하고, 마늘빵 하나 주세요.\"',\n",
       "   '- 직원: \"음료는 드릴까요?\"',\n",
       "   '- 고객: \"네, 콜라 2리터 한 병 주세요.\"',\n",
       "   '- 직원: \"알겠습니다, 합계는 $22.50입니다. 배달 주소를 알려주시겠어요?\"',\n",
       "   '- 고객: \"742 에버그린 테라스입니다.\"',\n",
       "   '- 직원: \"감사합니다.',\n",
       "   '주문하신 음식은 대략 30-45분 내에 도착할 예정입니다.',\n",
       "   '다른 도움이 필요하신가요?\"',\n",
       "   '- 고객: \"아니요, 이게 다예요. 감사합니다!\"']},\n",
       " {'source': 'https://wikidocs.net/233344',\n",
       "  'text': ['- 직원: \"토니의 피자를 선택해주셔서 감사합니다. 좋은 하루 되세요!\"']},\n",
       " {'source': 'https://wikidocs.net/233344',\n",
       "  'text': ['마지막 편집일시 : 2024년 6월 18일 1:20 오전']},\n",
       " {'source': 'https://wikidocs.net/233344',\n",
       "  'text': ['댓글 0 피드백', '※ 댓글 작성은 로그인이 필요합니다.', '(또는 피드백을 이용해 주세요.)']},\n",
       " {'source': 'https://wikidocs.net/233344', 'text': ['이전글 : 03.']},\n",
       " {'source': 'https://wikidocs.net/233344',\n",
       "  'text': ['OpenAI API 사용(GPT-4o 멀티모달)']},\n",
       " {'source': 'https://wikidocs.net/233344', 'text': ['다음글 : 05.']},\n",
       " {'source': 'https://wikidocs.net/233344', 'text': ['LCEL 인터페이스']},\n",
       " {'source': 'https://wikidocs.net/233344', 'text': ['책갈피']},\n",
       " {'source': 'https://wikidocs.net/233344', 'text': ['이 페이지에 대한 피드백을 남겨주세요']},\n",
       " {'source': 'https://wikidocs.net/233344', 'text': ['댓글을 신고합니다.']},\n",
       " {'source': 'https://wikidocs.net/233345',\n",
       "  'text': ['<랭체인LangChain 노트> - LangChain 한국어 튜토리얼🇰🇷 CH01 LangChain 시작하기']},\n",
       " {'source': 'https://wikidocs.net/233345',\n",
       "  'text': ['01. OpenAI API 키 발급 및 테스트']},\n",
       " {'source': 'https://wikidocs.net/233345', 'text': ['02. LangSmith 추적 설정']},\n",
       " {'source': 'https://wikidocs.net/233345',\n",
       "  'text': ['03. OpenAI API 사용(GPT-4o 멀티모달)']},\n",
       " {'source': 'https://wikidocs.net/233345',\n",
       "  'text': ['04. LangChain Expression Language(LCEL)']},\n",
       " {'source': 'https://wikidocs.net/233345', 'text': ['05. LCEL 인터페이스']},\n",
       " {'source': 'https://wikidocs.net/233345',\n",
       "  'text': ['06. Runnable CH02 프롬프트(Prompt)']},\n",
       " {'source': 'https://wikidocs.net/233345', 'text': ['01. 프롬프트(Prompt)']},\n",
       " {'source': 'https://wikidocs.net/233345',\n",
       "  'text': ['02. 퓨샷 프롬프트(FewShotPromptTemplate)']},\n",
       " {'source': 'https://wikidocs.net/233345', 'text': ['03. LangChain Hub']},\n",
       " {'source': 'https://wikidocs.net/233345',\n",
       "  'text': ['04. 개인화된 프롬프트(Hub에 업로드) CH03 출력 파서(Output Parsers)']},\n",
       " {'source': 'https://wikidocs.net/233345',\n",
       "  'text': ['01. Pydantic 출력 파서(PydanticOutputParser)']},\n",
       " {'source': 'https://wikidocs.net/233345',\n",
       "  'text': ['02. 콤마 구분자 출력 파서(CommaSeparatedListOutputParser)']},\n",
       " {'source': 'https://wikidocs.net/233345',\n",
       "  'text': ['03. 구조화된 출력 파서(StructuredOuputParser)']},\n",
       " {'source': 'https://wikidocs.net/233345',\n",
       "  'text': ['04. JSON 출력 파서(JsonOutputParser)']},\n",
       " {'source': 'https://wikidocs.net/233345',\n",
       "  'text': ['05. 데이터프레임 출력 파서(PandasDataFrameOutputParser)']},\n",
       " {'source': 'https://wikidocs.net/233345',\n",
       "  'text': ['06. 날짜 형식 출력 파서(DatetimeOutputParser)']},\n",
       " {'source': 'https://wikidocs.net/233345',\n",
       "  'text': ['07. 열거형 출력 파서(EnumOutputParser)']},\n",
       " {'source': 'https://wikidocs.net/233345',\n",
       "  'text': ['08. 출력 수정 파서(OutputFixingParser) CH04 모델(Model)']},\n",
       " {'source': 'https://wikidocs.net/233345', 'text': ['01. 다양한 LLM 모델 활용']},\n",
       " {'source': 'https://wikidocs.net/233345', 'text': ['02. 캐싱(Cache)']},\n",
       " {'source': 'https://wikidocs.net/233345',\n",
       "  'text': ['03. 모델 직렬화(Serialization) - 저장 및 불러오기']},\n",
       " {'source': 'https://wikidocs.net/233345', 'text': ['04. 토큰 사용량 확인']},\n",
       " {'source': 'https://wikidocs.net/233345',\n",
       "  'text': ['05. 구글 생성 AI(Google Generative AI)']},\n",
       " {'source': 'https://wikidocs.net/233345',\n",
       "  'text': ['06. 허깅페이스 엔드포인트(HuggingFace Endpoints)']},\n",
       " {'source': 'https://wikidocs.net/233345',\n",
       "  'text': ['07. 허깅페이스 로컬(HuggingFace Local)']},\n",
       " {'source': 'https://wikidocs.net/233345',\n",
       "  'text': ['08. 허깅페이스 파이프라인(HuggingFace Pipeline)']},\n",
       " {'source': 'https://wikidocs.net/233345', 'text': ['09. 올라마(Ollama)']},\n",
       " {'source': 'https://wikidocs.net/233345',\n",
       "  'text': ['10. GPT4ALL CH05 메모리(Memory)']},\n",
       " {'source': 'https://wikidocs.net/233345',\n",
       "  'text': ['01. 대화 버퍼 메모리(ConversationBufferMemory)']},\n",
       " {'source': 'https://wikidocs.net/233345',\n",
       "  'text': ['02. 대화 버퍼 윈도우 메모리(ConversationBufferWindowMemory)']},\n",
       " {'source': 'https://wikidocs.net/233345',\n",
       "  'text': ['03. 대화 토큰 버퍼 메모리(ConversationTokenBufferMemory)']},\n",
       " {'source': 'https://wikidocs.net/233345',\n",
       "  'text': ['04. 대화 엔티티 메모리(ConversationEntityMemory)']},\n",
       " {'source': 'https://wikidocs.net/233345',\n",
       "  'text': ['05. 대화 지식그래프 메모리(ConversationKGMemory)']},\n",
       " {'source': 'https://wikidocs.net/233345',\n",
       "  'text': ['06. 대화 요약 메모리(ConversationSummaryMemory)']},\n",
       " {'source': 'https://wikidocs.net/233345',\n",
       "  'text': ['07. 벡터저장소 검색 메모리(VectorStoreRetrieverMemory)']},\n",
       " {'source': 'https://wikidocs.net/233345',\n",
       "  'text': ['08. LCEL Chain 에 메모리 추가', '09. SQLite 에 대화내용 저장']},\n",
       " {'source': 'https://wikidocs.net/233345',\n",
       "  'text': ['10. RunnableWithMessageHistory에 ChatMessageHistory추가 CH06 문서 로더(Document Loader)']},\n",
       " {'source': 'https://wikidocs.net/233345',\n",
       "  'text': ['01. 도큐먼트(Document) 의 구조']},\n",
       " {'source': 'https://wikidocs.net/233345', 'text': ['02. PDF']},\n",
       " {'source': 'https://wikidocs.net/233345', 'text': ['03. 한글(HWP)']},\n",
       " {'source': 'https://wikidocs.net/233345', 'text': ['04. CSV']},\n",
       " {'source': 'https://wikidocs.net/233345', 'text': ['05. Excel']},\n",
       " {'source': 'https://wikidocs.net/233345', 'text': ['06. Word']},\n",
       " {'source': 'https://wikidocs.net/233345', 'text': ['07. PowerPoint']},\n",
       " {'source': 'https://wikidocs.net/233345',\n",
       "  'text': ['08. 웹 문서(WebBaseLoader)']},\n",
       " {'source': 'https://wikidocs.net/233345', 'text': ['09. 텍스트(TextLoader)']},\n",
       " {'source': 'https://wikidocs.net/233345', 'text': ['10. JSON']},\n",
       " {'source': 'https://wikidocs.net/233345', 'text': ['11. Arxiv']},\n",
       " {'source': 'https://wikidocs.net/233345',\n",
       "  'text': ['13. UpstageLayoutAnalysisLoader']},\n",
       " {'source': 'https://wikidocs.net/233345',\n",
       "  'text': ['14. LlamaParser CH07 텍스트 분할(Text Splitter)']},\n",
       " {'source': 'https://wikidocs.net/233345',\n",
       "  'text': ['01. 문자 텍스트 분할(CharacterTextSplitter)']},\n",
       " {'source': 'https://wikidocs.net/233345',\n",
       "  'text': ['02. 재귀적 문자 텍스트 분할(RecursiveCharacterTextSplitter)']},\n",
       " {'source': 'https://wikidocs.net/233345',\n",
       "  'text': ['03. 토큰 텍스트 분할(TokenTextSplitter)']},\n",
       " {'source': 'https://wikidocs.net/233345',\n",
       "  'text': ['04. 시멘틱 청커(SemanticChunker)']},\n",
       " {'source': 'https://wikidocs.net/233345',\n",
       "  'text': ['05. 코드 분할(Python, Markdown, JAVA, C++, C#, GO, JS, Latex 등)']},\n",
       " {'source': 'https://wikidocs.net/233345',\n",
       "  'text': ['06. 마크다운 헤더 텍스트 분할(MarkdownHeaderTextSplitter)']},\n",
       " {'source': 'https://wikidocs.net/233345',\n",
       "  'text': ['07. HTML 헤더 텍스트 분할(HTMLHeaderTextSplitter)']},\n",
       " {'source': 'https://wikidocs.net/233345',\n",
       "  'text': ['08. 재귀적 JSON 분할(RecursiveJsonSplitter) CH08 임베딩(Embedding)']},\n",
       " {'source': 'https://wikidocs.net/233345', 'text': ['01. OpenAIEmbeddings']},\n",
       " {'source': 'https://wikidocs.net/233345',\n",
       "  'text': ['02. 캐시 임베딩(CacheBackedEmbeddings)']},\n",
       " {'source': 'https://wikidocs.net/233345',\n",
       "  'text': ['03. 허깅페이스 임베딩(HuggingFace Embeddings)']},\n",
       " {'source': 'https://wikidocs.net/233345', 'text': ['04. UpstageEmbeddings']},\n",
       " {'source': 'https://wikidocs.net/233345', 'text': ['05. OllamaEmbeddings']},\n",
       " {'source': 'https://wikidocs.net/233345', 'text': ['06. GPT4ALL 임베딩']},\n",
       " {'source': 'https://wikidocs.net/233345',\n",
       "  'text': ['07. Llama CPP 임베딩 CH09 벡터저장소(VectorStore)']},\n",
       " {'source': 'https://wikidocs.net/233345', 'text': ['01. Chroma']},\n",
       " {'source': 'https://wikidocs.net/233345', 'text': ['02. FAISS']},\n",
       " {'source': 'https://wikidocs.net/233345',\n",
       "  'text': ['03. Pinecone CH10 검색기(Retriever)']},\n",
       " {'source': 'https://wikidocs.net/233345',\n",
       "  'text': ['01. 벡터저장소 지원 검색기(VectorStore-backed Retriever)']},\n",
       " {'source': 'https://wikidocs.net/233345',\n",
       "  'text': ['02. 문맥 압축 검색기(ContextualCompressionRetriever)']},\n",
       " {'source': 'https://wikidocs.net/233345',\n",
       "  'text': ['03. 앙상블 검색기(EnsembleRetriever)']},\n",
       " {'source': 'https://wikidocs.net/233345',\n",
       "  'text': ['04. 긴 문맥 재정렬(LongContextReorder)']},\n",
       " {'source': 'https://wikidocs.net/233345',\n",
       "  'text': ['05. 상위 문서 검색기(ParentDocumentRetriever)']},\n",
       " {'source': 'https://wikidocs.net/233345',\n",
       "  'text': ['06. 다중 쿼리 검색기(MultiQueryRetriever)']},\n",
       " {'source': 'https://wikidocs.net/233345',\n",
       "  'text': ['07. 다중 벡터저장소 검색기(MultiVectorRetriever)']},\n",
       " {'source': 'https://wikidocs.net/233345',\n",
       "  'text': ['08. 셀프 쿼리 검색기(SelfQueryRetriever)']},\n",
       " {'source': 'https://wikidocs.net/233345',\n",
       "  'text': ['09. 시간 가중 벡터저장소 검색기(TimeWeightedVectorStoreRetriever)']},\n",
       " {'source': 'https://wikidocs.net/233345',\n",
       "  'text': ['10. 한글 형태소 분석기(Kiwi, Kkma, Okt) + BM25 검색기 CH11 리랭커(Reranker)']},\n",
       " {'source': 'https://wikidocs.net/233345',\n",
       "  'text': ['01. Cross Encoder Reranker']},\n",
       " {'source': 'https://wikidocs.net/233345', 'text': ['02. Cohere Reranker']},\n",
       " {'source': 'https://wikidocs.net/233345', 'text': ['03. Jina Reranker']},\n",
       " {'source': 'https://wikidocs.net/233345',\n",
       "  'text': ['04. FlashRank Reranker CH12 Retrieval Augmented Generation(RAG)']},\n",
       " {'source': 'https://wikidocs.net/233345',\n",
       "  'text': ['01. PDF 문서 기반 QA(Question-Answer)']},\n",
       " {'source': 'https://wikidocs.net/233345',\n",
       "  'text': ['02. 네이버 뉴스기사 QA(Question-Answer)']},\n",
       " {'source': 'https://wikidocs.net/233345',\n",
       "  'text': ['03. RAG 의 기능별 다양한 모듈 활용기']},\n",
       " {'source': 'https://wikidocs.net/233345',\n",
       "  'text': ['04. RAPTOR: 긴 문맥 요약(Long Context Summary)']},\n",
       " {'source': 'https://wikidocs.net/233345',\n",
       "  'text': ['05. 대화내용을 기억하는 RAG 체인 CH13 LangChain Expression Language(LCEL)']},\n",
       " {'source': 'https://wikidocs.net/233345',\n",
       "  'text': ['01. RunnablePassthrough: 데이터 전달']},\n",
       " {'source': 'https://wikidocs.net/233345',\n",
       "  'text': ['02. Runnable 구조(그래프) 확인']},\n",
       " {'source': 'https://wikidocs.net/233345',\n",
       "  'text': ['03. RunnableLambda: 사용자 정의 함수']},\n",
       " {'source': 'https://wikidocs.net/233345',\n",
       "  'text': ['04. RunnableBranch: 라우팅(Routing)']},\n",
       " {'source': 'https://wikidocs.net/233345',\n",
       "  'text': ['05. RunnableParallel: 병렬 처리']},\n",
       " {'source': 'https://wikidocs.net/233345',\n",
       "  'text': ['06. configurable_fields, configurable_alternatives 07. @chain 데코레이터로 Runnable 생성',\n",
       "   '08. RunnableWithMessageHistory']},\n",
       " {'source': 'https://wikidocs.net/233345',\n",
       "  'text': ['09. 사용자 정의 제네레이터(generator)']},\n",
       " {'source': 'https://wikidocs.net/233345',\n",
       "  'text': ['10. Runtime Arguments 바인딩']},\n",
       " {'source': 'https://wikidocs.net/233345',\n",
       "  'text': ['11. 폴백(fallback) 모델 지정 CH14 체인(Chains)']},\n",
       " {'source': 'https://wikidocs.net/233345', 'text': ['01. 문서 요약']},\n",
       " {'source': 'https://wikidocs.net/233345',\n",
       "  'text': ['02. SQL CH15 에이전트(Agent)']},\n",
       " {'source': 'https://wikidocs.net/233345', 'text': ['01. Agent 사용법 톺아보기']},\n",
       " {'source': 'https://wikidocs.net/233345',\n",
       "  'text': ['02. 도구를 활용한 토론 에이전트(Two Agent Debates with Tools) CH16 파인튜닝(Fine Tuning)']},\n",
       " {'source': 'https://wikidocs.net/233345', 'text': ['CH17 LangGraph']},\n",
       " {'source': 'https://wikidocs.net/233345',\n",
       "  'text': ['01. Chain of Table for Multiple Tables']},\n",
       " {'source': 'https://wikidocs.net/233345',\n",
       "  'text': ['Published with WikiDocs']},\n",
       " {'source': 'https://wikidocs.net/233345',\n",
       "  'text': ['<랭체인LangChain 노트> - Lang…']},\n",
       " {'source': 'https://wikidocs.net/233345', 'text': ['CH01 LangChain 시작하기']},\n",
       " {'source': 'https://wikidocs.net/233345', 'text': ['05. LCEL 인터페이스']},\n",
       " {'source': 'https://wikidocs.net/233345', 'text': ['위키독스']},\n",
       " {'source': 'https://wikidocs.net/233345', 'text': ['05. LCEL 인터페이스']},\n",
       " {'source': 'https://wikidocs.net/233345', 'text': ['LCEL 인터페이스']},\n",
       " {'source': 'https://wikidocs.net/233345',\n",
       "  'text': ['사용자 정의 체인을 가능한 쉽게 만들 수 있도록, Runnable 프로토콜을 구현했습니다.',\n",
       "   'Runnable 프로토콜은 대부분의 컴포넌트에 구현되어 있습니다.']},\n",
       " {'source': 'https://wikidocs.net/233345',\n",
       "  'text': ['이는 표준 인터페이스로, 사용자 정의 체인을 정의하고 표준 방식으로 호출하는 것을 쉽게 만듭니다.',\n",
       "   '표준 인터페이스에는 다음이 포함됩니다.']},\n",
       " {'source': 'https://wikidocs.net/233345',\n",
       "  'text': ['stream: 응답의 청크를 스트리밍합니다.']},\n",
       " {'source': 'https://wikidocs.net/233345',\n",
       "  'text': ['invoke: 입력에 대해 체인을 호출합니다.', 'batch: 입력 목록에 대해 체인을 호출합니다.']},\n",
       " {'source': 'https://wikidocs.net/233345', 'text': ['비동기 메소드도 있습니다.']},\n",
       " {'source': 'https://wikidocs.net/233345',\n",
       "  'text': ['astream: 비동기적으로 응답의 청크를 스트리밍합니다.']},\n",
       " {'source': 'https://wikidocs.net/233345',\n",
       "  'text': ['ainvoke: 비동기적으로 입력에 대해 체인을 호출합니다.']},\n",
       " {'source': 'https://wikidocs.net/233345',\n",
       "  'text': ['abatch: 비동기적으로 입력 목록에 대해 체인을 호출합니다.']},\n",
       " {'source': 'https://wikidocs.net/233345',\n",
       "  'text': ['astream_log: 최종 응답뿐만 아니라 발생하는 중간 단계를 스트리밍합니다.']},\n",
       " {'source': 'https://wikidocs.net/233345',\n",
       "  'text': ['# API KEY를 환경변수로 관리하기 위한 설정 파일']},\n",
       " {'source': 'https://wikidocs.net/233345',\n",
       "  'text': ['from dotenv import load_dotenv',\n",
       "   '# API KEY 정보로드',\n",
       "   'load_dotenv()']},\n",
       " {'source': 'https://wikidocs.net/233345', 'text': ['True']},\n",
       " {'source': 'https://wikidocs.net/233345', 'text': ['# LangSmith 추적을 설정합니다.']},\n",
       " {'source': 'https://wikidocs.net/233345',\n",
       "  'text': ['https://smith.langchain.com']},\n",
       " {'source': 'https://wikidocs.net/233345',\n",
       "  'text': ['from langchain_teddynote import logging']},\n",
       " {'source': 'https://wikidocs.net/233345', 'text': ['# 프로젝트 이름을 입력합니다.']},\n",
       " {'source': 'https://wikidocs.net/233345',\n",
       "  'text': ['logging.langsmith(\"CH01-Basic\")']},\n",
       " {'source': 'https://wikidocs.net/233345',\n",
       "  'text': ['LCEL 문법을 사용하여 chain 을 생성합니다.']},\n",
       " {'source': 'https://wikidocs.net/233345',\n",
       "  'text': ['from langchain_openai import ChatOpenAI',\n",
       "   'from langchain_core.prompts import PromptTemplate',\n",
       "   'from langchain_core.output_parsers import StrOutputParser']},\n",
       " {'source': 'https://wikidocs.net/233345',\n",
       "  'text': ['# ChatOpenAI 모델을 인스턴스화합니다.']},\n",
       " {'source': 'https://wikidocs.net/233345', 'text': ['model = ChatOpenAI()']},\n",
       " {'source': 'https://wikidocs.net/233345',\n",
       "  'text': ['# 주어진 토픽에 대한 농담을 요청하는 프롬프트 템플릿을 생성합니다.']},\n",
       " {'source': 'https://wikidocs.net/233345',\n",
       "  'text': ['prompt = PromptTemplate.from_template(\"{topic} 에 대하여 3문장으로 설명해줘.\")']},\n",
       " {'source': 'https://wikidocs.net/233345',\n",
       "  'text': ['# 프롬프트와 모델을 연결하여 대화 체인을 생성합니다.']},\n",
       " {'source': 'https://wikidocs.net/233345',\n",
       "  'text': ['chain = prompt | model | StrOutputParser()']},\n",
       " {'source': 'https://wikidocs.net/233345', 'text': ['stream: 실시간 출력']},\n",
       " {'source': 'https://wikidocs.net/233345',\n",
       "  'text': ['이 함수는 chain.stream 메서드를 사용하여 주어진 토픽에 대한 데이터 스트림을 생성하고, 이 스트림을 반복하여 각 데이터의 내용(content)을 즉시 출력합니다.']},\n",
       " {'source': 'https://wikidocs.net/233345',\n",
       "  'text': ['end=\"\" 인자는 출력 후 줄바꿈을 하지 않도록 설정하며, flush=True 인자는 출력 버퍼를 즉시 비우도록 합니다.']},\n",
       " {'source': 'https://wikidocs.net/233345',\n",
       "  'text': [\"# chain.stream 메서드를 사용하여 '멀티모달' 토픽에 대한 스트림을 생성하고 반복합니다.\",\n",
       "   'for token in chain.stream({\"topic\": \"멀티모달\"}):']},\n",
       " {'source': 'https://wikidocs.net/233345',\n",
       "  'text': ['# 스트림에서 받은 데이터의 내용을 출력합니다.', '줄바꿈 없이 이어서 출력하고, 버퍼를 즉시 비웁니다.']},\n",
       " {'source': 'https://wikidocs.net/233345',\n",
       "  'text': ['print(token, end=\"\", flush=True)']},\n",
       " {'source': 'https://wikidocs.net/233345',\n",
       "  'text': ['멀티모달은 여러 가지 다른 형태의 커뮤니케이션 수단을 통해 정보를 전달하고 상호작용하는 기술을 의미합니다.',\n",
       "   '예를 들어 음성, 텍스트, 이미지, 동영상 등 다양한 매체를 활용하여 사용자와 상호작용할 수 있습니다.']},\n",
       " {'source': 'https://wikidocs.net/233345',\n",
       "  'text': ['멀티모달 기술은 사용자 경험을 향상시키고 정보 전달의 효율성을 높이는데 도움을 줄 수 있습니다.']},\n",
       " {'source': 'https://wikidocs.net/233345', 'text': ['invoke: 호출']},\n",
       " {'source': 'https://wikidocs.net/233345',\n",
       "  'text': ['chain 객체의 invoke 메서드는 주제를 인자로 받아 해당 주제에 대한 처리를 수행합니다.',\n",
       "   \"# chain 객체의 invoke 메서드를 호출하고, 'ChatGPT'라는 주제로 딕셔너리를 전달합니다.\"]},\n",
       " {'source': 'https://wikidocs.net/233345',\n",
       "  'text': ['chain.invoke({\"topic\": \"ChatGPT\"})']},\n",
       " {'source': 'https://wikidocs.net/233345',\n",
       "  'text': [\"'ChatGPT는 OpenAI에서 개발한 대화형 인공지능 모델로, 다양한 주제에 대한 대화를 자연스럽게 이어나갈 수 있습니다.\",\n",
       "   '사용자들은 ChatGPT를 통해 질문에 답변을 받거나 대화를 이어가며 새로운 정보를 습득할 수 있습니다.',\n",
       "   \"또한 ChatGPT는 사용자의 입력을 학습하여 점차적으로 더욱 유창하고 자연스러운 대화를 제공합니다.'\"]},\n",
       " {'source': 'https://wikidocs.net/233345', 'text': ['batch: 배치(단위 실행)']},\n",
       " {'source': 'https://wikidocs.net/233345',\n",
       "  'text': ['함수 chain.batch는 여러 개의 딕셔너리를 포함하는 리스트를 인자로 받아, 각 딕셔너리에 있는 topic 키의 값을 사용하여 일괄 처리를 수행합니다.']},\n",
       " {'source': 'https://wikidocs.net/233345',\n",
       "  'text': ['# 주어진 토픽 리스트를 batch 처리하는 함수 호출']},\n",
       " {'source': 'https://wikidocs.net/233345',\n",
       "  'text': ['chain.batch([{\"topic\": \"ChatGPT\"}, {\"topic\": \"Instagram\"}])']},\n",
       " {'source': 'https://wikidocs.net/233345',\n",
       "  'text': [\"['ChatGPT는 인공지능 챗봇으로 자연어 처리 기술을 사용하여 대화를 수행합니다.\"]},\n",
       " {'source': 'https://wikidocs.net/233345',\n",
       "  'text': ['사용자들과 자연스럽게 상호작용하며 다양한 주제에 대해 대화할 수 있습니다.',\n",
       "   \"ChatGPT는 정보 제공, 질문 응답, 상담 및 엔터테인먼트 등 다양한 용도로 활용될 수 있습니다.', 'Instagram은 사진과 동영상을 공유하고 다른 사람들과 소통하는 소셜 미디어 플랫폼이다.\",\n",
       "   '해시태그를 통해 관심사나 주제별로 사진을 검색하고 팔로워들과 소통할 수 있다.',\n",
       "   \"인기 있는 인플루언서나 브랜드가 활발하게 활동하는 플랫폼으로 세계적으로 인기가 높다.']\"]},\n",
       " {'source': 'https://wikidocs.net/233345',\n",
       "  'text': ['max_concurrency 매개변수를 사용하여 동시 요청 수를 설정할 수 있습니다',\n",
       "   'config 딕셔너리는 max_concurrency 키를 통해 동시에 처리할 수 있는 최대 작업 수를 설정합니다.',\n",
       "   '여기서는 최대 3개의 작업을 동시에 처리하도록 설정되어 있습니다.']},\n",
       " {'source': 'https://wikidocs.net/233345', 'text': ['chain.batch(']},\n",
       " {'source': 'https://wikidocs.net/233345', 'text': ['[']},\n",
       " {'source': 'https://wikidocs.net/233345', 'text': ['{\"topic\": \"ChatGPT\"},']},\n",
       " {'source': 'https://wikidocs.net/233345',\n",
       "  'text': ['{\"topic\": \"Instagram\"},']},\n",
       " {'source': 'https://wikidocs.net/233345', 'text': ['{\"topic\": \"멀티모달\"},']},\n",
       " {'source': 'https://wikidocs.net/233345', 'text': ['{\"topic\": \"프로그래밍\"},']},\n",
       " {'source': 'https://wikidocs.net/233345', 'text': ['{\"topic\": \"머신러닝\"},']},\n",
       " {'source': 'https://wikidocs.net/233345', 'text': ['],']},\n",
       " {'source': 'https://wikidocs.net/233345',\n",
       "  'text': ['config={\"max_concurrency\": 3},']},\n",
       " {'source': 'https://wikidocs.net/233345', 'text': [')']},\n",
       " {'source': 'https://wikidocs.net/233345',\n",
       "  'text': [\"['ChatGPT는 인공지능 챗봇으로, 자연어 처리 기술을 사용하여 대화 상대와 상호작용합니다.\",\n",
       "   '사용자의 질문에 응답하고 대화를 이어가며 다양한 주제에 대해 대화할 수 있습니다.',\n",
       "   \"ChatGPT는 사용자와 자연스럽게 대화를 나누는 데 도움을 줄 뿐만 아니라 정보를 제공하고 문제 해결을 돕기도 합니다.', 'Instagram은 사진과 동영상을 공유하고 다른 사람들과 소통할 수 있는 소셜 미디어 플랫폼이다.\",\n",
       "   '다양한 필터와 편집 기능을 제공하여 사용자가 쉽게 멋진 사진을 업로드할 수 있으며 해시태그를 통해 관심사에 맞는 콘텐츠를 찾을 수 있다.',\n",
       "   \"인기 있는 인플루언서들의 활동과 광고가 많이 이루어지는 플랫폼이기도 하다.', '멀티모달은 여러 가지의 다른 형태의 정보를 함께 제공하거나 처리하는 기술이다.\",\n",
       "   '이는 텍스트, 이미지, 음성, 비디오 등 여러 형태의 데이터를 통합하여 효과적으로 전달하고 상호작용할 수 있게 한다.',\n",
       "   \"멀티모달은 사용자 경험을 향상시키고 정보를 보다 쉽게 이해하고 활용할 수 있도록 도와준다.', '프로그래밍은 컴퓨터에게 실행할 작업을 지시하는 일종의 커뮤니케이션 방법이다.\",\n",
       "   '이를 위해 프로그래머가 사용하는 언어는 컴퓨터가 이해할 수 있는 형태여야 하며, 문법과 로직을 통해 원하는 결과를 얻을 수 있다.',\n",
       "   \"프로그래밍을 통해 소프트웨어를 개발하고 문제를 해결하는 등 다양한 분야에서 활용할 수 있다.', '머신러닝은 컴퓨터 시스템이 데이터에서 학습하고 패턴을 발견하여 예측하거나 결정을 내리는 인공지능의 한 분야입니다.\",\n",
       "   '이를 통해 컴퓨터는 사람의 개입 없이 스스로 학습하고 문제를 해결할 수 있습니다.',\n",
       "   \"머신러닝은 이미지 및 음성 인식, 자율 주행 자동차, 헬스케어 등 다양한 분야에서 활용되고 있습니다.']\"]},\n",
       " {'source': 'https://wikidocs.net/233345', 'text': ['async stream: 비동기 스트림']},\n",
       " {'source': 'https://wikidocs.net/233345',\n",
       "  'text': ['함수 chain.astream은 비동기 스트림을 생성하며, 주어진 토픽에 대한 메시지를 비동기적으로 처리합니다.',\n",
       "   '비동기 for 루프(async for)를 사용하여 스트림에서 메시지를 순차적으로 받아오고, print 함수를 통해 메시지의 내용(s.content)을 즉시 출력합니다.']},\n",
       " {'source': 'https://wikidocs.net/233345',\n",
       "  'text': ['end=\"\"는 출력 후 줄바꿈을 하지 않도록 설정하며, flush=True는 출력 버퍼를 강제로 비워 즉시 출력되도록 합니다.']},\n",
       " {'source': 'https://wikidocs.net/233345',\n",
       "  'text': [\"# 비동기 스트림을 사용하여 'YouTube' 토픽의 메시지를 처리합니다.\"]},\n",
       " {'source': 'https://wikidocs.net/233345',\n",
       "  'text': ['async for token in chain.astream({\"topic\": \"YouTube\"}):']},\n",
       " {'source': 'https://wikidocs.net/233345', 'text': ['# 메시지 내용을 출력합니다.']},\n",
       " {'source': 'https://wikidocs.net/233345',\n",
       "  'text': ['줄바꿈 없이 바로 출력하고 버퍼를 비웁니다.']},\n",
       " {'source': 'https://wikidocs.net/233345',\n",
       "  'text': ['print(token, end=\"\", flush=True)']},\n",
       " {'source': 'https://wikidocs.net/233345',\n",
       "  'text': ['YouTube 는 동영상을 공유하고 시청할 수 있는 온라인 동영상 플랫폼이다.',\n",
       "   '누구나 자신의 동영상을 업로드하여 다른 사람들과 공유할 수 있고, 영상 콘텐츠를 시청하며 다양한 정보나 즐길거리를 찾을 수 있다.',\n",
       "   '또한 유명한 크리에이터들의 영상을 통해 엔터테인먼트와 정보를 얻을 수 있다.']},\n",
       " {'source': 'https://wikidocs.net/233345', 'text': ['async invoke: 비동기 호출']},\n",
       " {'source': 'https://wikidocs.net/233345',\n",
       "  'text': ['chain 객체의 ainvoke 메서드는 비동기적으로 주어진 인자를 사용하여 작업을 수행합니다.',\n",
       "   '여기서는 topic이라는 키와 NVDA(엔비디아의 티커) 라는 값을 가진 딕셔너리를 인자로 전달하고 있습니다.',\n",
       "   '이 메서드는 특정 토픽에 대한 처리를 비동기적으로 요청하는 데 사용될 수 있습니다.',\n",
       "   \"# 비동기 체인 객체의 'ainvoke' 메서드를 호출하여 'NVDA' 토픽을 처리합니다.\"]},\n",
       " {'source': 'https://wikidocs.net/233345',\n",
       "  'text': ['my_process = chain.ainvoke({\"topic\": \"NVDA\"})']},\n",
       " {'source': 'https://wikidocs.net/233345',\n",
       "  'text': ['# 비동기로 처리되는 프로세스가 완료될 때까지 기다립니다.']},\n",
       " {'source': 'https://wikidocs.net/233345', 'text': ['await my_process']},\n",
       " {'source': 'https://wikidocs.net/233345',\n",
       "  'text': [\"'NVDA는 엔비디아의 주식 코드로, 미국의 반도체 기업인 엔비디아(NVIDIA)의 주식을 말합니다.\",\n",
       "   '엔비디아는 그래픽 처리 유닛(GPU)을 전문으로 하는 기업으로, 인공지능, 가상현실, 자율주행차 등 다양한 분야에서 기술을 제공하고 있습니다.']},\n",
       " {'source': 'https://wikidocs.net/233345',\n",
       "  'text': [\"NVDA 주식은 기술 산업의 성장과 함께 높은 수익을 창출하고 있습니다.'\"]},\n",
       " {'source': 'https://wikidocs.net/233345', 'text': ['async batch: 비동기 배치']},\n",
       " {'source': 'https://wikidocs.net/233345',\n",
       "  'text': ['함수 abatch는 비동기적으로 일련의 작업을 일괄 처리합니다.']},\n",
       " {'source': 'https://wikidocs.net/233345',\n",
       "  'text': ['이 예시에서는 chain 객체의 abatch 메서드를 사용하여 topic 에 대한 작업을 비동기적으로 처리하고 있습니다.']},\n",
       " {'source': 'https://wikidocs.net/233345',\n",
       "  'text': ['await 키워드는 해당 비동기 작업이 완료될 때까지 기다리는 데 사용됩니다.']},\n",
       " {'source': 'https://wikidocs.net/233345',\n",
       "  'text': ['# 주어진 토픽에 대해 비동기적으로 일괄 처리를 수행합니다.']},\n",
       " {'source': 'https://wikidocs.net/233345',\n",
       "  'text': ['my_abatch_process = chain.abatch(']},\n",
       " {'source': 'https://wikidocs.net/233345',\n",
       "  'text': ['[{\"topic\": \"YouTube\"}, {\"topic\": \"Instagram\"}, {\"topic\": \"Facebook\"}]']},\n",
       " {'source': 'https://wikidocs.net/233345', 'text': [')']},\n",
       " {'source': 'https://wikidocs.net/233345',\n",
       "  'text': ['# 비동기로 처리되는 일괄 처리 프로세스가 완료될 때까지 기다립니다.']},\n",
       " {'source': 'https://wikidocs.net/233345',\n",
       "  'text': ['await my_abatch_process']},\n",
       " {'source': 'https://wikidocs.net/233345',\n",
       "  'text': [\"['YouTube는 동영상 공유 플랫폼으로 사용자들이 영상을 업로드하고 시청할 수 있는 서비스입니다.\",\n",
       "   '다양한 콘텐츠를 제공하며 사용자는 무료로 영상을 시청할 수 있습니다.']},\n",
       " {'source': 'https://wikidocs.net/233345',\n",
       "  'text': [\"유명한 유튜버들이 활동하고 수익을 창출할 수 있는 플랫폼으로도 알려져 있습니다.', '인스타그램은 사진과 동영상을 공유하는 소셜 미디어 플랫폼으로, 사용자들은 다양한 필터와 효과를 이용해 자신의 콘텐츠를 멋지게 꾸밀 수 있습니다.\",\n",
       "   '또한 팔로워들과 소통하고, 다른 사용자의 게시물을 좋아하거나 댓글을 남기며 커뮤니케이션을 할 수 있습니다.',\n",
       "   \"인스타그램은 비즈니스나 개인 브랜딩에도 활용되며, 많은 사람들이 일상 속 소소한 순간부터 특별한 순간까지를 공유하고 있습니다.', 'Facebook은 미국의 소셜 네트워크 서비스로, 사용자들이 커뮤니케이션하고 정보를 공유할 수 있는 플랫폼이다.\",\n",
       "   '현재 전 세계적으로 약 30억 명 이상의 사용자가 활동하고 있으며, 광고 및 비즈니스 활동에도 널리 활용되고 있다.']},\n",
       " {'source': 'https://wikidocs.net/233345',\n",
       "  'text': [\"또한 개인정보 보호 문제와 가짜 뉴스 등 여러 논란을 빚어왔으나, 여전히 많은 사람들이 이용하고 있는 대표적인 SNS 서비스이다.']\"]},\n",
       " {'source': 'https://wikidocs.net/233345', 'text': ['Parallel: 병렬성']},\n",
       " {'source': 'https://wikidocs.net/233345',\n",
       "  'text': ['LangChain Expression Language가 병렬 요청을 지원하는 방법을 살펴봅시다.',\n",
       "   '예를 들어, RunnableParallel을 사용할 때(자주 사전 형태로 작성됨), 각 요소를 병렬로 실행합니다.',\n",
       "   'langchain_core.runnables 모듈의 RunnableParallel 클래스를 사용하여 두 가지 작업을 병렬로 실행하는 예시를 보여줍니다.',\n",
       "   'ChatPromptTemplate.from_template 메서드를 사용하여 주어진 country에 대한 수도 와 면적 을 구하는 두 개의 체인(chain1, chain2)을 만듭니다.',\n",
       "   '이 체인들은 각각 model과 파이프(|) 연산자를 통해 연결됩니다.',\n",
       "   '마지막으로, RunnableParallel 클래스를 사용하여 이 두 체인을 capital와 area이라는 키로 결합하여 동시에 실행할 수 있는 combined 객체를 생성합니다.']},\n",
       " {'source': 'https://wikidocs.net/233345',\n",
       "  'text': ['from langchain_core.runnables import RunnableParallel']},\n",
       " {'source': 'https://wikidocs.net/233345',\n",
       "  'text': ['# {country} 의 수도를 물어보는 체인을 생성합니다.', 'chain1 = (']},\n",
       " {'source': 'https://wikidocs.net/233345',\n",
       "  'text': ['PromptTemplate.from_template(\"{country} 의 수도는 어디야?\")']},\n",
       " {'source': 'https://wikidocs.net/233345', 'text': ['| model']},\n",
       " {'source': 'https://wikidocs.net/233345', 'text': ['| StrOutputParser()']},\n",
       " {'source': 'https://wikidocs.net/233345', 'text': [')']},\n",
       " {'source': 'https://wikidocs.net/233345',\n",
       "  'text': ['# {country} 의 면적을 물어보는 체인을 생성합니다.']},\n",
       " {'source': 'https://wikidocs.net/233345', 'text': ['chain2 = (']},\n",
       " {'source': 'https://wikidocs.net/233345',\n",
       "  'text': ['PromptTemplate.from_template(\"{country} 의 면적은 얼마야?\")']},\n",
       " {'source': 'https://wikidocs.net/233345', 'text': ['| model']},\n",
       " {'source': 'https://wikidocs.net/233345', 'text': ['| StrOutputParser()']},\n",
       " {'source': 'https://wikidocs.net/233345', 'text': [')']},\n",
       " {'source': 'https://wikidocs.net/233345',\n",
       "  'text': ['# 위의 2개 체인을 동시에 생성하는 병렬 실행 체인을 생성합니다.']},\n",
       " {'source': 'https://wikidocs.net/233345',\n",
       "  'text': ['combined = RunnableParallel(capital=chain1, area=chain2)']},\n",
       " {'source': 'https://wikidocs.net/233345',\n",
       "  'text': ['chain1.invoke() 함수는 chain1 객체의 invoke 메서드를 호출합니다.',\n",
       "   '이때, country이라는 키에 대한민국라는 값을 가진 딕셔너리를 인자로 전달합니다.']},\n",
       " {'source': 'https://wikidocs.net/233345',\n",
       "  'text': ['# chain1 를 실행합니다.', 'chain1.invoke({\"country\": \"대한민국\"})']},\n",
       " {'source': 'https://wikidocs.net/233345', 'text': [\"'대한민국의 수도는 서울이다.'\"]},\n",
       " {'source': 'https://wikidocs.net/233345',\n",
       "  'text': ['이번에는 chain2.invoke() 를 호출합니다.']},\n",
       " {'source': 'https://wikidocs.net/233345',\n",
       "  'text': ['country 키에 다른 국가인 미국 을 전달합니다.']},\n",
       " {'source': 'https://wikidocs.net/233345', 'text': ['# chain2 를 실행합니다.']},\n",
       " {'source': 'https://wikidocs.net/233345',\n",
       "  'text': ['chain2.invoke({\"country\": \"미국\"})']},\n",
       " {'source': 'https://wikidocs.net/233345',\n",
       "  'text': [\"'미국의 면적은 약 9,826,675 제곱 킬로미터입니다.'\"]},\n",
       " {'source': 'https://wikidocs.net/233345',\n",
       "  'text': ['combined 객체의 invoke 메서드는 주어진 country에 대한 처리를 수행합니다.']},\n",
       " {'source': 'https://wikidocs.net/233345',\n",
       "  'text': ['이 예제에서는 대한민국라는 주제를 invoke 메서드에 전달하여 실행합니다.']},\n",
       " {'source': 'https://wikidocs.net/233345', 'text': ['# 병렬 실행 체인을 실행합니다.']},\n",
       " {'source': 'https://wikidocs.net/233345',\n",
       "  'text': ['combined.invoke({\"country\": \"대한민국\"})']},\n",
       " {'source': 'https://wikidocs.net/233345',\n",
       "  'text': [\"{'capital': '대한민국의 수도는 서울입니다.', 'area': '대한민국의 면적은 약 100,363.4 제곱 킬로미터 입니다.'}\"]},\n",
       " {'source': 'https://wikidocs.net/233345', 'text': ['배치에서의 병렬 처리']},\n",
       " {'source': 'https://wikidocs.net/233345',\n",
       "  'text': ['병렬 처리는 다른 실행 가능한 코드와 결합될 수 있습니다.']},\n",
       " {'source': 'https://wikidocs.net/233345',\n",
       "  'text': ['배치와 병렬 처리를 사용해 보도록 합시다.']},\n",
       " {'source': 'https://wikidocs.net/233345',\n",
       "  'text': ['chain1.batch 함수는 여러 개의 딕셔너리를 포함하는 리스트를 인자로 받아, 각 딕셔너리에 있는 \"topic\" 키에 해당하는 값을 처리합니다.']},\n",
       " {'source': 'https://wikidocs.net/233345',\n",
       "  'text': ['이 예시에서는 \"대한민국\"와 \"미국\"라는 두 개의 토픽을 배치 처리하고 있습니다.']},\n",
       " {'source': 'https://wikidocs.net/233345', 'text': ['# 배치 처리를 수행합니다.']},\n",
       " {'source': 'https://wikidocs.net/233345',\n",
       "  'text': ['chain1.batch([{\"country\": \"대한민국\"}, {\"country\": \"미국\"}])']},\n",
       " {'source': 'https://wikidocs.net/233345',\n",
       "  'text': [\"['대한민국의 수도는 서울이에요.', '미국의 수도는 워싱턴 D.C.입니다.']\"]},\n",
       " {'source': 'https://wikidocs.net/233345',\n",
       "  'text': ['chain2.batch 함수는 여러 개의 딕셔너리를 리스트 형태로 받아, 일괄 처리(batch)를 수행합니다.']},\n",
       " {'source': 'https://wikidocs.net/233345',\n",
       "  'text': ['이 예시에서는 대한민국와 미국라는 두 가지 국가에 대한 처리를 요청합니다.']},\n",
       " {'source': 'https://wikidocs.net/233345', 'text': ['# 배치 처리를 수행합니다.']},\n",
       " {'source': 'https://wikidocs.net/233345',\n",
       "  'text': ['chain2.batch([{\"country\": \"대한민국\"}, {\"country\": \"미국\"}])']},\n",
       " {'source': 'https://wikidocs.net/233345',\n",
       "  'text': [\"['대한민국의 총 면적은 약 100,363 제곱킬로미터 입니다.', '미국의 면적은 약 9,834,000km² 입니다.']\"]},\n",
       " {'source': 'https://wikidocs.net/233345',\n",
       "  'text': ['combined.batch 함수는 주어진 데이터를 배치로 처리하는 데 사용됩니다.']},\n",
       " {'source': 'https://wikidocs.net/233345',\n",
       "  'text': ['이 예시에서는 두 개의 딕셔너리 객체를 포함하는 리스트를 인자로 받아 각각 대한민국와 미국 두 나라에 대한 데이터를 배치 처리합니다.']},\n",
       " {'source': 'https://wikidocs.net/233345', 'text': ['# 주어진 데이터를 배치로 처리합니다.']},\n",
       " {'source': 'https://wikidocs.net/233345',\n",
       "  'text': ['combined.batch([{\"country\": \"대한민국\"}, {\"country\": \"미국\"}])']},\n",
       " {'source': 'https://wikidocs.net/233345',\n",
       "  'text': [\"[{'capital': '대한민국의 수도는 서울이다.', 'area': '대한민국의 면적은 약 100,363km² 입니다.'}, {'capital': '미국의 수도는 워싱턴 D.C.입니다.', 'area': '미국의 면적은 약 9,833,520 km² 입니다.'}]\"]},\n",
       " {'source': 'https://wikidocs.net/233345',\n",
       "  'text': ['마지막 편집일시 : 2024년 6월 17일 8:04 오후']},\n",
       " {'source': 'https://wikidocs.net/233345', 'text': ['댓글 0 피드백']},\n",
       " {'source': 'https://wikidocs.net/233345', 'text': ['※ 댓글 작성은 로그인이 필요합니다.']},\n",
       " {'source': 'https://wikidocs.net/233345', 'text': ['(또는 피드백을 이용해 주세요.)']},\n",
       " {'source': 'https://wikidocs.net/233345', 'text': ['이전글 : 04.']},\n",
       " {'source': 'https://wikidocs.net/233345',\n",
       "  'text': ['LangChain Expression Language(LCEL)']},\n",
       " {'source': 'https://wikidocs.net/233345', 'text': ['다음글 : 06.']},\n",
       " {'source': 'https://wikidocs.net/233345', 'text': ['Runnable']},\n",
       " {'source': 'https://wikidocs.net/233345', 'text': ['책갈피']},\n",
       " {'source': 'https://wikidocs.net/233345', 'text': ['이 페이지에 대한 피드백을 남겨주세요']},\n",
       " {'source': 'https://wikidocs.net/233345', 'text': ['댓글을 신고합니다.']},\n",
       " {'source': 'https://wikidocs.net/250954',\n",
       "  'text': ['<랭체인LangChain 노트> - LangChain 한국어 튜토리얼🇰🇷 CH01 LangChain 시작하기']},\n",
       " {'source': 'https://wikidocs.net/250954',\n",
       "  'text': ['01. OpenAI API 키 발급 및 테스트']},\n",
       " {'source': 'https://wikidocs.net/250954', 'text': ['02. LangSmith 추적 설정']},\n",
       " {'source': 'https://wikidocs.net/250954',\n",
       "  'text': ['03. OpenAI API 사용(GPT-4o 멀티모달)']},\n",
       " {'source': 'https://wikidocs.net/250954',\n",
       "  'text': ['04. LangChain Expression Language(LCEL)']},\n",
       " {'source': 'https://wikidocs.net/250954', 'text': ['05. LCEL 인터페이스']},\n",
       " {'source': 'https://wikidocs.net/250954',\n",
       "  'text': ['06. Runnable CH02 프롬프트(Prompt)']},\n",
       " {'source': 'https://wikidocs.net/250954', 'text': ['01. 프롬프트(Prompt)']},\n",
       " {'source': 'https://wikidocs.net/250954',\n",
       "  'text': ['02. 퓨샷 프롬프트(FewShotPromptTemplate)']},\n",
       " {'source': 'https://wikidocs.net/250954', 'text': ['03. LangChain Hub']},\n",
       " {'source': 'https://wikidocs.net/250954',\n",
       "  'text': ['04. 개인화된 프롬프트(Hub에 업로드) CH03 출력 파서(Output Parsers)']},\n",
       " {'source': 'https://wikidocs.net/250954',\n",
       "  'text': ['01. Pydantic 출력 파서(PydanticOutputParser)']},\n",
       " {'source': 'https://wikidocs.net/250954',\n",
       "  'text': ['02. 콤마 구분자 출력 파서(CommaSeparatedListOutputParser)']},\n",
       " {'source': 'https://wikidocs.net/250954',\n",
       "  'text': ['03. 구조화된 출력 파서(StructuredOuputParser)']},\n",
       " {'source': 'https://wikidocs.net/250954',\n",
       "  'text': ['04. JSON 출력 파서(JsonOutputParser)']},\n",
       " {'source': 'https://wikidocs.net/250954',\n",
       "  'text': ['05. 데이터프레임 출력 파서(PandasDataFrameOutputParser)']},\n",
       " {'source': 'https://wikidocs.net/250954',\n",
       "  'text': ['06. 날짜 형식 출력 파서(DatetimeOutputParser)']},\n",
       " {'source': 'https://wikidocs.net/250954',\n",
       "  'text': ['07. 열거형 출력 파서(EnumOutputParser)']},\n",
       " {'source': 'https://wikidocs.net/250954',\n",
       "  'text': ['08. 출력 수정 파서(OutputFixingParser) CH04 모델(Model)']},\n",
       " {'source': 'https://wikidocs.net/250954', 'text': ['01. 다양한 LLM 모델 활용']},\n",
       " {'source': 'https://wikidocs.net/250954', 'text': ['02. 캐싱(Cache)']},\n",
       " {'source': 'https://wikidocs.net/250954',\n",
       "  'text': ['03. 모델 직렬화(Serialization) - 저장 및 불러오기']},\n",
       " {'source': 'https://wikidocs.net/250954', 'text': ['04. 토큰 사용량 확인']},\n",
       " {'source': 'https://wikidocs.net/250954',\n",
       "  'text': ['05. 구글 생성 AI(Google Generative AI)']},\n",
       " {'source': 'https://wikidocs.net/250954',\n",
       "  'text': ['06. 허깅페이스 엔드포인트(HuggingFace Endpoints)']},\n",
       " {'source': 'https://wikidocs.net/250954',\n",
       "  'text': ['07. 허깅페이스 로컬(HuggingFace Local)']},\n",
       " {'source': 'https://wikidocs.net/250954',\n",
       "  'text': ['08. 허깅페이스 파이프라인(HuggingFace Pipeline)']},\n",
       " {'source': 'https://wikidocs.net/250954', 'text': ['09. 올라마(Ollama)']},\n",
       " {'source': 'https://wikidocs.net/250954',\n",
       "  'text': ['10. GPT4ALL CH05 메모리(Memory)']},\n",
       " {'source': 'https://wikidocs.net/250954',\n",
       "  'text': ['01. 대화 버퍼 메모리(ConversationBufferMemory)']},\n",
       " {'source': 'https://wikidocs.net/250954',\n",
       "  'text': ['02. 대화 버퍼 윈도우 메모리(ConversationBufferWindowMemory)']},\n",
       " {'source': 'https://wikidocs.net/250954',\n",
       "  'text': ['03. 대화 토큰 버퍼 메모리(ConversationTokenBufferMemory)']},\n",
       " {'source': 'https://wikidocs.net/250954',\n",
       "  'text': ['04. 대화 엔티티 메모리(ConversationEntityMemory)']},\n",
       " {'source': 'https://wikidocs.net/250954',\n",
       "  'text': ['05. 대화 지식그래프 메모리(ConversationKGMemory)']},\n",
       " {'source': 'https://wikidocs.net/250954',\n",
       "  'text': ['06. 대화 요약 메모리(ConversationSummaryMemory)']},\n",
       " {'source': 'https://wikidocs.net/250954',\n",
       "  'text': ['07. 벡터저장소 검색 메모리(VectorStoreRetrieverMemory)']},\n",
       " {'source': 'https://wikidocs.net/250954',\n",
       "  'text': ['08. LCEL Chain 에 메모리 추가', '09. SQLite 에 대화내용 저장']},\n",
       " {'source': 'https://wikidocs.net/250954',\n",
       "  'text': ['10. RunnableWithMessageHistory에 ChatMessageHistory추가 CH06 문서 로더(Document Loader)']},\n",
       " {'source': 'https://wikidocs.net/250954',\n",
       "  'text': ['01. 도큐먼트(Document) 의 구조']},\n",
       " {'source': 'https://wikidocs.net/250954', 'text': ['02. PDF']},\n",
       " {'source': 'https://wikidocs.net/250954', 'text': ['03. 한글(HWP)']},\n",
       " {'source': 'https://wikidocs.net/250954', 'text': ['04. CSV']},\n",
       " {'source': 'https://wikidocs.net/250954', 'text': ['05. Excel']},\n",
       " {'source': 'https://wikidocs.net/250954', 'text': ['06. Word']},\n",
       " {'source': 'https://wikidocs.net/250954', 'text': ['07. PowerPoint']},\n",
       " {'source': 'https://wikidocs.net/250954',\n",
       "  'text': ['08. 웹 문서(WebBaseLoader)']},\n",
       " {'source': 'https://wikidocs.net/250954', 'text': ['09. 텍스트(TextLoader)']},\n",
       " {'source': 'https://wikidocs.net/250954', 'text': ['10. JSON']},\n",
       " {'source': 'https://wikidocs.net/250954', 'text': ['11. Arxiv']},\n",
       " {'source': 'https://wikidocs.net/250954',\n",
       "  'text': ['13. UpstageLayoutAnalysisLoader']},\n",
       " {'source': 'https://wikidocs.net/250954',\n",
       "  'text': ['14. LlamaParser CH07 텍스트 분할(Text Splitter)']},\n",
       " {'source': 'https://wikidocs.net/250954',\n",
       "  'text': ['01. 문자 텍스트 분할(CharacterTextSplitter)']},\n",
       " {'source': 'https://wikidocs.net/250954',\n",
       "  'text': ['02. 재귀적 문자 텍스트 분할(RecursiveCharacterTextSplitter)']},\n",
       " {'source': 'https://wikidocs.net/250954',\n",
       "  'text': ['03. 토큰 텍스트 분할(TokenTextSplitter)']},\n",
       " {'source': 'https://wikidocs.net/250954',\n",
       "  'text': ['04. 시멘틱 청커(SemanticChunker)']},\n",
       " {'source': 'https://wikidocs.net/250954',\n",
       "  'text': ['05. 코드 분할(Python, Markdown, JAVA, C++, C#, GO, JS, Latex 등)']},\n",
       " {'source': 'https://wikidocs.net/250954',\n",
       "  'text': ['06. 마크다운 헤더 텍스트 분할(MarkdownHeaderTextSplitter)']},\n",
       " {'source': 'https://wikidocs.net/250954',\n",
       "  'text': ['07. HTML 헤더 텍스트 분할(HTMLHeaderTextSplitter)']},\n",
       " {'source': 'https://wikidocs.net/250954',\n",
       "  'text': ['08. 재귀적 JSON 분할(RecursiveJsonSplitter) CH08 임베딩(Embedding)']},\n",
       " {'source': 'https://wikidocs.net/250954', 'text': ['01. OpenAIEmbeddings']},\n",
       " {'source': 'https://wikidocs.net/250954',\n",
       "  'text': ['02. 캐시 임베딩(CacheBackedEmbeddings)']},\n",
       " {'source': 'https://wikidocs.net/250954',\n",
       "  'text': ['03. 허깅페이스 임베딩(HuggingFace Embeddings)']},\n",
       " {'source': 'https://wikidocs.net/250954', 'text': ['04. UpstageEmbeddings']},\n",
       " {'source': 'https://wikidocs.net/250954', 'text': ['05. OllamaEmbeddings']},\n",
       " {'source': 'https://wikidocs.net/250954', 'text': ['06. GPT4ALL 임베딩']},\n",
       " {'source': 'https://wikidocs.net/250954',\n",
       "  'text': ['07. Llama CPP 임베딩 CH09 벡터저장소(VectorStore)']},\n",
       " {'source': 'https://wikidocs.net/250954', 'text': ['01. Chroma']},\n",
       " {'source': 'https://wikidocs.net/250954', 'text': ['02. FAISS']},\n",
       " {'source': 'https://wikidocs.net/250954',\n",
       "  'text': ['03. Pinecone CH10 검색기(Retriever)']},\n",
       " {'source': 'https://wikidocs.net/250954',\n",
       "  'text': ['01. 벡터저장소 지원 검색기(VectorStore-backed Retriever)']},\n",
       " {'source': 'https://wikidocs.net/250954',\n",
       "  'text': ['02. 문맥 압축 검색기(ContextualCompressionRetriever)']},\n",
       " {'source': 'https://wikidocs.net/250954',\n",
       "  'text': ['03. 앙상블 검색기(EnsembleRetriever)']},\n",
       " {'source': 'https://wikidocs.net/250954',\n",
       "  'text': ['04. 긴 문맥 재정렬(LongContextReorder)']},\n",
       " {'source': 'https://wikidocs.net/250954',\n",
       "  'text': ['05. 상위 문서 검색기(ParentDocumentRetriever)']},\n",
       " {'source': 'https://wikidocs.net/250954',\n",
       "  'text': ['06. 다중 쿼리 검색기(MultiQueryRetriever)']},\n",
       " {'source': 'https://wikidocs.net/250954',\n",
       "  'text': ['07. 다중 벡터저장소 검색기(MultiVectorRetriever)']},\n",
       " {'source': 'https://wikidocs.net/250954',\n",
       "  'text': ['08. 셀프 쿼리 검색기(SelfQueryRetriever)']},\n",
       " {'source': 'https://wikidocs.net/250954',\n",
       "  'text': ['09. 시간 가중 벡터저장소 검색기(TimeWeightedVectorStoreRetriever)']},\n",
       " {'source': 'https://wikidocs.net/250954',\n",
       "  'text': ['10. 한글 형태소 분석기(Kiwi, Kkma, Okt) + BM25 검색기 CH11 리랭커(Reranker)']},\n",
       " {'source': 'https://wikidocs.net/250954',\n",
       "  'text': ['01. Cross Encoder Reranker']},\n",
       " {'source': 'https://wikidocs.net/250954', 'text': ['02. Cohere Reranker']},\n",
       " {'source': 'https://wikidocs.net/250954', 'text': ['03. Jina Reranker']},\n",
       " {'source': 'https://wikidocs.net/250954',\n",
       "  'text': ['04. FlashRank Reranker CH12 Retrieval Augmented Generation(RAG)']},\n",
       " {'source': 'https://wikidocs.net/250954',\n",
       "  'text': ['01. PDF 문서 기반 QA(Question-Answer)']},\n",
       " {'source': 'https://wikidocs.net/250954',\n",
       "  'text': ['02. 네이버 뉴스기사 QA(Question-Answer)']},\n",
       " {'source': 'https://wikidocs.net/250954',\n",
       "  'text': ['03. RAG 의 기능별 다양한 모듈 활용기']},\n",
       " {'source': 'https://wikidocs.net/250954',\n",
       "  'text': ['04. RAPTOR: 긴 문맥 요약(Long Context Summary)']},\n",
       " {'source': 'https://wikidocs.net/250954',\n",
       "  'text': ['05. 대화내용을 기억하는 RAG 체인 CH13 LangChain Expression Language(LCEL)']},\n",
       " {'source': 'https://wikidocs.net/250954',\n",
       "  'text': ['01. RunnablePassthrough: 데이터 전달']},\n",
       " {'source': 'https://wikidocs.net/250954',\n",
       "  'text': ['02. Runnable 구조(그래프) 확인']},\n",
       " {'source': 'https://wikidocs.net/250954',\n",
       "  'text': ['03. RunnableLambda: 사용자 정의 함수']},\n",
       " {'source': 'https://wikidocs.net/250954',\n",
       "  'text': ['04. RunnableBranch: 라우팅(Routing)']},\n",
       " {'source': 'https://wikidocs.net/250954',\n",
       "  'text': ['05. RunnableParallel: 병렬 처리']},\n",
       " {'source': 'https://wikidocs.net/250954',\n",
       "  'text': ['06. configurable_fields, configurable_alternatives 07. @chain 데코레이터로 Runnable 생성',\n",
       "   '08. RunnableWithMessageHistory']},\n",
       " {'source': 'https://wikidocs.net/250954',\n",
       "  'text': ['09. 사용자 정의 제네레이터(generator)']},\n",
       " {'source': 'https://wikidocs.net/250954',\n",
       "  'text': ['10. Runtime Arguments 바인딩']},\n",
       " {'source': 'https://wikidocs.net/250954',\n",
       "  'text': ['11. 폴백(fallback) 모델 지정 CH14 체인(Chains)']},\n",
       " {'source': 'https://wikidocs.net/250954', 'text': ['01. 문서 요약']},\n",
       " {'source': 'https://wikidocs.net/250954',\n",
       "  'text': ['02. SQL CH15 에이전트(Agent)']},\n",
       " {'source': 'https://wikidocs.net/250954', 'text': ['01. Agent 사용법 톺아보기']},\n",
       " {'source': 'https://wikidocs.net/250954',\n",
       "  'text': ['02. 도구를 활용한 토론 에이전트(Two Agent Debates with Tools) CH16 파인튜닝(Fine Tuning)']},\n",
       " {'source': 'https://wikidocs.net/250954', 'text': ['CH17 LangGraph']},\n",
       " {'source': 'https://wikidocs.net/250954',\n",
       "  'text': ['01. Chain of Table for Multiple Tables']},\n",
       " {'source': 'https://wikidocs.net/250954',\n",
       "  'text': ['Published with WikiDocs']},\n",
       " {'source': 'https://wikidocs.net/250954',\n",
       "  'text': ['<랭체인LangChain 노트> - Lang…']},\n",
       " {'source': 'https://wikidocs.net/250954', 'text': ['CH01 LangChain 시작하기']},\n",
       " {'source': 'https://wikidocs.net/250954', 'text': ['02. LangSmith 추적 설정']},\n",
       " {'source': 'https://wikidocs.net/250954', 'text': ['위키독스']},\n",
       " {'source': 'https://wikidocs.net/250954', 'text': ['02. LangSmith 추적 설정']},\n",
       " {'source': 'https://wikidocs.net/250954', 'text': ['LangSmith 추적 설정하기']},\n",
       " {'source': 'https://wikidocs.net/250954',\n",
       "  'text': ['LangSmith는 LLM 애플리케이션 개발, 모니터링 및 테스트 를 위한 플랫폼입니다.']},\n",
       " {'source': 'https://wikidocs.net/250954',\n",
       "  'text': ['프로젝트나 LangChain 학습을 시작하시는 분들이라면 LangSmith는 꼭 설정 후 진행하는 것을 추천 드립니다.']},\n",
       " {'source': 'https://wikidocs.net/250954', 'text': ['LangSmith 의 추적기능']},\n",
       " {'source': 'https://wikidocs.net/250954',\n",
       "  'text': ['추적은 LLM 애플리케이션의 동작을 이해하기 위한 강력한 도구입니다.',\n",
       "   'LangSmith는 LangChain 사용 여부와 관계없이 동급 최고의 추적 기능을 제공합니다.']},\n",
       " {'source': 'https://wikidocs.net/250954',\n",
       "  'text': ['추적은 다음과 같은 문제를 추적하는 데 도움이 될 수 있습니다.']},\n",
       " {'source': 'https://wikidocs.net/250954', 'text': ['예상치 못한 최종 결과']},\n",
       " {'source': 'https://wikidocs.net/250954',\n",
       "  'text': ['에이전트가 루핑되는 이유', '체인이 예상보다 느린 이유']},\n",
       " {'source': 'https://wikidocs.net/250954', 'text': ['에이전트가 각 단계에서 사용한 토큰 수']},\n",
       " {'source': 'https://wikidocs.net/250954', 'text': ['프로젝트 단위 추적']},\n",
       " {'source': 'https://wikidocs.net/250954',\n",
       "  'text': ['프로젝트 단위로 실행 카운트, Error 발생률, 토큰 사용량, 과금 정보등을 확인할 수 있습니다.',\n",
       "   '프로젝트를 클릭하면 실행된 모든 Run 이 나타납니다.',\n",
       "   '1개의 실행에 대한 세부 단계별 추척']},\n",
       " {'source': 'https://wikidocs.net/250954',\n",
       "  'text': ['1개의 실행을 한 뒤 retrieve 된 문서의 검색 결과 뿐만 아니라, GPT 의 입출력 내용에 대해서 자세하게 기록합니다.',\n",
       "   '따라서, 문서의 검색된 내용을 확인 후 검색 알고리즘을 변경해야할지 혹은 프롬프트를 변경해야할지 판단하는데 도움이 됩니다.',\n",
       "   '뿐만 아니라, 상단에는 1개의 실행(Run) 이 걸린 시간(약 30초)와 사용된 토큰(5,104) 등이 표기가 되고, 토큰에 마우스 호버를 하게 되면 청구 금액까지 표기해 줍니다.']},\n",
       " {'source': 'https://wikidocs.net/250954',\n",
       "  'text': ['LangSmith 추적 사용하기', '추적을 사용하는 방법은 매우 간단합니다.']},\n",
       " {'source': 'https://wikidocs.net/250954',\n",
       "  'text': ['LangSmith API Key 발급',\n",
       "   'https://smith.langchain.com/ 으로 접속하여 회원가입을 진행합니다.',\n",
       "   '가입후 이메일 인증하는 절차를 진행해야 합니다.',\n",
       "   '왼쪽 톱니바퀴(Setting) - 가운데 \"Personal\" - \"Create API Key\" 를 눌러 API 키를 발급 받습니다.',\n",
       "   'Description 에 본인이 알 수 있는 설명을 넣고 Create API Key 버튼을 클릭하여 생성합니다.',\n",
       "   '생성한 키를 복사한 뒤 다음 단계로 진행합니다.']},\n",
       " {'source': 'https://wikidocs.net/250954',\n",
       "  'text': ['(주의!)', '생성한 키를 유출하지 않도록 안전한 곳에 복사해 두세요.']},\n",
       " ...]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunked_html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Embedding\n",
    "\n",
    "문단 나누기 API를 통해 나누어진 525개의 chunk(chunked_html)을 CLOVA Studio의 임베딩 API를 사용해 1024차원의 벡터로 변환하는 과정입니다. clir-emb-dolphin의 경우, 임베딩 과정에서 유사도 판단을 위해 벡터의 내적(Inner Product, IP)을 거리 단위로 사용합니다. 반면, clir-sts-dolphin은 코사인 거리(Cosine)를 거리 단위로 사용합니다. 이후, 벡터의 인덱싱과 검색 과정에서 사용자는 어떤 거리 단위를 사용하여 데이터와 사용자의 쿼리 간 유사도를 판단할 것인지 선택할 수 있습니다.\n",
    "\n",
    "거리 단위를 임베딩부터 인덱싱, 검색까지 일치시켜야 데이터의 품질이 향상되므로, 임베딩 과정에서 사용한 모델(emb / sts)을 기억하는 것이 중요합니다. 임베딩 클래스에 오류가 발생시 멈추게끔 하는 로직을 일부 추가해, 다량의 데이터를 처리할 때 오류 발생시 재실행의 부담을 줄입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 64/1486 [00:08<01:56, 12.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding API Error. 오류 발생: 42901: Too many requests - rate exceeded\n",
      "['02. 캐시 임베딩(CacheBackedEmbeddings)']\n",
      "Embedding API Error. 오류 발생: 42901: Too many requests - rate exceeded\n",
      "['03. 허깅페이스 임베딩(HuggingFace Embeddings)']\n",
      "Embedding API Error. 오류 발생: 42901: Too many requests - rate exceeded\n",
      "['04. UpstageEmbeddings']\n",
      "Embedding API Error. 오류 발생: 42901: Too many requests - rate exceeded\n",
      "['05. OllamaEmbeddings']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 66/1486 [00:08<01:42, 13.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding API Error. 오류 발생: 42901: Too many requests - rate exceeded\n",
      "['06. GPT4ALL 임베딩']\n",
      "Embedding API Error. 오류 발생: 42901: Too many requests - rate exceeded\n",
      "['07. Llama CPP 임베딩 CH09 벡터저장소(VectorStore)']\n",
      "Embedding API Error. 오류 발생: 42901: Too many requests - rate exceeded\n",
      "['01. Chroma']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 71/1486 [00:08<01:31, 15.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding API Error. 오류 발생: 42901: Too many requests - rate exceeded\n",
      "['02. FAISS']\n",
      "Embedding API Error. 오류 발생: 42901: Too many requests - rate exceeded\n",
      "['03. Pinecone CH10 검색기(Retriever)']\n",
      "Embedding API Error. 오류 발생: 42901: Too many requests - rate exceeded\n",
      "['01. 벡터저장소 지원 검색기(VectorStore-backed Retriever)']\n",
      "Embedding API Error. 오류 발생: 42901: Too many requests - rate exceeded\n",
      "['02. 문맥 압축 검색기(ContextualCompressionRetriever)']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 75/1486 [00:09<01:23, 16.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding API Error. 오류 발생: 42901: Too many requests - rate exceeded\n",
      "['03. 앙상블 검색기(EnsembleRetriever)']\n",
      "Embedding API Error. 오류 발생: 42901: Too many requests - rate exceeded\n",
      "['04. 긴 문맥 재정렬(LongContextReorder)']\n",
      "Embedding API Error. 오류 발생: 42901: Too many requests - rate exceeded\n",
      "['05. 상위 문서 검색기(ParentDocumentRetriever)']\n",
      "Embedding API Error. 오류 발생: 42901: Too many requests - rate exceeded\n",
      "['06. 다중 쿼리 검색기(MultiQueryRetriever)']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 79/1486 [00:09<01:21, 17.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding API Error. 오류 발생: 42901: Too many requests - rate exceeded\n",
      "['07. 다중 벡터저장소 검색기(MultiVectorRetriever)']\n",
      "Embedding API Error. 오류 발생: 42901: Too many requests - rate exceeded\n",
      "['08. 셀프 쿼리 검색기(SelfQueryRetriever)']\n",
      "Embedding API Error. 오류 발생: 42901: Too many requests - rate exceeded\n",
      "['09. 시간 가중 벡터저장소 검색기(TimeWeightedVectorStoreRetriever)']\n",
      "Embedding API Error. 오류 발생: 42901: Too many requests - rate exceeded\n",
      "['10. 한글 형태소 분석기(Kiwi, Kkma, Okt) + BM25 검색기 CH11 리랭커(Reranker)']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 83/1486 [00:09<01:20, 17.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding API Error. 오류 발생: 42901: Too many requests - rate exceeded\n",
      "['01. Cross Encoder Reranker']\n",
      "Embedding API Error. 오류 발생: 42901: Too many requests - rate exceeded\n",
      "['02. Cohere Reranker']\n",
      "Embedding API Error. 오류 발생: 42901: Too many requests - rate exceeded\n",
      "['03. Jina Reranker']\n",
      "Embedding API Error. 오류 발생: 42901: Too many requests - rate exceeded\n",
      "['04. FlashRank Reranker CH12 Retrieval Augmented Generation(RAG)']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 87/1486 [00:09<01:19, 17.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding API Error. 오류 발생: 42901: Too many requests - rate exceeded\n",
      "['01. PDF 문서 기반 QA(Question-Answer)']\n",
      "Embedding API Error. 오류 발생: 42901: Too many requests - rate exceeded\n",
      "['02. 네이버 뉴스기사 QA(Question-Answer)']\n",
      "Embedding API Error. 오류 발생: 42901: Too many requests - rate exceeded\n",
      "['03. RAG 의 기능별 다양한 모듈 활용기']\n",
      "Embedding API Error. 오류 발생: 42901: Too many requests - rate exceeded\n",
      "['04. RAPTOR: 긴 문맥 요약(Long Context Summary)']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 89/1486 [00:09<01:16, 18.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding API Error. 오류 발생: 42901: Too many requests - rate exceeded\n",
      "['05. 대화내용을 기억하는 RAG 체인 CH13 LangChain Expression Language(LCEL)']\n",
      "Embedding API Error. 오류 발생: 42901: Too many requests - rate exceeded\n",
      "['01. RunnablePassthrough: 데이터 전달']\n",
      "Embedding API Error. 오류 발생: 42901: Too many requests - rate exceeded\n",
      "['02. Runnable 구조(그래프) 확인']\n",
      "Embedding API Error. 오류 발생: 42901: Too many requests - rate exceeded\n",
      "['03. RunnableLambda: 사용자 정의 함수']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 94/1486 [00:10<01:15, 18.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding API Error. 오류 발생: 42901: Too many requests - rate exceeded\n",
      "['04. RunnableBranch: 라우팅(Routing)']\n",
      "Embedding API Error. 오류 발생: 42901: Too many requests - rate exceeded\n",
      "['05. RunnableParallel: 병렬 처리']\n",
      "Embedding API Error. 오류 발생: 42901: Too many requests - rate exceeded\n",
      "['06. configurable_fields, configurable_alternatives 07. @chain 데코레이터로 Runnable 생성', '08. RunnableWithMessageHistory']\n",
      "Embedding API Error. 오류 발생: 42901: Too many requests - rate exceeded\n",
      "['09. 사용자 정의 제네레이터(generator)']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 98/1486 [00:10<01:17, 18.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding API Error. 오류 발생: 42901: Too many requests - rate exceeded\n",
      "['10. Runtime Arguments 바인딩']\n",
      "Embedding API Error. 오류 발생: 42901: Too many requests - rate exceeded\n",
      "['11. 폴백(fallback) 모델 지정 CH14 체인(Chains)']\n",
      "Embedding API Error. 오류 발생: 42901: Too many requests - rate exceeded\n",
      "['01. 문서 요약']\n",
      "Embedding API Error. 오류 발생: 42901: Too many requests - rate exceeded\n",
      "['02. SQL CH15 에이전트(Agent)']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 102/1486 [00:10<01:15, 18.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding API Error. 오류 발생: 42901: Too many requests - rate exceeded\n",
      "['01. Agent 사용법 톺아보기']\n",
      "Embedding API Error. 오류 발생: 42901: Too many requests - rate exceeded\n",
      "['02. 도구를 활용한 토론 에이전트(Two Agent Debates with Tools) CH16 파인튜닝(Fine Tuning)']\n",
      "Embedding API Error. 오류 발생: 42901: Too many requests - rate exceeded\n",
      "['CH17 LangGraph']\n",
      "Embedding API Error. 오류 발생: 42901: Too many requests - rate exceeded\n",
      "['01. Chain of Table for Multiple Tables']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 106/1486 [00:10<01:14, 18.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding API Error. 오류 발생: 42901: Too many requests - rate exceeded\n",
      "['Published with WikiDocs']\n",
      "Embedding API Error. 오류 발생: 42901: Too many requests - rate exceeded\n",
      "['<랭체인LangChain 노트> - Lang…']\n",
      "Embedding API Error. 오류 발생: 42901: Too many requests - rate exceeded\n",
      "['CH01 LangChain 시작하기', '위키독스']\n",
      "Embedding API Error. 오류 발생: 42901: Too many requests - rate exceeded\n",
      "['CH01 LangChain 시작하기']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 110/1486 [00:11<01:15, 18.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding API Error. 오류 발생: 42901: Too many requests - rate exceeded\n",
      "['🦜️🔗 랭체인 LangChain']\n",
      "Embedding API Error. 오류 발생: 42901: Too many requests - rate exceeded\n",
      "['LangChain 은 언어 모델을 활용해 다양한 애플리케이션을 개발할 수 있는 프레임워크를 말합니다.', '이 프레임워크를 통해 언어 모델은 다음과 같은 기능을 수행할 수 있게 됩니다.']\n",
      "Embedding API Error. 오류 발생: 42901: Too many requests - rate exceeded\n",
      "['문맥을 인식하는 기능: LangChain은 언어 모델을 다양한 문맥 소스와 연결합니다.', '여기에는 프롬프트 지시사항, 소수의 예시, 응답에 근거한 내용 등이 포함됩니다.', '이를 통해 언어 모델은 제공된 정보를 기반으로 더 정확하고 관련성 높은 답변을 생성할 수 있습니다.', '추론하는 기능: 또한, 언어 모델은 주어진 문맥을 바탕으로 어떠한 답변을 제공하거나, 어떤 조치를 취해야 할지를 스스로 추론할 수 있습니다.', '이는 언어 모델이 단순히 정보를 재생산하는 것을 넘어서, 주어진 상황을 분석하고 적절한 해결책을 제시할 수 있음을 의미합니다.', 'LangChain 을 활용하면 이전에 언급한 기능을 바탕으로 검색 증강 생성(RAG) 어플리케이션 제작, 구조화된 데이터 분석, 챗봇 등을 만들 수 있습니다.']\n",
      "Embedding API Error. 오류 발생: 42901: Too many requests - rate exceeded\n",
      "['더 많은 예제는 유튜브 채널 테디노트 에서 확인하실 수 있습니다.']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 114/1486 [00:11<02:28,  9.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding API Error. 오류 발생: 42901: Too many requests - rate exceeded\n",
      "['설치']\n",
      "Embedding API Error. 오류 발생: 42901: Too many requests - rate exceeded\n",
      "['권장하는 파이썬 버전은 3.11 버전입니다.']\n",
      "Embedding API Error. 오류 발생: 42901: Too many requests - rate exceeded\n",
      "['pip 를 이용한 설치', 'pip install -r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt']\n",
      "Embedding API Error. 오류 발생: 42901: Too many requests - rate exceeded\n",
      "['최소한의 기능만 설치하기 위한 mini 버전 (일부 패키지만 설치하는 경우)']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 118/1486 [00:11<01:50, 12.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding API Error. 오류 발생: 42901: Too many requests - rate exceeded\n",
      "['pip install -r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements-mini.txt']\n",
      "Embedding API Error. 오류 발생: 42901: Too many requests - rate exceeded\n",
      "['구성']\n",
      "Embedding API Error. 오류 발생: 42901: Too many requests - rate exceeded\n",
      "['이 프레임워크는 여러 부분으로 구성되어 있습니다.']\n",
      "Embedding API Error. 오류 발생: 42901: Too many requests - rate exceeded\n",
      "['LangChain 라이브러리: Python 및 JavaScript 라이브러리.']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 122/1486 [00:12<01:31, 14.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding API Error. 오류 발생: 42901: Too many requests - rate exceeded\n",
      "['다양한 컴포넌트의 인터페이스와 통합, 이러한 컴포넌트를 체인과 에이전트로 결합하는 기본 런타임, 그리고 즉시 사용 가능한 체인과 에이전트의 구현을 포함합니다.']\n",
      "Embedding API Error. 오류 발생: 42901: Too many requests - rate exceeded\n",
      "['LangChain 템플릿: 다양한 작업을 위한 쉽게 배포할 수 있는 참조 아키텍처 모음입니다.']\n",
      "Embedding API Error. 오류 발생: 42901: Too many requests - rate exceeded\n",
      "['LangServe: LangChain 체인을 REST API로 배포하기 위한 라이브러리입니다.']\n",
      "Embedding API Error. 오류 발생: 42901: Too many requests - rate exceeded\n",
      "['LangSmith: 어떤 LLM 프레임워크에도 구축된 체인을 디버그, 테스트, 평가, 모니터링할 수 있게 해주며 LangChain과 원활하게 통합되는 개발자 플랫폼입니다.']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 126/1486 [00:12<01:22, 16.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding API Error. 오류 발생: 42901: Too many requests - rate exceeded\n",
      "['LangGraph: LLM을 사용한 상태유지가 가능한 다중 액터 애플리케이션을 구축하기 위한 라이브러리로, LangChain 위에 구축되었으며 LangChain과 함께 사용하도록 설계되었습니다.', '여러 계산 단계에서 다중 체인(또는 액터)을 순환 방식으로 조정할 수 있는 능력을 LangChain 표현 언어에 추가합니다.']\n",
      "Embedding API Error. 오류 발생: 42901: Too many requests - rate exceeded\n",
      "['개발 용이성✨']\n",
      "Embedding API Error. 오류 발생: 42901: Too many requests - rate exceeded\n",
      "['컴포넌트의 조립 및 통합 🔧', 'LangChain은 언어 모델과의 작업을 위한 조립 가능한 도구 및 통합을 제공합니다.', '컴포넌트는 모듈식으로 설계되어, 사용하기 쉽습니다.', '이는 개발자가 LangChain 프레임워크를 자유롭게 활용할 수 있게 해줍니다.', '즉시 사용 가능한 체인 🚀', '고수준 작업을 수행하기 위한 컴포넌트의 내장 조합을 제공합니다.', '이러한 체인은 개발 과정을 간소화하고 속도를 높여줍니다.']\n",
      "Embedding API Error. 오류 발생: 42901: Too many requests - rate exceeded\n",
      "['주요 모듈 📌', '모델 I/O 📃', '프롬프트 관리, 최적화 및 LLM과의 일반적인 인터페이스와 작업을 위한 유틸리티를 포함합니다.']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▊         | 130/1486 [00:12<01:19, 17.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding API Error. 오류 발생: 42901: Too many requests - rate exceeded\n",
      "['검색 📚']\n",
      "Embedding API Error. 오류 발생: 42901: Too many requests - rate exceeded\n",
      "[\"'데이터 강화 생성'에 초점을 맞춘 이 모듈은 생성 단계에서 필요한 데이터를 외부 데이터 소스에서 가져오는 작업을 담당합니다.\"]\n",
      "Embedding API Error. 오류 발생: 42901: Too many requests - rate exceeded\n",
      "['에이전트 🤖']\n",
      "Embedding API Error. 오류 발생: 42901: Too many requests - rate exceeded\n",
      "['언어 모델이 어떤 조치를 취할지 결정하고, 해당 조치를 실행하며, 관찰하고, 필요한 경우 반복하는 과정을 포함합니다.']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 134/1486 [00:12<01:14, 18.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding API Error. 오류 발생: 42901: Too many requests - rate exceeded\n",
      "['LangChain을 활용하면, 언어 모델 기반 애플리케이션의 개발을 보다 쉽게 시작할 수 있으며, 필요에 맞게 기능을 맞춤 설정하고, 다양한 데이터 소스와 통합하여 복잡한 작업을 처리할 수 있게 됩니다.']\n",
      "Embedding API Error. 오류 발생: 42901: Too many requests - rate exceeded\n",
      "['마지막 편집일시 : 2024년 7월 16일 2:40 오전']\n",
      "Embedding API Error. 오류 발생: 42901: Too many requests - rate exceeded\n",
      "['댓글 0 피드백', '※ 댓글 작성은 로그인이 필요합니다.', '(또는 피드백을 이용해 주세요.)']\n",
      "Embedding API Error. 오류 발생: 42901: Too many requests - rate exceeded\n",
      "['이전글 : <랭체인LangChain 노트> - LangChain 한국어 튜토리얼🇰🇷']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 138/1486 [00:13<01:14, 18.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding API Error. 오류 발생: 42901: Too many requests - rate exceeded\n",
      "['다음글 : 01.']\n",
      "Embedding API Error. 오류 발생: 42901: Too many requests - rate exceeded\n",
      "['OpenAI API 키 발급 및 테스트']\n",
      "Embedding API Error. 오류 발생: 42901: Too many requests - rate exceeded\n",
      "['책갈피']\n",
      "Embedding API Error. 오류 발생: 42901: Too many requests - rate exceeded\n",
      "['이 페이지에 대한 피드백을 남겨주세요']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 142/1486 [00:13<01:13, 18.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding API Error. 오류 발생: 42901: Too many requests - rate exceeded\n",
      "['댓글을 신고합니다.']\n",
      "Embedding API Error. 오류 발생: 42901: Too many requests - rate exceeded\n",
      "['<랭체인LangChain 노트> - LangChain 한국어 튜토리얼🇰🇷 CH01 LangChain 시작하기']\n",
      "Embedding API Error. 오류 발생: 42901: Too many requests - rate exceeded\n",
      "['01. OpenAI API 키 발급 및 테스트']\n",
      "Embedding API Error. 오류 발생: 42901: Too many requests - rate exceeded\n",
      "['02. LangSmith 추적 설정']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 146/1486 [00:13<01:12, 18.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding API Error. 오류 발생: 42901: Too many requests - rate exceeded\n",
      "['03. OpenAI API 사용(GPT-4o 멀티모달)']\n",
      "Embedding API Error. 오류 발생: 42901: Too many requests - rate exceeded\n",
      "['04. LangChain Expression Language(LCEL)']\n",
      "Embedding API Error. 오류 발생: 42901: Too many requests - rate exceeded\n",
      "['05. LCEL 인터페이스']\n",
      "Embedding API Error. 오류 발생: 42901: Too many requests - rate exceeded\n",
      "['06. Runnable CH02 프롬프트(Prompt)']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 150/1486 [00:13<01:12, 18.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding API Error. 오류 발생: 42901: Too many requests - rate exceeded\n",
      "['01. 프롬프트(Prompt)']\n",
      "Embedding API Error. 오류 발생: 42901: Too many requests - rate exceeded\n",
      "['02. 퓨샷 프롬프트(FewShotPromptTemplate)']\n",
      "Embedding API Error. 오류 발생: 42901: Too many requests - rate exceeded\n",
      "['03. LangChain Hub']\n",
      "Embedding API Error. 오류 발생: 42901: Too many requests - rate exceeded\n",
      "['04. 개인화된 프롬프트(Hub에 업로드) CH03 출력 파서(Output Parsers)']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 154/1486 [00:13<01:10, 18.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding API Error. 오류 발생: 42901: Too many requests - rate exceeded\n",
      "['01. Pydantic 출력 파서(PydanticOutputParser)']\n",
      "Embedding API Error. 오류 발생: 42901: Too many requests - rate exceeded\n",
      "['02. 콤마 구분자 출력 파서(CommaSeparatedListOutputParser)']\n",
      "Embedding API Error. 오류 발생: 42901: Too many requests - rate exceeded\n",
      "['03. 구조화된 출력 파서(StructuredOuputParser)']\n",
      "Embedding API Error. 오류 발생: 42901: Too many requests - rate exceeded\n",
      "['04. JSON 출력 파서(JsonOutputParser)']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 158/1486 [00:14<01:10, 18.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding API Error. 오류 발생: 42901: Too many requests - rate exceeded\n",
      "['05. 데이터프레임 출력 파서(PandasDataFrameOutputParser)']\n",
      "Embedding API Error. 오류 발생: 42901: Too many requests - rate exceeded\n",
      "['06. 날짜 형식 출력 파서(DatetimeOutputParser)']\n",
      "Embedding API Error. 오류 발생: 42901: Too many requests - rate exceeded\n",
      "['07. 열거형 출력 파서(EnumOutputParser)']\n",
      "Embedding API Error. 오류 발생: 42901: Too many requests - rate exceeded\n",
      "['08. 출력 수정 파서(OutputFixingParser) CH04 모델(Model)']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 160/1486 [00:14<01:57, 11.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding API Error. 오류 발생: 42901: Too many requests - rate exceeded\n",
      "['01. 다양한 LLM 모델 활용']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 53\u001b[0m\n\u001b[1;32m     49\u001b[0m         text_content\u001b[38;5;241m=\u001b[39mtext_content[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     50\u001b[0m     request_json \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     51\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m: text_content\n\u001b[1;32m     52\u001b[0m     }\n\u001b[0;32m---> 53\u001b[0m     response_data \u001b[38;5;241m=\u001b[39m \u001b[43membedding_executor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest_json\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m     chunked_document[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124membedding\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m response_data\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "Cell \u001b[0;32mIn[28], line 29\u001b[0m, in \u001b[0;36mEmbeddingExecutor.execute\u001b[0;34m(self, completion_request)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mexecute\u001b[39m(\u001b[38;5;28mself\u001b[39m, completion_request):\n\u001b[0;32m---> 29\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompletion_request\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m res[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m20000\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     31\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m res[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresult\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124membedding\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "Cell \u001b[0;32mIn[28], line 16\u001b[0m, in \u001b[0;36mEmbeddingExecutor._send_request\u001b[0;34m(self, completion_request)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_send_request\u001b[39m(\u001b[38;5;28mself\u001b[39m, completion_request):\n\u001b[1;32m      9\u001b[0m     headers \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     10\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContent-Type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapplication/json; charset=utf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     11\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX-NCP-CLOVASTUDIO-API-KEY\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_api_key,\n\u001b[1;32m     12\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX-NCP-APIGW-API-KEY\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_api_key_primary_val,\n\u001b[1;32m     13\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX-NCP-CLOVASTUDIO-REQUEST-ID\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request_id\n\u001b[1;32m     14\u001b[0m     }\n\u001b[0;32m---> 16\u001b[0m     conn \u001b[38;5;241m=\u001b[39m \u001b[43mhttp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mHTTPSConnection\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_host\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m     conn\u001b[38;5;241m.\u001b[39mrequest(\n\u001b[1;32m     18\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPOST\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     19\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/testapp/v1/api-tools/embedding/v2/95709fb7cc5047b6adad8f4d8442bf24\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     20\u001b[0m         json\u001b[38;5;241m.\u001b[39mdumps(completion_request),\n\u001b[1;32m     21\u001b[0m         headers\n\u001b[1;32m     22\u001b[0m     )\n\u001b[1;32m     23\u001b[0m     response \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39mgetresponse()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/clova-env/lib/python3.12/http/client.py:1459\u001b[0m, in \u001b[0;36mHTTPSConnection.__init__\u001b[0;34m(self, host, port, timeout, source_address, context, blocksize)\u001b[0m\n\u001b[1;32m   1455\u001b[0m \u001b[38;5;28msuper\u001b[39m(HTTPSConnection, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(host, port, timeout,\n\u001b[1;32m   1456\u001b[0m                                       source_address,\n\u001b[1;32m   1457\u001b[0m                                       blocksize\u001b[38;5;241m=\u001b[39mblocksize)\n\u001b[1;32m   1458\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1459\u001b[0m     context \u001b[38;5;241m=\u001b[39m \u001b[43m_create_https_context\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_http_vsn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1460\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_context \u001b[38;5;241m=\u001b[39m context\n",
      "File \u001b[0;32m/opt/anaconda3/envs/clova-env/lib/python3.12/http/client.py:807\u001b[0m, in \u001b[0;36m_create_https_context\u001b[0;34m(http_version)\u001b[0m\n\u001b[1;32m    804\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_create_https_context\u001b[39m(http_version):\n\u001b[1;32m    805\u001b[0m     \u001b[38;5;66;03m# Function also used by urllib.request to be able to set the check_hostname\u001b[39;00m\n\u001b[1;32m    806\u001b[0m     \u001b[38;5;66;03m# attribute on a context object.\u001b[39;00m\n\u001b[0;32m--> 807\u001b[0m     context \u001b[38;5;241m=\u001b[39m \u001b[43mssl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_default_https_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    808\u001b[0m     \u001b[38;5;66;03m# send ALPN extension to indicate HTTP/1.1 protocol\u001b[39;00m\n\u001b[1;32m    809\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m http_version \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m11\u001b[39m:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/clova-env/lib/python3.12/ssl.py:713\u001b[0m, in \u001b[0;36mcreate_default_context\u001b[0;34m(purpose, cafile, capath, cadata)\u001b[0m\n\u001b[1;32m    708\u001b[0m     context\u001b[38;5;241m.\u001b[39mload_verify_locations(cafile, capath, cadata)\n\u001b[1;32m    709\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m context\u001b[38;5;241m.\u001b[39mverify_mode \u001b[38;5;241m!=\u001b[39m CERT_NONE:\n\u001b[1;32m    710\u001b[0m     \u001b[38;5;66;03m# no explicit cafile, capath or cadata but the verify mode is\u001b[39;00m\n\u001b[1;32m    711\u001b[0m     \u001b[38;5;66;03m# CERT_OPTIONAL or CERT_REQUIRED. Let's try to load default system\u001b[39;00m\n\u001b[1;32m    712\u001b[0m     \u001b[38;5;66;03m# root CA certificates for the given purpose. This may fail silently.\u001b[39;00m\n\u001b[0;32m--> 713\u001b[0m     \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_default_certs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpurpose\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    714\u001b[0m \u001b[38;5;66;03m# OpenSSL 1.1.1 keylog file\u001b[39;00m\n\u001b[1;32m    715\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(context, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkeylog_filename\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "File \u001b[0;32m/opt/anaconda3/envs/clova-env/lib/python3.12/ssl.py:535\u001b[0m, in \u001b[0;36mSSLContext.load_default_certs\u001b[0;34m(self, purpose)\u001b[0m\n\u001b[1;32m    533\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m storename \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_windows_cert_stores:\n\u001b[1;32m    534\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_load_windows_store_certs(storename, purpose)\n\u001b[0;32m--> 535\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_default_verify_paths\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "class EmbeddingExecutor:\n",
    "    def __init__(self, host, api_key, api_key_primary_val, request_id):\n",
    "        self._host = host\n",
    "        self._api_key = api_key\n",
    "        self._api_key_primary_val = api_key_primary_val\n",
    "        self._request_id = request_id\n",
    "\n",
    "    def _send_request(self, completion_request):\n",
    "        headers = {\n",
    "            \"Content-Type\": \"application/json; charset=utf-8\",\n",
    "            \"X-NCP-CLOVASTUDIO-API-KEY\": self._api_key,\n",
    "            \"X-NCP-APIGW-API-KEY\": self._api_key_primary_val,\n",
    "            \"X-NCP-CLOVASTUDIO-REQUEST-ID\": self._request_id\n",
    "        }\n",
    "\n",
    "        conn = http.client.HTTPSConnection(self._host)\n",
    "        conn.request(\n",
    "            \"POST\",\n",
    "            \"/testapp/v1/api-tools/embedding/v2/95709fb7cc5047b6adad8f4d8442bf24\",\n",
    "            json.dumps(completion_request),\n",
    "            headers\n",
    "        )\n",
    "        response = conn.getresponse()\n",
    "        result = json.loads(response.read().decode(encoding=\"utf-8\"))\n",
    "        conn.close()\n",
    "        return result\n",
    "\n",
    "    def execute(self, completion_request):\n",
    "        res = self._send_request(completion_request)\n",
    "        if res[\"status\"][\"code\"] == \"20000\":\n",
    "            return res[\"result\"][\"embedding\"]\n",
    "        else:\n",
    "            error_code = res[\"status\"][\"code\"]\n",
    "            error_message = res.get(\"status\", {}).get(\"message\", \"Unknown error\")\n",
    "            raise ValueError(f\"오류 발생: {error_code}: {error_message}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    embedding_executor = EmbeddingExecutor(\n",
    "        host=\"clovastudio.apigw.ntruss.com\",\n",
    "        api_key='NTA0MjU2MWZlZTcxNDJiY9olvu8DfBGDWQ20qeVZrRupbxCgWcs/59xl7cuRCJQ/',\n",
    "        api_key_primary_val='J97Kg6j6Nrc14yhuSv1JfvgWlJ2qbcOKUsAS88BB',\n",
    "        request_id='1037451f-6a88-40ae-afd4-fbc4a26cb354'\n",
    "    )\n",
    "\n",
    "    for i, chunked_document in enumerate(tqdm(chunked_html)):\n",
    "        if i==10:\n",
    "            break\n",
    "        try:\n",
    "            text_content = chunked_document['text']\n",
    "            if isinstance(text_content, list):\n",
    "                text_content=text_content[0]\n",
    "            request_json = {\n",
    "                \"text\": text_content\n",
    "            }\n",
    "            response_data = embedding_executor.execute(request_json)\n",
    "            chunked_document[\"embedding\"] = response_data\n",
    "        except ValueError as e:\n",
    "            print(f\"Embedding API Error. {e}\")\n",
    "            print(chunked_document['text'])\n",
    "        except Exception as e:\n",
    "            print(f\"Unexpected error: {e}\")\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "임베딩된 벡터들의 차원: {308}\n"
     ]
    }
   ],
   "source": [
    "dimension_set = set()\n",
    " \n",
    "for item in chunked_html:\n",
    "    if \"embedding\" in item:\n",
    "        dimension = len(item[\"embedding\"])\n",
    "        dimension_set.add(dimension)\n",
    " \n",
    "print(\"임베딩된 벡터들의 차원:\", dimension_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': 'https://wikidocs.net/233341',\n",
       " 'text': ['01. OpenAI API 키 발급 및 테스트'],\n",
       " 'embedding': [['<랭체인LangChain 노트> - LangChain 한국어 튜토리얼🇰🇷 CH01 LangChain 시작하기'],\n",
       "  ['01. OpenAI API 키 발급 및 테스트'],\n",
       "  ['02. LangSmith 추적 설정'],\n",
       "  ['03. OpenAI API 사용(GPT-4o 멀티모달)'],\n",
       "  ['04. LangChain Expression Language(LCEL)'],\n",
       "  ['05. LCEL 인터페이스'],\n",
       "  ['06. Runnable CH02 프롬프트(Prompt)'],\n",
       "  ['01. 프롬프트(Prompt)'],\n",
       "  ['02. 퓨샷 프롬프트(FewShotPromptTemplate)'],\n",
       "  ['03. LangChain Hub'],\n",
       "  ['04. 개인화된 프롬프트(Hub에 업로드) CH03 출력 파서(Output Parsers)'],\n",
       "  ['01. Pydantic 출력 파서(PydanticOutputParser)'],\n",
       "  ['02. 콤마 구분자 출력 파서(CommaSeparatedListOutputParser)'],\n",
       "  ['03. 구조화된 출력 파서(StructuredOuputParser)'],\n",
       "  ['04. JSON 출력 파서(JsonOutputParser)'],\n",
       "  ['05. 데이터프레임 출력 파서(PandasDataFrameOutputParser)'],\n",
       "  ['06. 날짜 형식 출력 파서(DatetimeOutputParser)'],\n",
       "  ['07. 열거형 출력 파서(EnumOutputParser)'],\n",
       "  ['08. 출력 수정 파서(OutputFixingParser) CH04 모델(Model)'],\n",
       "  ['01. 다양한 LLM 모델 활용'],\n",
       "  ['02. 캐싱(Cache)'],\n",
       "  ['03. 모델 직렬화(Serialization) - 저장 및 불러오기'],\n",
       "  ['04. 토큰 사용량 확인'],\n",
       "  ['05. 구글 생성 AI(Google Generative AI)'],\n",
       "  ['06. 허깅페이스 엔드포인트(HuggingFace Endpoints)'],\n",
       "  ['07. 허깅페이스 로컬(HuggingFace Local)'],\n",
       "  ['08. 허깅페이스 파이프라인(HuggingFace Pipeline)'],\n",
       "  ['09. 올라마(Ollama)'],\n",
       "  ['10. GPT4ALL CH05 메모리(Memory)'],\n",
       "  ['01. 대화 버퍼 메모리(ConversationBufferMemory)'],\n",
       "  ['02. 대화 버퍼 윈도우 메모리(ConversationBufferWindowMemory)'],\n",
       "  ['03. 대화 토큰 버퍼 메모리(ConversationTokenBufferMemory)'],\n",
       "  ['04. 대화 엔티티 메모리(ConversationEntityMemory)'],\n",
       "  ['05. 대화 지식그래프 메모리(ConversationKGMemory)'],\n",
       "  ['06. 대화 요약 메모리(ConversationSummaryMemory)'],\n",
       "  ['07. 벡터저장소 검색 메모리(VectorStoreRetrieverMemory)'],\n",
       "  ['08. LCEL Chain 에 메모리 추가', '09. SQLite 에 대화내용 저장'],\n",
       "  ['10. RunnableWithMessageHistory에 ChatMessageHistory추가 CH06 문서 로더(Document Loader)'],\n",
       "  ['01. 도큐먼트(Document) 의 구조'],\n",
       "  ['02. PDF'],\n",
       "  ['03. 한글(HWP)'],\n",
       "  ['04. CSV'],\n",
       "  ['05. Excel'],\n",
       "  ['06. Word'],\n",
       "  ['07. PowerPoint'],\n",
       "  ['08. 웹 문서(WebBaseLoader)'],\n",
       "  ['09. 텍스트(TextLoader)'],\n",
       "  ['10. JSON'],\n",
       "  ['11. Arxiv'],\n",
       "  ['13. UpstageLayoutAnalysisLoader'],\n",
       "  ['14. LlamaParser CH07 텍스트 분할(Text Splitter)'],\n",
       "  ['01. 문자 텍스트 분할(CharacterTextSplitter)'],\n",
       "  ['02. 재귀적 문자 텍스트 분할(RecursiveCharacterTextSplitter)'],\n",
       "  ['03. 토큰 텍스트 분할(TokenTextSplitter)'],\n",
       "  ['04. 시멘틱 청커(SemanticChunker)'],\n",
       "  ['05. 코드 분할(Python, Markdown, JAVA, C++, C#, GO, JS, Latex 등)'],\n",
       "  ['06. 마크다운 헤더 텍스트 분할(MarkdownHeaderTextSplitter)'],\n",
       "  ['07. HTML 헤더 텍스트 분할(HTMLHeaderTextSplitter)'],\n",
       "  ['08. 재귀적 JSON 분할(RecursiveJsonSplitter) CH08 임베딩(Embedding)'],\n",
       "  ['01. OpenAIEmbeddings'],\n",
       "  ['02. 캐시 임베딩(CacheBackedEmbeddings)'],\n",
       "  ['03. 허깅페이스 임베딩(HuggingFace Embeddings)'],\n",
       "  ['04. UpstageEmbeddings'],\n",
       "  ['05. OllamaEmbeddings'],\n",
       "  ['06. GPT4ALL 임베딩'],\n",
       "  ['07. Llama CPP 임베딩 CH09 벡터저장소(VectorStore)'],\n",
       "  ['01. Chroma'],\n",
       "  ['02. FAISS'],\n",
       "  ['03. Pinecone CH10 검색기(Retriever)'],\n",
       "  ['01. 벡터저장소 지원 검색기(VectorStore-backed Retriever)'],\n",
       "  ['02. 문맥 압축 검색기(ContextualCompressionRetriever)'],\n",
       "  ['03. 앙상블 검색기(EnsembleRetriever)'],\n",
       "  ['04. 긴 문맥 재정렬(LongContextReorder)'],\n",
       "  ['05. 상위 문서 검색기(ParentDocumentRetriever)'],\n",
       "  ['06. 다중 쿼리 검색기(MultiQueryRetriever)'],\n",
       "  ['07. 다중 벡터저장소 검색기(MultiVectorRetriever)'],\n",
       "  ['08. 셀프 쿼리 검색기(SelfQueryRetriever)'],\n",
       "  ['09. 시간 가중 벡터저장소 검색기(TimeWeightedVectorStoreRetriever)'],\n",
       "  ['10. 한글 형태소 분석기(Kiwi, Kkma, Okt) + BM25 검색기 CH11 리랭커(Reranker)'],\n",
       "  ['01. Cross Encoder Reranker'],\n",
       "  ['02. Cohere Reranker'],\n",
       "  ['03. Jina Reranker'],\n",
       "  ['04. FlashRank Reranker CH12 Retrieval Augmented Generation(RAG)'],\n",
       "  ['01. PDF 문서 기반 QA(Question-Answer)'],\n",
       "  ['02. 네이버 뉴스기사 QA(Question-Answer)'],\n",
       "  ['03. RAG 의 기능별 다양한 모듈 활용기'],\n",
       "  ['04. RAPTOR: 긴 문맥 요약(Long Context Summary)'],\n",
       "  ['05. 대화내용을 기억하는 RAG 체인 CH13 LangChain Expression Language(LCEL)'],\n",
       "  ['01. RunnablePassthrough: 데이터 전달'],\n",
       "  ['02. Runnable 구조(그래프) 확인'],\n",
       "  ['03. RunnableLambda: 사용자 정의 함수'],\n",
       "  ['04. RunnableBranch: 라우팅(Routing)'],\n",
       "  ['05. RunnableParallel: 병렬 처리'],\n",
       "  ['06. configurable_fields, configurable_alternatives 07. @chain 데코레이터로 Runnable 생성',\n",
       "   '08. RunnableWithMessageHistory'],\n",
       "  ['09. 사용자 정의 제네레이터(generator)'],\n",
       "  ['10. Runtime Arguments 바인딩'],\n",
       "  ['11. 폴백(fallback) 모델 지정 CH14 체인(Chains)'],\n",
       "  ['01. 문서 요약'],\n",
       "  ['02. SQL CH15 에이전트(Agent)'],\n",
       "  ['01. Agent 사용법 톺아보기'],\n",
       "  ['02. 도구를 활용한 토론 에이전트(Two Agent Debates with Tools) CH16 파인튜닝(Fine Tuning)'],\n",
       "  ['CH17 LangGraph'],\n",
       "  ['01. Chain of Table for Multiple Tables'],\n",
       "  ['<랭체인LangChain 노트> - Lang…'],\n",
       "  ['CH01 LangChain 시작하기'],\n",
       "  ['03. OpenAI API 사용(GPT-4o…'],\n",
       "  ['도서 증정 이벤트 !!'],\n",
       "  ['위키독스'],\n",
       "  ['03. OpenAI API 사용(GPT-4o 멀티모달)'],\n",
       "  ['# API KEY를 환경변수로 관리하기 위한 설정 파일'],\n",
       "  ['from dotenv import load_dotenv'],\n",
       "  ['# API KEY 정보로드'],\n",
       "  ['load_dotenv()'],\n",
       "  ['True'],\n",
       "  ['# LangSmith 추적을 설정합니다.', 'https://smith.langchain.com'],\n",
       "  ['# .env 파일에 LANGCHAIN_API_KEY를 입력합니다.'],\n",
       "  ['# !pip install -qU langchain-teddynote'],\n",
       "  ['from langchain_teddynote import logging'],\n",
       "  ['# 프로젝트 이름을 입력합니다.', 'logging.langsmith(\"CH01-Basic\")'],\n",
       "  ['LangSmith 추적을 시작합니다.'],\n",
       "  ['[프로젝트명]'],\n",
       "  ['CH01-Basic'],\n",
       "  ['ChatOpenAI', 'OpenAI 사의 채팅 전용 Large Language Model(llm) 입니다.'],\n",
       "  ['객체를 생성할 때 다음을 옵션 값을 지정할 수 있습니다.', '옵션에 대한 상세 설명은 다음과 같습니다.'],\n",
       "  ['temperature'],\n",
       "  ['사용할 샘플링 온도는 0과 2 사이에서 선택합니다.',\n",
       "   '0.8과 같은 높은 값은 출력을 더 무작위하게 만들고, 0.2와 같은 낮은 값은 출력을 더 집중되고 결정론적으로 만듭니다.'],\n",
       "  ['max_tokens'],\n",
       "  ['채팅 완성에서 생성할 토큰의 최대 개수입니다.'],\n",
       "  ['model_name: 적용 가능한 모델 리스트 - gpt-3.5-turbo - gpt-4-turbo - gpt-4o'],\n",
       "  ['링크: https://platform.openai.com/docs/models'],\n",
       "  ['from langchain_openai import ChatOpenAI'],\n",
       "  ['# 객체 생성', 'llm = ChatOpenAI('],\n",
       "  ['temperature=0.1, # 창의성 (0.0 ~ 2.0)'],\n",
       "  ['model_name=\"gpt-4o\", # 모델명'],\n",
       "  [')'],\n",
       "  ['# 질의내용', 'question = \"대한민국의 수도는 어디인가요?\"'],\n",
       "  ['# 질의'],\n",
       "  ['print(f\"[답변]: {llm.invoke(question)}\")'],\n",
       "  [\"[답변]: content='대한민국의 수도는 서울입니다.\"],\n",
       "  [\"서울은 대한민국의 정치, 경제, 문화의 중심지로서 많은 인구와 다양한 명소를 자랑하는 도시입니다.' response_metadata={'token_usage': {'completion_tokens': 36, 'prompt_tokens': 16, 'total_tokens': 52}, 'model_name': 'gpt-4o', 'system_fingerprint': 'fp_f4e629d0a5', 'finish_reason': 'stop', 'logprobs': None} id='run-dcda4cfa-3143-4982-b24c-4a25ce0a447e-0' usage_metadata={'input_tokens': 16, 'output_tokens': 36, 'total_tokens': 52}\"],\n",
       "  ['답변의 형식(AI Message)'],\n",
       "  ['# 질의내용'],\n",
       "  ['question = \"대한민국의 수도는 어디인가요?\"'],\n",
       "  ['# 질의'],\n",
       "  ['response = llm.invoke(question)'],\n",
       "  ['response'],\n",
       "  [\"AIMessage(content='대한민국의 수도는 서울입니다.\"],\n",
       "  [\"서울은 대한민국의 정치, 경제, 문화의 중심지로서 많은 인구와 다양한 명소를 자랑하는 도시입니다.', response_metadata={'token_usage': {'completion_tokens': 36, 'prompt_tokens': 16, 'total_tokens': 52}, 'model_name': 'gpt-4o', 'system_fingerprint': 'fp_aa87380ac5', 'finish_reason': 'stop', 'logprobs': None}, id='run-3296402a-f47b-4ace-88cd-b74efb7465fb-0', usage_metadata={'input_tokens': 16, 'output_tokens': 36, 'total_tokens': 52})\"],\n",
       "  ['response.content'],\n",
       "  [\"'대한민국의 수도는 서울입니다.\"],\n",
       "  [\"서울은 대한민국의 정치, 경제, 문화의 중심지로서 많은 인구와 다양한 명소를 자랑하는 도시입니다.'\"],\n",
       "  ['response.response_metadata'],\n",
       "  [\"{'token_usage': {'completion_tokens': 36, 'prompt_tokens': 16, 'total_tokens': 52}, 'model_name': 'gpt-4o', 'system_fingerprint': 'fp_aa87380ac5', 'finish_reason': 'stop', 'logprobs': None}\"],\n",
       "  ['LogProb 활성화'],\n",
       "  ['주어진 텍스트에 대한 모델의 토큰 확률의 로그 값 을 의미합니다.',\n",
       "   '토큰이란 문장을 구성하는 개별 단어나 문자 등의 요소를 의미하고, 확률은 모델이 그 토큰을 예측할 확률을 나타냅니다.'],\n",
       "  ['# 객체 생성'],\n",
       "  ['llm_with_logprob = ChatOpenAI('],\n",
       "  ['temperature=0.1, # 창의성 (0.0 ~ 2.0)'],\n",
       "  ['max_tokens=2048, # 최대 토큰수'],\n",
       "  ['model_name=\"gpt-3.5-turbo\", # 모델명'],\n",
       "  [').bind(logprobs=True)'],\n",
       "  ['# 질의내용', 'question = \"대한민국의 수도는 어디인가요?\"'],\n",
       "  ['# 질의'],\n",
       "  ['response = llm_with_logprob.invoke(question)'],\n",
       "  ['# 결과 출력', 'response.response_metadata'],\n",
       "  [\"{'token_usage': {'completion_tokens': 15, 'prompt_tokens': 24, 'total_tokens': 39}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': {'content': [{'token': '대', 'bytes': [235, 140, 128], 'logprob': -0.03859115, 'top_logprobs': []}, {'token': '한', 'bytes': [237, 149, 156], 'logprob': -5.5122365e-07, 'top_logprobs': []}, {'token': '\\\\\\\\xeb\\\\\\\\xaf', 'bytes': [235, 175], 'logprob': -2.8160932e-06, 'top_logprobs': []}, {'token': '\\\\\\\\xbc', 'bytes': [188], 'logprob': 0.0, 'top_logprobs': []}, {'token': '\\\\\\\\xea\\\\\\\\xb5', 'bytes': [234, 181], 'logprob': -6.704273e-07, 'top_logprobs': []}, {'token': '\\\\\\\\xad', 'bytes': [173], 'logprob': 0.0, 'top_logprobs': []}, {'token': '의', 'bytes': [236, 157, 152], 'logprob': -6.2729996e-06, 'top_logprobs': []}, {'token': ' 수', 'bytes': [32, 236, 136, 152], 'logprob': -5.5122365e-07, 'top_logprobs': []}, {'token': '도', 'bytes': [235, 143, 132], 'logprob': -5.5122365e-07, 'top_logprobs': []}, {'token': '는', 'bytes': [235, 138, 148], 'logprob': -1.9361265e-07, 'top_logprobs': []}, {'token': ' 서', 'bytes': [32, 236, 132, 156], 'logprob': -5.080963e-06, 'top_logprobs': []}, {'token': '\\\\\\\\xec\\\\\\\\x9a', 'bytes': [236, 154], 'logprob': 0.0, 'top_logprobs': []}, {'token': '\\\\\\\\xb8', 'bytes': [184], 'logprob': 0.0, 'top_logprobs': []}, {'token': '입니다', 'bytes': [236, 158, 133, 235, 139, 136, 235, 139, 164], 'logprob': -0.13815464, 'top_logprobs': []}, {'token': '.', 'bytes': [46], 'logprob': -9.0883464e-07, 'top_logprobs': []}]}}\"],\n",
       "  ['스트리밍 출력'],\n",
       "  ['스트리밍 옵션은 질의에 대한 답변을 실시간으로 받을 때 유용합니다.'],\n",
       "  ['# 스트림 방식으로 질의'],\n",
       "  ['# answer 에 스트리밍 답변의 결과를 받습니다.'],\n",
       "  ['answer = llm.stream(\"대한민국의 아름다운 관광지 10곳과 주소를 알려주세요!\")'],\n",
       "  ['# 스트리밍 방식으로 각 토큰을 출력합니다.'],\n",
       "  ['(실시간 출력)',\n",
       "   'for token in answer:',\n",
       "   'print(token.content, end=\"\", flush=True)'],\n",
       "  ['물론입니다!'],\n",
       "  ['대한민국에는 아름다운 관광지가 많이 있습니다.'],\n",
       "  ['다음은 그 중 10곳과 그 주소입니다:'],\n",
       "  ['1. **경복궁**'],\n",
       "  ['- 주소: 서울특별시 종로구 사직로 161'],\n",
       "  ['2. **부산 해운대 해수욕장**', '- 주소: 부산광역시 해운대구 우동'],\n",
       "  ['3. **제주도 한라산 국립공원**', '- 주소: 제주특별자치도 제주시 1100로 2070-61'],\n",
       "  ['4. **경주 불국사**'],\n",
       "  ['- 주소: 경상북도 경주시 불국로 385'],\n",
       "  ['5. **설악산 국립공원**'],\n",
       "  ['- 주소: 강원도 속초시 설악산로 833'],\n",
       "  ['6. **남이섬**'],\n",
       "  ['- 주소: 강원도 춘천시 남산면 남이섬길 1'],\n",
       "  ['7. **안동 하회마을**'],\n",
       "  ['- 주소: 경상북도 안동시 풍천면 하회종가길 40'],\n",
       "  ['8. **전주 한옥마을**'],\n",
       "  ['- 주소: 전라북도 전주시 완산구 기린대로 99'],\n",
       "  ['9. **서울 남산타워 (N서울타워)**'],\n",
       "  ['- 주소: 서울특별시 용산구 남산공원길 105'],\n",
       "  ['10. **보성 녹차밭 대한다원**', '- 주소: 전라남도 보성군 보성읍 녹차로 763-67'],\n",
       "  ['이 관광지들은 각기 다른 매력을 가지고 있어 다양한 경험을 할 수 있습니다.'],\n",
       "  ['즐거운 여행 되세요!'],\n",
       "  ['from langchain_teddynote.messages import stream_response'],\n",
       "  ['# 스트림 방식으로 질의',\n",
       "   '# answer 에 스트리밍 답변의 결과를 받습니다.',\n",
       "   'answer = llm.stream(\"대한민국의 아름다운 관광지 10곳과 주소를 알려주세요!\")'],\n",
       "  ['stream_response(answer)', '물론입니다!'],\n",
       "  ['대한민국에는 아름다운 관광지가 많이 있습니다.', '다음은 그 중 10곳과 그 주소입니다:'],\n",
       "  ['1. **경복궁**'],\n",
       "  ['- 주소: 서울특별시 종로구 사직로 161'],\n",
       "  ['2. **부산 해운대 해수욕장**', '- 주소: 부산광역시 해운대구 우동'],\n",
       "  ['3. **제주도 한라산 국립공원**', '- 주소: 제주특별자치도 제주시 1100로 2070-61'],\n",
       "  ['4. **경주 불국사**'],\n",
       "  ['- 주소: 경상북도 경주시 불국로 385'],\n",
       "  ['5. **설악산 국립공원**'],\n",
       "  ['- 주소: 강원도 속초시 설악산로 833'],\n",
       "  ['6. **남이섬**'],\n",
       "  ['- 주소: 강원도 춘천시 남산면 남이섬길 1'],\n",
       "  ['7. **전주 한옥마을**'],\n",
       "  ['- 주소: 전라북도 전주시 완산구 기린대로 99'],\n",
       "  ['8. **안동 하회마을**'],\n",
       "  ['- 주소: 경상북도 안동시 풍천면 하회종가길 40'],\n",
       "  ['9. **서울 남산타워 (N서울타워)**'],\n",
       "  ['- 주소: 서울특별시 용산구 남산공원길 105'],\n",
       "  ['10. **순천만 국가정원**'],\n",
       "  ['- 주소: 전라남도 순천시 국가정원1호길 47'],\n",
       "  ['이 관광지들은 각기 다른 매력을 가지고 있어 다양한 경험을 할 수 있습니다.'],\n",
       "  ['즐거운 여행 되세요!'],\n",
       "  ['멀티모달 모델(이미지 인식)'],\n",
       "  ['멀티모달은 여러 가지 형태의 정보(모달)를 통합하여 처리하는 기술이나 접근 방식을 의미합니다.'],\n",
       "  ['이는 다음과 같은 다양한 데이터 유형을 포함할 수 있습니다.'],\n",
       "  ['텍스트: 문서, 책, 웹 페이지 등의 글자로 된 정보'],\n",
       "  ['이미지: 사진, 그래픽, 그림 등 시각적 정보'],\n",
       "  ['오디오: 음성, 음악, 소리 효과 등의 청각적 정보'],\n",
       "  ['비디오: 동영상 클립, 실시간 스트리밍 등 시각적 및 청각적 정보의 결합'],\n",
       "  ['gpt-4o 나 gpt-4-turbo 모델은 이미지 인식 기능(Vision) 이 추가되어 있는 모델입니다.'],\n",
       "  ['from langchain_teddynote.models import MultiModal'],\n",
       "  ['from langchain_teddynote.messages import stream_response'],\n",
       "  ['# 객체 생성'],\n",
       "  ['llm = ChatOpenAI('],\n",
       "  ['temperature=0.1, # 창의성 (0.0 ~ 2.0)'],\n",
       "  ['max_tokens=2048, # 최대 토큰수'],\n",
       "  ['model_name=\"gpt-4o\", # 모델명'],\n",
       "  [')'],\n",
       "  ['# 멀티모달 객체 생성'],\n",
       "  ['multimodal_llm = MultiModal(llm)'],\n",
       "  ['# 샘플 이미지 주소(웹사이트로 부터 바로 인식)'],\n",
       "  ['IMAGE_URL = \"https://t3.ftcdn.net/jpg/03/77/33/96/360_F_377339633_Rtv9I77sSmSNcev8bEcnVxTHrXB4nRJ5.jpg\"'],\n",
       "  ['# 이미지 파일로 부터 질의'],\n",
       "  ['answer = multimodal_llm.stream(IMAGE_URL)'],\n",
       "  ['# 스트리밍 방식으로 각 토큰을 출력합니다.', '(실시간 출력)', 'stream_response(answer)'],\n",
       "  ['이 이미지는 표 형식의 데이터 테이블을 보여줍니다.',\n",
       "   '테이블의 제목은 \"TABLE 001: LOREM IPSUM DOLOR AMIS ENIMA ACCUMER TUNA\"입니다.',\n",
       "   '테이블은 다섯 개의 열과 여덟 개의 행으로 구성되어 있습니다.',\n",
       "   '열 제목은 다음과 같습니다:'],\n",
       "  ['1. Loremis'],\n",
       "  ['2. Amis terim'],\n",
       "  ['3. Gato lepis'],\n",
       "  ['4. Tortores'],\n",
       "  ['각 행의 데이터는 다음과 같습니다:'],\n",
       "  ['1. Lorem dolor siamet: 8,288, 123%, YES, $89'],\n",
       "  ['2. Consecter odio: 123, 87%, NO, $129'],\n",
       "  ['3. Gatoque accums: 1,005, 12%, NO, $199'],\n",
       "  ['4. Sed hac enim rem: 56, 69%, N/A, $199',\n",
       "   '5. Rempus tortor just: 5,554, 18%, NO, $999',\n",
       "   '6. Klimas nsecter: 455, 56%, NO, $245'],\n",
       "  ['7. Babiask atque accu: 1,222, 2%, YES, $977'],\n",
       "  ['8. Enim rem kos: 5,002, 91%, N/A, $522'],\n",
       "  ['표 하단에는 작은 글씨로 Lorem ipsum 텍스트가 포함되어 있습니다.'],\n",
       "  ['# 로컬 PC 에 저장되어 있는 이미지의 경로 입력'],\n",
       "  ['IMAGE_PATH_FROM_FILE = \"./images/sample-image.png\"'],\n",
       "  ['# 이미지 파일로 부터 질의(스트림 방식)',\n",
       "   'answer = multimodal_llm.stream(IMAGE_PATH_FROM_FILE)'],\n",
       "  ['# 스트리밍 방식으로 각 토큰을 출력합니다.', '(실시간 출력)', 'stream_response(answer)'],\n",
       "  ['이미지 설명 대체 텍스트:'],\n",
       "  ['이미지에는 \"FIRST OPENAI DEVDAY EVENT\"라는 제목이 상단에 크게 표시되어 있습니다.'],\n",
       "  ['이벤트 날짜는 2023년 11월 6일입니다.'],\n",
       "  ['주요 업데이트 항목으로는 GPT 4 Turbo, 128k Tokens, Custom GPTs, Assistant API, Price Reduction이 나열되어 있습니다.',\n",
       "   '이미지 왼쪽 상단에는 \"ASTRA TECHZ\" 로고가 있습니다.',\n",
       "   '이미지 중앙에는 \"MAIN UPDATES SUMMARISED\"라는 제목 아래 주요 업데이트 내용이 요약되어 있습니다.',\n",
       "   '각 항목 옆에는 체크 표시가 있으며, 세부 내용은 다음과 같습니다:'],\n",
       "  ['- Token Length: 128K'],\n",
       "  ['- Custom GPTs: Private or Public'],\n",
       "  ['- Multi Modal: Img, Video, Voice'],\n",
       "  ['- JSON Mode: Guaranteed'],\n",
       "  ['- Assistant API: Developers'],\n",
       "  ['- Text 2 Speech: Beta Release'],\n",
       "  ['- Natural Voice Options: 6 Voices'],\n",
       "  ['- GPT Store: Revenue Shared'],\n",
       "  ['- Conversation Threading: Per Conversation'],\n",
       "  ['- File Uploading: Multiple'],\n",
       "  ['- API Price Reduction: 2.5x - 3.5x'],\n",
       "  ['- Code Interpreter: Built In'],\n",
       "  ['- Function Calling: Built In'],\n",
       "  ['이미지 하단에는 \"visit www.astratechz.com to build AI solutions\"라는 문구가 있습니다.'],\n",
       "  ['System, User 프롬프트 수정'],\n",
       "  ['system_prompt = \"\"\"당신은 표(재무제표) 를 해석하는 금융 AI 어시스턴트 입니다.',\n",
       "   '당신의 임무는 주어진 테이블 형식의 재무제표를 바탕으로 흥미로운 사실을 정리하여 친절하게 답변하는 것입니다.\"\"\"'],\n",
       "  ['user_prompt = \"\"\"당신에게 주어진 표는 회사의 재무제표 입니다.'],\n",
       "  ['흥미로운 사실을 정리하여 답변하세요.\"\"\"'],\n",
       "  ['# 멀티모달 객체 생성'],\n",
       "  ['multimodal_llm_with_prompt = MultiModal(',\n",
       "   'llm, system_prompt=system_prompt, user_prompt=user_prompt'],\n",
       "  [')'],\n",
       "  ['# 로컬 PC 에 저장되어 있는 이미지의 경로 입력'],\n",
       "  ['IMAGE_PATH_FROM_FILE = \"https://storage.googleapis.com/static.fastcampus.co.kr/prod/uploads/202212/080345-661/kwon-01.png\"'],\n",
       "  ['# 이미지 파일로 부터 질의(스트림 방식)'],\n",
       "  ['answer = multimodal_llm_with_prompt.stream(IMAGE_PATH_FROM_FILE)'],\n",
       "  ['# 스트리밍 방식으로 각 토큰을 출력합니다.', '(실시간 출력)', 'stream_response(answer)'],\n",
       "  ['주어진 재무제표를 바탕으로 몇 가지 흥미로운 사실을 정리해 보았습니다:'],\n",
       "  ['1. **유동자산의 변화**:'],\n",
       "  ['- 제 19기(2019년) 유동자산은 8,349,633백만원으로, 제 18기(2018년) 8,602,837백만원에 비해 감소하였습니다.',\n",
       "   '- 특히 현금 및 현금성 자산이 제 18기 1,690,862백만원에서 제 19기 1,002,263백만원으로 크게 감소하였습니다.'],\n",
       "  ['2. **매출채권**:',\n",
       "   '- 매출채권은 제 18기 4,004,920백만원에서 제 19기 3,981,935백만원으로 소폭 감소하였습니다.'],\n",
       "  ['3. **기타수취채권**:',\n",
       "   '- 기타수취채권은 제 18기 321,866백만원에서 제 19기 366,141백만원으로 증가하였습니다.'],\n",
       "  ['4. **비유동자산의 증가**:',\n",
       "   '- 비유동자산은 제 18기 15,127,741백만원에서 제 19기 18,677,453백만원으로 크게 증가하였습니다.',\n",
       "   '- 특히, 재고자산이 제 18기 2,426,364백만원에서 제 19기 2,670,294백만원으로 증가하였습니다.'],\n",
       "  ['5. **기타유동자산**:',\n",
       "   '- 기타유동자산은 제 18기 156,538백만원에서 제 19기 207,596백만원으로 증가하였습니다.'],\n",
       "  ['6. **기타장기수취채권**:',\n",
       "   '- 기타장기수취채권은 제 18기 118,086백만원에서 제 19기 505,489백만원으로 크게 증가하였습니다.',\n",
       "   '이러한 변화들은 회사의 자산 구조와 재무 상태에 중요한 영향을 미칠 수 있으며, 특히 현금성 자산의 감소와 비유동자산의 증가가 눈에 띕니다.'],\n",
       "  ['이는 회사의 유동성 관리와 장기 투자 전략에 대한 추가적인 분석이 필요함을 시사합니다.'],\n",
       "  ['마지막 편집일시 : 2024년 6월 18일 1:19 오전'],\n",
       "  ['댓글 0 피드백', '※ 댓글 작성은 로그인이 필요합니다.', '(또는 피드백을 이용해 주세요.)'],\n",
       "  ['이전글 : 02.'],\n",
       "  ['LangSmith 추적 설정'],\n",
       "  ['다음글 : 04.'],\n",
       "  ['LangChain Expression Language(LCEL)'],\n",
       "  ['목차보기'],\n",
       "  ['책갈피'],\n",
       "  ['이 페이지에 대한 피드백을 남겨주세요'],\n",
       "  ['댓글을 신고합니다.']]}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunked_html[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Vector DB\n",
    "\n",
    "CLOVA Studio의 임베딩 API를 활용하여 모든 chunked_의 text를 1024차원의 벡터로 변환한 후, 'embedding'이라는 이름의 객체로 chunked_html에 추가해 주었습니다. 이제 이 데이터를 Vector DB에 저장하고, 인덱싱을 하는 단계입니다. Vector DB로는 Milvus를 사용하였으며, 대시보드는 Docker를 사용하여 DB를 켜고(Run) 끄는(Stop) 작업을 수행하였습니다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
